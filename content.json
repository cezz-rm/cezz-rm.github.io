{"meta":{"title":"Hexo","subtitle":"","description":"","author":"CeJ","url":"https://cezz.github.io","root":"/"},"pages":[{"title":"关于","date":"2022-05-23T01:27:43.000Z","updated":"2022-10-10T14:10:50.254Z","comments":false,"path":"about/index.html","permalink":"https://cezz.github.io/about/index.html","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637&#123; &quot;name&quot;: &quot;CeJ&quot;, &quot;age&quot;: 27, &quot;gender&quot;: &quot;man&quot;, &quot;profression&quot;: &quot;python &amp; go Developer&quot;, &quot;experience&quot;: &quot;4 years&quot;, &quot;address&quot;: &quot;BeiJing&quot;, &quot;education&quot;: &quot;Southwest Jiaotong University&quot;, &quot;major&quot;: &quot;mechanical design, manufacturing and automation&quot;, &quot;github&quot;: &quot;https://github.com/zcej&quot;, &quot;description&quot;: &quot;faithful to your heart, fruitful to your result&quot;, &quot;skills&quot;: [ [&quot;HTML5&quot;, &quot;javascript&quot;, &quot;jquery&quot;, &quot;css&quot;], [&quot;python&quot;, &quot;go&quot;], [&quot;django&quot;, &quot;flask&quot;, &quot;gin&quot;, &quot;grpc&quot;, &quot;vue&quot;], [&quot;mysql&quot;, &quot;redis&quot;, &quot;mongodb&quot;], [&quot;linux&quot;, &quot;shell&quot;], [&quot;rabbitmq&quot;], [&quot;git&quot;, &quot;svn&quot;], [&quot;docker&quot;, &quot;kubernetes&quot;], ], &quot;devTools&quot;: [ [&quot;pycharm&quot;, &quot;goland&quot;, &quot;webstorm&quot;], [&quot;sublime&quot;, &quot;nptepad++&quot;], [&quot;chrome&quot;, &quot;fiddler&quot;], [&quot;navicat&quot;], [&quot;mobaxterm&quot;], [&quot;snipaste&quot;, &quot;faststone&quot;, &quot;processon&quot;], ], &quot;hobby&quot;: &#123; &quot;sports&quot;: [&quot;ping-pong&quot;, &quot;badminton&quot;], &quot;animation&quot;: [&quot;one piece&quot;, &quot;naruto&quot;, &quot;bleach&quot;] &#125;&#125;"},{"title":"tags","date":"2022-05-23T01:21:14.000Z","updated":"2022-05-23T01:22:32.583Z","comments":false,"path":"tags/index.html","permalink":"https://cezz.github.io/tags/index.html","excerpt":"","text":""},{"title":"分类","date":"2022-04-10T06:46:53.000Z","updated":"2022-04-10T06:49:32.991Z","comments":false,"path":"categories/index.html","permalink":"https://cezz.github.io/categories/index.html","excerpt":"","text":""},{"title":"书单","date":"2022-05-23T01:25:50.000Z","updated":"2022-05-23T01:26:28.458Z","comments":false,"path":"books/index.html","permalink":"https://cezz.github.io/books/index.html","excerpt":"","text":""},{"title":"友链","date":"2022-05-23T01:26:49.000Z","updated":"2022-05-23T01:27:19.285Z","comments":false,"path":"links/index.html","permalink":"https://cezz.github.io/links/index.html","excerpt":"","text":""},{"title":"项目","date":"2022-05-23T01:24:19.000Z","updated":"2022-05-23T01:25:24.126Z","comments":false,"path":"repository/index.html","permalink":"https://cezz.github.io/repository/index.html","excerpt":"","text":""}],"posts":[{"title":"airflow使用pip或docker compose安装","slug":"python/airflow使用pip或docker compose安装","date":"2023-03-02T13:11:41.000Z","updated":"2023-05-04T10:41:22.538Z","comments":true,"path":"2023/03/02/python/airflow使用pip或docker compose安装/","link":"","permalink":"https://cezz.github.io/2023/03/02/python/airflow%E4%BD%BF%E7%94%A8pip%E6%88%96docker%20compose%E5%AE%89%E8%A3%85/","excerpt":"","text":"本文记录当前airflow的两种安装方式，当前最新版本为2.5.1。 注：就目前而言，airflow版本大于2.3.0时，官方推荐python的版本为3.7-3.10，3.11暂不支持。 使用pip安装 安装python 创建虚拟环境 12345# 方式1pyenv virtualenv 3.9.10 venvAirflow# 方式2python -m virtualenv venvAirflow 安装airflow 默认会安装在~/airflow下，可通过指定环境变量修改，如：export AIRFLOW_HOME=~/airflow 12# 只包含启动的基础部分内容，扩展包其它方式安装，参照官网pip install apache-airflow 初始化数据库，默认使用sqlite存储元数据，仅用于测试环境。生产环境下的并发支持需用mysql或psql 1airflow db init 初始用户为admin，密码见同目录下文件standalone_admin_password.txt 启动web服务器 两种方式启动 一键启动： 1airflow standalone 手动运行airflow各个部分： 123456789101112airflow db initairflow users create \\ --username admin \\ --firstname Peter \\ --lastname Parker \\ --role Admin \\ --email spiderman@superhero.orgairflow webserver --port 8080airflow scheduler 访问web界面 访问http://localhost:8080，将看到web界面 通过docker-compose安装 检查内存是否足够 官方建议至少为docker engine分配4GB内存，最好是8GB，通过下述命令检测。 1docker run --rm &quot;debian:bullseye-slim&quot; bash -c &#x27;numfmt --to iec $(echo $(($(getconf _PHYS_PAGES) * $(getconf PAGE_SIZE))))&#x27; 下载docker-compose.yaml1curl -LfO &#x27;https://airflow.apache.org/docs/apache-airflow/2.5.1/docker-compose.yaml&#x27; 该文件定义了多个服务： airflow-scheduler：调度程序监视所有任务和DAGs，并在任务实例的依赖关系完成后触发 airflow-webserver：http://localhost:8080 airflow-worker：执行调度程序分配的任务 airflow-init：初始化服务 postgres：数据库 redis：消息从scheduler转发到worker的代理broker flower：环境监控，http://localhost:5555 创建挂载目录及用户设置 12mkdir -p ./dags ./logs ./pluginsecho -e &quot;AIRFLOW_UID=$(id -u)&quot; &gt; .env 初始化数据库 1234567docker compose up airflow-init# 当初始化完成将看到下述输出# airflow-init_1 | Upgrades done# airflow-init_1 | Admin user airflow created# airflow-init_1 | 2.5.1# start_airflow-init_1 exited with code 0 初始化用户密码为airflow/airflow 运行airflow 123456789docker-compose up# 执行docker-compose ps -a看到下述输出则说明正常运行# CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES# 247ebe6cf87a apache/airflow:2.5.1 &quot;/usr/bin/dumb-init …&quot; 3 minutes ago Up 3 minutes (healthy) 8080/tcp compose_airflow-worker_1# ed9b09fc84b1 apache/airflow:2.5.1 &quot;/usr/bin/dumb-init …&quot; 3 minutes ago Up 3 minutes (healthy) 8080/tcp compose_airflow-scheduler_1# 7cb1fb603a98 apache/airflow:2.5.1 &quot;/usr/bin/dumb-init …&quot; 3 minutes ago Up 3 minutes (healthy) 0.0.0.0:8080-&gt;8080/tcp compose_airflow-webserver_1# 74f3bbe506eb postgres:13 &quot;docker-entrypoint.s…&quot; 18 minutes ago Up 17 minutes (healthy) 5432/tcp compose_postgres_1# 0bd6576d23cb redis:latest &quot;docker-entrypoint.s…&quot; 10 hours ago Up 17 minutes (healthy) 0.0.0.0:6379-&gt;6379/tcp compose_redis_1 如何使用 在启动airflow后，有以下三种使用方式： 通过CLI命令 12345678910111213# 同样可以使用CLI命令docker-compose run airflow-worker airflow info# 或者下载官方提供的命令包装脚本curl -LfO &#x27;https://airflow.apache.org/docs/apache-airflow/2.5.1/airflow.sh&#x27;chmod +x airflow.sh./airflow.sh info# 同时支持进入交互式bash shell，或进入python容器./airflow.sh bash./airflow.sh python 通过Web页面 使用预设用户密码airflow/airflow进入web页面http://localhost:8080 使用REST API接口 如下命令简单参考，更详细可查阅官方文档 1234ENDPOINT_URL=&quot;http://localhost:8080/&quot;curl -X GET \\ --user &quot;airflow:airflow&quot; \\ &quot;$&#123;ENDPOINT_URL&#125;/api/v1/pools&quot; 清除 若要停止和删除容器，删除数据卷及镜像的话可参考下述命令： 1docker-compose down --volumes --rmi all","categories":[{"name":"python","slug":"python","permalink":"https://cezz.github.io/categories/python/"}],"tags":[]},{"title":"airflow简单了解","slug":"python/airflow简单了解","date":"2023-02-27T05:08:26.000Z","updated":"2023-05-04T10:39:34.786Z","comments":true,"path":"2023/02/27/python/airflow简单了解/","link":"","permalink":"https://cezz.github.io/2023/02/27/python/airflow%E7%AE%80%E5%8D%95%E4%BA%86%E8%A7%A3/","excerpt":"","text":"Q：airflow介绍是用于任务调度和监控的开源工具，由python编写。以DAG有向无环图的方式组建task任务流，灵活的定义任务间的依赖关系，监控任务的运行状态。强大的web UI，页面功能丰富。 任务流怎么理解，工作流程有一个明确的开始和结束，按一定的间隔运行，就可以用python定义一个dag文件。dag的定义文件，只是一个配置文件，该脚本不能用于任务之间的交叉通信，不过有一个高级特性解决该问题XComs。下面是定义任务依赖关系的方法： t1.set_upstream(t2) t1.set_downstream([t2, t3]) t1 &gt;&gt; [t2, t3] 官方的一个简单的dag文件定义如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182from datetime import datetime, timedeltafrom textwrap import dedent# The DAG object; we&#x27;ll need this to instantiate a DAGfrom airflow import DAG# Operators; we need this to operate!from airflow.operators.bash import BashOperatorwith DAG( &quot;tutorial&quot;, # These args will get passed on to each operator # You can override them on a per-task basis during operator initialization default_args=&#123; &quot;depends_on_past&quot;: False, &quot;email&quot;: [&quot;airflow@example.com&quot;], &quot;email_on_failure&quot;: False, &quot;email_on_retry&quot;: False, &quot;retries&quot;: 1, &quot;retry_delay&quot;: timedelta(minutes=5), # &#x27;queue&#x27;: &#x27;bash_queue&#x27;, # &#x27;pool&#x27;: &#x27;backfill&#x27;, # &#x27;priority_weight&#x27;: 10, # &#x27;end_date&#x27;: datetime(2016, 1, 1), # &#x27;wait_for_downstream&#x27;: False, # &#x27;sla&#x27;: timedelta(hours=2), # &#x27;execution_timeout&#x27;: timedelta(seconds=300), # &#x27;on_failure_callback&#x27;: some_function, # &#x27;on_success_callback&#x27;: some_other_function, # &#x27;on_retry_callback&#x27;: another_function, # &#x27;sla_miss_callback&#x27;: yet_another_function, # &#x27;trigger_rule&#x27;: &#x27;all_success&#x27; &#125;, description=&quot;A simple tutorial DAG&quot;, schedule=timedelta(days=1), start_date=datetime(2021, 1, 1), catchup=False, tags=[&quot;example&quot;],) as dag: # t1, t2 and t3 are examples of tasks created by instantiating operators t1 = BashOperator( task_id=&quot;print_date&quot;, bash_command=&quot;date&quot;, ) t2 = BashOperator( task_id=&quot;sleep&quot;, depends_on_past=False, bash_command=&quot;sleep 5&quot;, retries=3, ) t1.doc_md = dedent( &quot;&quot;&quot;\\ #### Task Documentation You can document your task using the attributes `doc_md` (markdown), `doc` (plain text), `doc_rst`, `doc_json`, `doc_yaml` which gets rendered in the UI&#x27;s Task Instance Details page. ![img](http://montcs.bloomu.edu/~bobmon/Semesters/2012-01/491/import%20soul.png) **Image Credit:** Randall Munroe, [XKCD](https://xkcd.com/license.html) &quot;&quot;&quot; ) dag.doc_md = __doc__ # providing that you have a docstring at the beginning of the DAG; OR dag.doc_md = &quot;&quot;&quot; This is a documentation placed anywhere &quot;&quot;&quot; # otherwise, type it like this templated_command = dedent( &quot;&quot;&quot; &#123;% for i in range(5) %&#125; echo &quot;&#123;&#123; ds &#125;&#125;&quot; echo &quot;&#123;&#123; macros.ds_add(ds, 7)&#125;&#125;&quot; &#123;% endfor %&#125; &quot;&quot;&quot; ) t3 = BashOperator( task_id=&quot;templated&quot;, depends_on_past=False, bash_command=templated_command, ) t1 &gt;&gt; [t2, t3] Q：airflow基本功能 任务调度：支持按时间计划、依赖关系或手动触发等方式调度任务。 任务监控：可以查看任务执行情况，如执行时间、任务状态、失败原因等。 依赖关系管理：支持设置任务间的依赖关系，确保任务的执行顺序。 数据流图：提供数据流图，方便用户清晰地查看任务间的依赖关系。 任务执行：支持将任务提交到不同的执行环境，如本地、云环境等。 高度定制：支持自定义插件，以扩展Airflow的功能。 权限管理：支持对用户进行权限管理，确保任务的安全性。 Web界面：提供易于使用的Web界面，方便用户进行任务调度、监控、配置等操作。 任务扩展：支持任务扩展，可以根据需求增加任务类型。 数据库存储：支持使用数据库存储任务信息，方便用户对任务信息进行查询和维护。 任务记录：支持对任务的执行情况进行详细记录，以便用户查询和分析。 电子邮件通知：支持对任务的执行情况进行电子邮件通知，以便用户及时了解任务执行情况。 多租户支持：支持多租户，可以将不同的任务隔离开来，保证各个任务的安全性和独立性。 可靠性：支持多种高可靠性策略，如任务重试、任务隔离等，确保任务的可靠性。 安全性：支持多种安全措施，如用户认证、数据加密等，确保系统的安全性。 故障恢复：支持故障恢复，在系统出现故障时，可以自动恢复任务的执行。 API支持：提供丰富的API，方便用户通过代码编程方式对任务进行操作。 可扩展性：提供可扩展的架构，可以根据业务需求进行扩展。 报表生成：支持报表生成，方便用户查询和分析任务执行情况。 日志管理：支持日志管理，方便用户查询和分析系统运行情况。 可视化管理：提供可视化的任务管理界面，方便用户对任务进行监控和管理。 支持多种语言：支持多种语言，如Python、Java、C++等，方便用户编写任务代码。 Q：airflow应用场景 数据管道：用于编排数据管道，从数据源获取数据，并在进行数据处理、转换、存储等操作后将数据存储到目标数据库。 数据分析：用于编排数据分析任务，将数据从数据库中抽取，并进行数据分析、可视化等操作。 模型训练：用于编排模型训练任务，将数据从数据库中抽取，并使用机器学习模型进行训练。 定时任务：用于编排定时任务，定期执行一些固定的任务，如数据备份、定期清理等。 其他自动化任务：用于编排其他自动化任务，如文件转换、数据同步等。 Q：airflow有哪些组件 Webserver：管理界面，可以在其中管理任务、查看任务执行状态、配置任务等。 Scheduler：调度器，负责调度任务执行。 Workers：执行任务的节点，负责执行任务。 DAGs：任务流程，表示任务之间的依赖关系。 Operators：任务执行单元，封装了一组任务执行的逻辑。 Hooks：连接器，用于连接不同的任务或外部系统。 Sensors：传感器，用于监测外部系统的状态。 Variables：变量，存储一些全局变量，可以在任务流程中使用。 XComs：交互数据，可以在任务之间传递数据。 Connections：连接，用于连接不同的数据源。Q：airflow和dolphinsheduler的不同和优缺点DolphinScheduler致力于可视化，通过页面完成一个DAG工作流。Airflow则是通过编程的方式完成一个DAG工作量，定制化开发相对比较容易。 相似点： 两者都允许用户创建和管理复杂的工作流。 两者都有基于网页的用户界面，用于查看和管理作业。 两者都提供了一种自动调度和执行任务的方法。 不同点： Airflow 是用 Python 编写的，具有庞大的活跃社区，而 DolphinScheduler 是用 Java 编写的，社区较小。 Airflow 有丰富的内置操作符，用于处理数据，例如在系统之间传输文件的能力，并且可以使用自定义插件轻松扩展，而 DolphinScheduler 提供了一组更基本的操作符，可能需要更多的自定义才能适合特定的用例。 Airflow 的监控和报警功能更强大，相比之下，DolphinScheduler 提供了基本的监控和报警功能。 Airflow 具有更灵活的执行模型，允许以顺序或并行的方式执行任务，而 DolphinScheduler 主要支持顺序执行。 Airflow 的优点： 功能丰富：Airflow 提供了诸如 DAG 编排，任务审核，任务监控等功能，并且具有很好的扩展性，可以使用第三方插件扩展其功能。 用户友好：Airflow 提供了一个简单易用的 Web 界面，方便用户进行任务管理和监控。 集成性强：Airflow 在整个 DevOps 生命周期中有良好的集成性，可以方便地与各种数据存储，数据分析，机器学习等工具集成。 Airflow 的缺点： 部署复杂：Airflow 的部署相对比较复杂，对于新手可能有一定的学习曲线。 资源消耗大：由于 Airflow 提供了大量的功能，因此对于资源的消耗也相对较大。 DolphinScheduler 的优点： 部署简单：DolphinScheduler 的部署相对比较简单，易于上手。 资源消耗小：DolphinScheduler 对于资源的消耗相对较小，适合在资源有限的情况下使用。 稳定性高：DolphinScheduler 具有较高的稳定性，可以保证任务的顺利执行。 DolphinScheduler 的缺点： 功能较弱：相对于 Airflow，DolphinScheduler 的功能相对较弱，可能无法满足复杂的任务管理需求。 可扩展性差：DolphinScheduler 可扩展性较差，可能不支持用户希望的一些特殊功能。","categories":[{"name":"python","slug":"python","permalink":"https://cezz.github.io/categories/python/"}],"tags":[]},{"title":"go文件第一行build注释有什么作用？","slug":"go/go文件第一行build注释有什么作用？","date":"2023-02-16T12:13:37.000Z","updated":"2023-05-04T10:36:37.820Z","comments":true,"path":"2023/02/16/go/go文件第一行build注释有什么作用？/","link":"","permalink":"https://cezz.github.io/2023/02/16/go/go%E6%96%87%E4%BB%B6%E7%AC%AC%E4%B8%80%E8%A1%8Cbuild%E6%B3%A8%E9%87%8A%E6%9C%89%E4%BB%80%E4%B9%88%E4%BD%9C%E7%94%A8%EF%BC%9F/","excerpt":"","text":"其专业术语为构建约束，其实不止是go文件，也可以运用在其他文件中。一句话总结其作用就是指定文件的编译场景，若满足条件则编译，反之就不会进行编译。下面进行一个简单的总结，详细内容可以看看官方的设计文档：https://go.googlesource.com/proposal/+/master/design/draft-gobuild.md 什么是构建约束构建约束（build constraint）， 也叫做构建标记（build tag），在源文件中通过注释的方式指定编译环境，若要为不同的编译环境编写不同的go代码，则需要使用构建约束，例如： 1// +build linux 上述的注释行意思是只有在linux环境下才会编译该文件，否则会忽略。其编写格式需要注意以下几点： 可以在任何文件源文件中编写 必须在写在文件顶部附近，可以写多行 为了区别package的文档注释，在约束后必须有空行 其支持类型比较广泛，有以下几种： 指定编译的操作系统：如：windows，linux，darwin（对应runtime.GOOS） 指定架构：如：amd64、386（对应runtime.GOARCH） 指定使用的编译器，如：gccgo、gc 指定go版本，如：go1.17、go1.18 自定义tag，编译时通过指定-tags传入的值 老版本语法在go1.17之前是使用的老版本语法，1.17之后的支持比较完善了。老版本的构建语法为// +build这种形式，可以通过空格、逗号或多行进行组合，例如： 1234// +build linux,386// 上述构建约束表示的是: linux and 386// 逗号表示and, 空格表示or 比较复杂的写法： 123// +build linux,386 darwin,!cgo// 上述构建约束表示的是: (linux and 386) or (darwin and (not cgo)) 也可以分成多行书写： 1234// +build linux darwin// +build amd64// 相当于: (linux or darwin) and amd64 通过上述可见老版本的写法比较复杂，非常容易出错 新版本语法新版的构建约束使用//go:开头： 1//go:build 新版本语法有以下几点需要注意： //和go:之间不能有空格 使用的是布尔表达式，而不是逗号和空格等 一个文件只能有一行构建语句，而不是像老版那样支持多行 例如linux and 386现在这样写： 1//go:build linux &amp;&amp; 386 新的语法主体未Go spec的EBNF标记： 1234567BuildLine = &quot;//go:build&quot; ExprExpr = OrExprOrExpr = AndExpr &#123; &quot;||&quot; AndExpr &#125;AndExpr = UnaryExpr &#123; &quot;&amp;&amp;&quot; UnaryExpr &#125;UnaryExpr = &quot;!&quot; UnaryExpr | &quot;(&quot; Expr &quot;)&quot; | tagtag = tag_letter &#123; tag_letter &#125;tag_letter = unicode_letter | unicode_digit | &quot;_&quot; | &quot;.&quot; 也就是说，构建标记的语法与当前形式保持不变，但构建标记的组合现在使用Go的||, &amp;&amp;, !运算符和括号完成。","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"}],"tags":[]},{"title":"MySQL中的几类日志","slug":"数据库/MySQL中几类日志","date":"2023-02-05T11:07:58.000Z","updated":"2023-05-04T10:33:29.385Z","comments":true,"path":"2023/02/05/数据库/MySQL中几类日志/","link":"","permalink":"https://cezz.github.io/2023/02/05/%E6%95%B0%E6%8D%AE%E5%BA%93/MySQL%E4%B8%AD%E5%87%A0%E7%B1%BB%E6%97%A5%E5%BF%97/","excerpt":"","text":"先简单对三大日志进行总结： mysql innodb引擎使用redo log(重做日志)保证事务的持久性，使用undo log(回滚日志)保证事务的原子性 mysql的数据备份，主备，主主，主从都离不开binlog，需要依靠binlog来同步数据，保证数据的一致性 除三大日志外，还有relay log(中继日志)，slow query log(慢查询日志)，error log(错误日志等) redo log 作用：确保事务的持久性。redo日志记录事务执行后的状态，用来恢复未写入data file的已成功事务更新的数据。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。 内容：物理格式的日志，记录的是物理数据页面的修改信息，其redo log是顺序写入其物理文件中的。 Q：什么时候产生？在事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入redo log文件中。 Q：什么时候释放？当对应事务的脏页写入到磁盘之后，redo log的使命也就完成了，重做日志占用的空间就可以重用(被覆盖)。 Q：对应的物理文件？默认情况下，对应的物理文件位于数据库的data目录下的ib_logfile1&amp;ib_logfile2innodb_log_group_home_dir指定日志文件组所在的路径，默认为.&#x2F;innodb_log_files_in_group指定重做日志文件组中文件的数量，默认为2另外还有其他参数等innodb_log_file_size、innodb_mirrored_log_groups undo log 作用：保证数据的原子性，保证了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读(MVCC)，也即非锁定读。 内容：逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从物理页面上操作实现的，这一点是不同于redo log的。 Q：什么时候产生?事务开始之前，将当前的版本生成undo log，undo也会产生redo来保证undo log的可靠性。 Q：什么时候释放?当事务提交之后，undo log并不能立马被删除，而是放入待清理的链表，由purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log的日志空间。 Q：对应的物理文件？mysql5.6之前，undo表空间位于共享表空间的回滚段中，共享表空间的默认名称是ibdata，位于数据文件目录中。mysql5.6之后，undo表空间可以配置成独立的文件，但是提前需要在配置文件中配置，完成数据库初始化后生效且不可改变undo log文件的个数。如果初始化数据库之前没有进行相关配置，那么就无法配置成独立的表空间了。mysql5.7之后的独立undo表空间配置参数如下：innodb_undo_directory=/data/undospace/存放目录innodb_undo_logs=128回滚段为128KBinnodb_undo_tablespaces=4指定有4个undo log文件若是使用共享表空间，则由innodb_data_file_path配置 binlog 作用：用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步，保证数据的一致性。用于数据库的基于时间点的还原。 内容：逻辑格式的日志，可以简单认为就是执行过的事务中的sql语句。但又不完全是sql语句这么简单，而是包括了执行的sql语句反向的信息，意味着delete对应着delete本身和其反向的insert。可以使用mysqlbinlog解析binlog。 Q：什么时候产生？事务提交的时候，一次性将事务中的sql语句(一个事务可能对应多个sql语句)按照一定的格式记录到binlog中。 Q：什么时候释放？binlog默认保持时间由参数expire_logs_day配置，对于非活动的日志文件，在生成时间超过该配置的天数之后，会被自动删除。 Q：对应的物理文件？配置的文件的路径为log_bin_basename，binlog日志文件按照指定大小，当日志文件达到指定大小后进行滚动更新，生成新的日志文件。对于每个binlog日志文件，通过一个统一的index文件来组织。","categories":[{"name":"数据库","slug":"数据库","permalink":"https://cezz.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"tags":[]},{"title":"使用Github Action自动化部署Hexo","slug":"其他/使用Github Action自动化部署Hexo","date":"2023-01-15T06:22:02.000Z","updated":"2023-05-04T10:29:11.854Z","comments":true,"path":"2023/01/15/其他/使用Github Action自动化部署Hexo/","link":"","permalink":"https://cezz.github.io/2023/01/15/%E5%85%B6%E4%BB%96/%E4%BD%BF%E7%94%A8Github%20Action%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2Hexo/","excerpt":"","text":"本文基于已经创建了hexo的基础，向github action自动化部署迈进。出于长远考虑，还是应当将blog结合CI进行完善。避免存放hexo源码的电脑重装或者更换带来的不变。下面将记录自己的部署过程。 准备工作 创建Token 为了确保由github action持续部署时，其拥有足够的权限进行hexo deploy的相关操作，需提前创建好token。登录并访问Github-&gt;头像(右上角)-&gt;Settings-&gt;Developer Settings-&gt;Persional access tokens-&gt;Tokens (classic)，点击generate new token，token名和过期时间自定义，必须勾选repo和workflows。 注：创建完成的access token只会显示一次，切记先拷贝下来。忘了只能重新创建。 创建项目 共需创建两个项目（当然也可存放与不同分支，修改workflow的配置即可）：一个私有项目，用于存放hexo博客源码，以**blog**命名。一个公有项目，用于存放静态页面，以**test.github.io**命名。 编写workflow的配置文件 在本地hexo博客项目路径的.github文件新建workflows文件夹，再在文件夹workflows文件夹内新建autodeploy.yml文件，内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465# 当有改动推送到master分支时，启动Actionname: Auto Depolyon: push: branches: - master #2020年10月后github新建仓库默认分支改为main，注意更改 release: types: - publishedjobs: deploy: runs-on: ubuntu-latest steps: - name: Checkout source uses: actions/checkout@v2 with: ref: master #2020年10月后github新建仓库默认分支改为main，注意更改 - name: Setup Node.js uses: actions/setup-node@v1 with: node-version: &quot;16.16&quot; #action使用的node版本，建议大版本和本地保持一致。可以在本地用node -v查询版本号。 - name: Install hexo run: | export TZ=&#x27;Asia/Shanghai&#x27; npm install hexo-cli -g - name: Cache hexo uses: actions/cache@v1 id: cache with: path: node_modules key: $&#123;&#123;runner.OS&#125;&#125;-$&#123;&#123;hashFiles(&#x27;**/package-lock.json&#x27;)&#125;&#125; - name: Install dependencies if: steps.cache.outputs.cache-hit != &#x27;true&#x27; run: | npm install hexo-wordcount hexo-generator-json-content hexo-generator-feed hexo-generator-sitemap hexo-generator-baidu-sitemap --save - name: Generate static files run: | hexo clean hexo generate - name: Depoly to Github Pages #此处master:master 指从本地的master分支提交到远程仓库的master分支，若远程仓库没有对应分支则新建一个。如有其他需要，可以根据自己的需求更改。 env: GIT_NAME: cezz-rm GIT_EMAIL: $&#123;&#123; vars.GITHUBS_EMAIL &#125;&#125; GIT_TOKEN: $&#123;&#123; vars.GITHUBS_TOKEN &#125;&#125;# REPO: github.com/cezz-rm/$&#123;&#123; env.GITHUBS_PAGENAME &#125;&#125;.github.io.git run: | export TZ=&#x27;Asia/Shanghai&#x27; cd ./public git init git config --global user.name &#x27;$&#123;&#123; vars.GITHUBS_USERNAME &#125;&#125;&#x27; git config --global user.email &#x27;$&#123;&#123; vars.GITHUBS_EMAIL &#125;&#125;&#x27; git add . git commit -m &quot;$&#123;&#123; github.event.head_commit.message &#125;&#125; $(date +&quot;%Z %Y-%m-%d %A %H:%M:%S&quot;) Updated By Github Actions&quot; git push --force --quiet &quot;https://$&#123;&#123; vars.GITHUBS_USERNAME &#125;&#125;:$&#123;&#123; vars.GITHUBS_TOKEN &#125;&#125;@github.com/$&#123;&#123; vars.GITHUBS_USERNAME &#125;&#125;/$&#123;&#123; vars.GITHUBS_PAGENAME &#125;&#125;.github.io.git&quot; master:master# git push --force --quiet &quot;https://$&#123;&#123; env.TOKENUSER &#125;&#125;:$&#123;&#123; env.CODINGTOKEN &#125;&#125;@e.coding.net/$&#123;&#123; env.CODINGUSERNAME &#125;&#125;/$&#123;&#123; env.CODINGBLOGREPO &#125;&#125;.git&quot; master:master #coding部署写法，需要的自行取消注释# git push --force --quiet &quot;https://$&#123;&#123; env.GITEEUSERNAME &#125;&#125;:$&#123;&#123; env.GITEETOKEN &#125;&#125;@gitee.com/$&#123;&#123; env.GITEEUSERNAME &#125;&#125;/$&#123;&#123; env.GITEEUSERNAME &#125;&#125;.git&quot; master:master #gitee部署写法，需要的自行取消注释 注：配置文件中的分支需与实际情况相对应。 blog项目配置来到仓库下的Settings-&gt;Secrets and variables-&gt;Actions，切换到Variables， 点击New repository variable，新建以下四个变量： **GITHUBS_USERNAME**：gihub的用户名。 **GITHUBS_EMAIL**：电子邮箱，运行失败会有邮件推送。 **GITHUBS_PAGENAME**：test.github.io中的test，按实际情况填写。 **GITHUBS_TOKEN**：填写准备工作中创建的token。 test.github.io项目配置来到仓库下的Settings-&gt;Pages下，进行如下相关配置，有域名可绑定域名。 测试验证来到本地存放blog源代码的路径，创建新的文章提交。参考命令如下： 123git add .git commit -m &quot;add new blog&quot;git push origin master 去页面上点击该仓库的Actions，可以看到记录了每一次的过程，点击其中一条查看如下：","categories":[{"name":"其他","slug":"其他","permalink":"https://cezz.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[]},{"title":"vim和echo修改文件的区别","slug":"其他/vim和echo修改文件的区别","date":"2023-01-08T02:39:11.000Z","updated":"2023-05-04T10:18:54.946Z","comments":true,"path":"2023/01/08/其他/vim和echo修改文件的区别/","link":"","permalink":"https://cezz.github.io/2023/01/08/%E5%85%B6%E4%BB%96/vim%E5%92%8Cecho%E4%BF%AE%E6%94%B9%E6%96%87%E4%BB%B6%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"背景最近研究filebeat的时候，发现每次修改文件后输出的是文件的全量内容，与自己期望的不太一样，然后又翻看了相关的文章，快速过了下官方文档。得出一个结论，filebeat默认应该是输出的文件增量内容才对，经群里小伙伴的提示才反应过来，问题是不是出在修改文件的方式？果不其然，我个人调试的时候使用的是vim修改文件新增内容的，换成echo的方式后，达到了期望的结果。那么为什么vim不行呢？ 什么是inode？每个文件有一个inode标识，操作系统通过inode的号码来识别不同的文件。unix&#x2F;linux系统内部不使用文件名来识别文件，文件名只是inode号码便于识别的别称。表面上，用户通过文件名打开文件，而实际系统内部将这个过程分为三步： 首先找到这个文件名对应的inode号码 其次通过inode号码获取inode信息 最后根据inode信息，找到文件数据所在的block，读出数据 查看文件的inode信息可以使用下述命令： 123456789(venvStudy) [root@node1 filebeat-8.5.2-linux-x86_64]# stat test.json File: ‘test.json’ Size: 963 Blocks: 8 IO Block: 4096 regular fileDevice: fd01h/64769d Inode: 1845136 Links: 1Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root)Access: 2022-11-14 21:28:48.542300958 +0800Modify: 2022-11-14 21:28:48.542300958 +0800Change: 2022-11-14 21:28:48.546301002 +0800 Birth: - 猜测使用vim应该是修改inode，而使用echo则不会。 验证使用vim修改文件内容后，查看文件的inode如下： 1234567891011(venvStudy) [root@node1 filebeat-8.5.2-linux-x86_64]# vim test.json(venvStudy) [root@node1 filebeat-8.5.2-linux-x86_64]# stat test.json File: ‘test.json’ Size: 882 Blocks: 8 IO Block: 4096 regular fileDevice: fd01h/64769d Inode: 1845742 Links: 1Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root)Access: 2022-11-14 21:35:14.155696874 +0800Modify: 2022-11-14 21:35:14.155696874 +0800Change: 2022-11-14 21:35:14.167697004 +0800 Birth: - 而使用echo修改文件内容后，查看文件的inode如下： 1234567891011(venvStudy) [root@node1 filebeat-8.5.2-linux-x86_64]# echo &#x27;xxxxx&#x27; &gt;&gt; ./test.json(venvStudy) [root@node1 filebeat-8.5.2-linux-x86_64]# stat test.json File: ‘test.json’ Size: 963 Blocks: 8 IO Block: 4096 regular fileDevice: fd01h/64769d Inode: 1845742 Links: 1Access: (0644/-rw-r--r--) Uid: ( 0/ root) Gid: ( 0/ root)Access: 2022-11-14 21:35:14.155696874 +0800Modify: 2022-11-14 21:37:20.004064506 +0800Change: 2022-11-14 21:37:20.004064506 +0800 Birth: - 确实发现使用vim的话，inode改变了。使用echo则inode保持不变。 调试通过inotifywait监控一下文件的变化，该命令位于inotify-tools下，需要单独安装。源码编译安装的涉及到的命令如下： 123456wget http://github.com/downloads/rvoicilas/inotify-tools/inotify-tools-3.14.tar.gztar zxvf inotify-tools-3.14.tar.gzcd inotify-tools-3.14./configuremakemake install 其他安装方式见官方文档：https://github.com/rvoicilas/inotify-tools/wiki#wiki-getting参数说明： -m：持续监视变化 -r：使用递归形式监视目录 -q：减少冗余信息，只打印出需要的信息 -e：指定要监视的事件列表 –timefmt：指定时间的输出格式 –format：指定文件变化的详细信息 当使用vim修改文件内容时，inotifywait的输出如下： 123456789[root@node1 filebeat-8.5.2-linux-x86_64]# inotifywait -rm ./test.jsonSetting up watches. Beware: since -r was given, this may take a while!Watches established../test.json OPEN./test.json ACCESS./test.json CLOSE_NOWRITE,CLOSE./test.json MOVE_SELF./test.json ATTRIB./test.json DELETE_SELF 发现最后有DELETE_SELF的操作，此时再修改文件内容时，已经无法监听到了，需要重新监听。当使用echo修改文件内容时： 123456[root@node1 filebeat-8.5.2-linux-x86_64]# inotifywait -rm ./test.jsonSetting up watches. Beware: since -r was given, this may take a while!Watches established../test.json OPEN./test.json MODIFY./test.json CLOSE_WRITE,CLOSE echo只是对文件进行了修改另外可以监听整个目录的变化，能看到更多信息： 12345678910111213141516171819202122232425262728293031323334353637383940414243# 使用vim修改发生的变化[root@node1 filebeat-8.5.2-linux-x86_64]# inotifywait -rm ./Setting up watches. Beware: since -r was given, this may take a while!Watches established../ OPEN test.json./ CREATE .test.json.swp./ OPEN .test.json.swp./ CREATE .test.json.swx./ OPEN .test.json.swx./ CLOSE_WRITE,CLOSE .test.json.swx./ DELETE .test.json.swx./ CLOSE_WRITE,CLOSE .test.json.swp./ DELETE .test.json.swp./ CREATE .test.json.swp./ OPEN .test.json.swp./ MODIFY .test.json.swp./ ATTRIB .test.json.swp./ CLOSE_NOWRITE,CLOSE test.json./ OPEN test.json./ ACCESS test.json./ CLOSE_NOWRITE,CLOSE test.json./ OPEN,ISDIR./ CLOSE_NOWRITE,CLOSE,ISDIR./ OPEN,ISDIR./ CLOSE_NOWRITE,CLOSE,ISDIR# 打开文件会看到上述信息, 修改内容并保存时输出下面的内容./ CREATE 4913./ OPEN 4913./ ATTRIB 4913./ CLOSE_WRITE,CLOSE 4913./ DELETE 4913./ MOVED_FROM test.json./ MOVED_TO test.json~./ MODIFY .test.json.swp./ CREATE test.json./ OPEN test.json./ MODIFY test.json./ CLOSE_WRITE,CLOSE test.json./ ATTRIB test.json./ MODIFY .test.json.swp./ DELETE test.json~ 发现保存的时候执行了MOVED_TO test.json~，并新建了一个test.json文件。 有没有什么方式使用vim但是也不会修改inode呢？有两种方式： 和文件权限有关：chmod o+w test.json 修改vim设置，关闭其备份：set nobackup nowritebackup，关闭后保存时不会生成test.json~文件 总结 vim修改是产生了新的文件，inode发送了改变，而echo不会。 vim保存时会产生带~后缀的文件，这个文件是保存时生成，正常保存该文件会被立即删除 若文件其他用户有write权限(chmod o+w xxx)，vim编辑时inode不会发生改变 关闭vim备份时，inode信息也不会发生改变","categories":[{"name":"其他","slug":"其他","permalink":"https://cezz.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[]},{"title":"2022总结","slug":"其他/2022总结","date":"2022-12-28T14:47:21.000Z","updated":"2023-05-04T10:08:54.621Z","comments":true,"path":"2022/12/28/其他/2022总结/","link":"","permalink":"https://cezz.github.io/2022/12/28/%E5%85%B6%E4%BB%96/2022%E6%80%BB%E7%BB%93/","excerpt":"","text":"工作与学习这一年比较笼统，回头来感觉做了很多又很多都没做。不过值得庆幸的是坚持整理了自己的博客，也算是学习过程的记录，虽然质量数量都比较一般，不过对比前几年感觉好多了，前几年也有断断续续的写了些，但更像草稿般，只有自己看得懂的那种。到了年底翻一翻这一年来的博客，还是颇有感慨。未来的一年也必须得坚持下去！ 工作上印象比较深的一件事是被拉去参加了护网行动，主要工作基于suricata写一些漏洞或工具特征的流量检测规则，还是有不小的收获，对抓包分析越来越熟了，还有初步学习了sqlmap，pocsuite3，冰蝎等之前自己没有用过的工具。不过还是要吐槽下工作那几天，当时正值夏天周末去加班的时候缺没有空调，真是热的不行。 感觉自己今年最大的学习成果不是说学会了什么什么，而是学习的思维上不一样了，能够更加看透一些本质问题，快速的掌握新的东西，但是不足的地方也很多，一个是还不够深入，另一个是不同知识点之间的整合，灵活性还不够。之和结合工作和私下的学习再加强吧。 生活今年的疫情也是断断续续，依旧是每隔三天都要做一次核酸，有一次北京的比较严重好几个区都居家办公了大概两周的时间(没记错的话是在5月的时候)，不过没想到到年底政策有所改变，已经放开了。真是来了个大转变让人猝不及防，自己也成了第一波中招的人，当时也挺无助的，没有退烧药、体温计和抗原，可以说什么都没准备好。第一时间还不知道是不是阳了，硬是顶着持续不断的头疼上了一天班，后续有舍友给了连花清瘟和抗原，真是雪中送炭，非常感谢。 另外在9月的时候房子也快到期了，还出去找了一段时间的房子，最终也没有选择公司附近的，还是太贵了三千多一间还只有10平左右。最终还是续租了，虽然算下来加上交通费一个月也没便宜多少，但是想着习惯了周边环境，加上自己的东西变得越来越多了，也就懒得搬了。另外还得提一句在前几天得知另外一个合租两年多的广东室友准备退租回老家了，自己内心也是十分感慨自己未来的出路，不过走一步看一步吧。 还有就是今年的世界杯印象比较深刻，在同事的带领下之前从来不看足球的我居然也完整的看了几场，或许是买了10块20块的原因，参与感十足，不过比赛确实非常精彩。 最后值得一提的自从去年慢慢的入了海贼手办的坑，目前已经买了十多套海贼王的wcf，谁能想到一个小小的手办居然还挺贵，放在一起倒挺壮观的，有时候从柜子里拿出来看看盒子还挺开心。比较可惜的由于租房的空间不是很大，我只零散的拆了一两个，以后整租的时候再每天拆上一个吧，泪目。另外由于摆放不下的原因，海贼手办界的天花板popmax也暂时放弃了，不知道未来我的第一个popmax是谁。慢慢的期待后续手办作品吧，不敢想象海贼完结的那一天！ 明年的计划 学习某些新技术的时候坚持整理总结，输出文章，每月至少3篇吧！ 快速过下java，再把前端的技术点捡回来，页面上的是最直观的，便于我之后在写点什么页面吧 时间充裕的话还想学下日语，海贼火影死神龙珠妖尾可都是青春 有机会整租一个吧 健身！健身！健身！ 如果允许的话我还想找个女朋友，哈哈 写这个总结感觉比较零碎，感觉加上时间线会好很多，这就得平常就开始积累，而不是年底写了，立个flag吧，23年的总结加上时间线！条件允许的话再上点照片。","categories":[{"name":"其他","slug":"其他","permalink":"https://cezz.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[]},{"title":"Nginx配置basic-auth","slug":"其他/Nginx配置basic-auth","date":"2022-12-16T15:03:45.000Z","updated":"2023-05-04T10:05:51.070Z","comments":true,"path":"2022/12/16/其他/Nginx配置basic-auth/","link":"","permalink":"https://cezz.github.io/2022/12/16/%E5%85%B6%E4%BB%96/Nginx%E9%85%8D%E7%BD%AEbasic-auth/","excerpt":"","text":"在部署web应用服务后，很多场景下需要进行身份认证和访问控制的相关配置，只有在访问者输入了正确的用户密码才允许访问web内容。在这里记录下nginx的简单配置，基于模块ngx_http_auth_basic_module通过使用HTTP基本认证协议验证用户名和密码来限制对资源的访问。 Nginx认证配置实例 1. 生成认证文件123# printf &quot;test:$(openssl passwd -crypt 123456)\\n&quot; &gt;&gt;/home/htpasswd# cat /home/htpasswd test:xyJkVhXGAZ8tM 2. 配置nignx.conf文件123456789server&#123; listen 38443; location / &#123; auth_basic &quot;Please enter your username and password&quot;; auth_basic_user_file /home/htpasswd; autoindex on; &#125;&#125; 3. 重启nginx并验证1234/etc/init.d/nginx restartnginx -t # 测试配置是否有误nginx -s reload # 载入配置文件 指定目录设置访问认证 1. 创建类htpassswd文件1wget -c https://www.moerats.com/usr/down/htpasswd.sh;bash htpasswd.sh 按照提示输入用户名，密码及认证名。脚本会自动生成认证文件。 2. 配置nginx.conf文件12345location ^~ /src/&#123; auth_basic &quot;Authorized users only&quot;; auth_basic_user_file 这里写前面脚本返回的文件路径;&#125; 最后再按照上述方式进行重启验证即可。","categories":[{"name":"其他","slug":"其他","permalink":"https://cezz.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[]},{"title":"(转)Docker网络回顾","slug":"docker/(转)Docker网络回顾","date":"2022-12-11T08:30:09.000Z","updated":"2023-05-04T10:01:57.963Z","comments":true,"path":"2022/12/11/docker/(转)Docker网络回顾/","link":"","permalink":"https://cezz.github.io/2022/12/11/docker/(%E8%BD%AC)Docker%E7%BD%91%E7%BB%9C%E5%9B%9E%E9%A1%BE/","excerpt":"","text":"出自：https://juejin.cn/post/7041923410649153543个人感觉作者这块总结的不错，转载下以便之后个人回顾。 Docker网络基础 docker使用Linux桥接网卡，在宿主机虚拟一个docker容器网桥（docker0），docker启动一个容器时会根据docker网桥的网段分配给容器一个IP地址，称为Container-IP，同时Docker网桥是每个容器的默认网络网关。因为在同一宿主机内的容器都接入同一个网桥，这样容器之间就能够通过容器的Container-IP直接通信。 docker网桥是宿主机虚拟出来的，并不是真实存在的网络设备，外部网络是无法寻址到的，这也意味着外部网络无法通过直接Container-IP访问到容器。 如果容器希望外部访问能够访问到，可以通过映射容器端口到宿主主机(端口映射)，即docker run创建容器时候通过-p或-P参数来启用，访问容器的时候就通过宿主机IP:容器端口访问容器。Docker网络模式 Docker网络模式 配置 说明 host模式 -net&#x3D;host 容器和宿主机共享Network namespace，容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口。 container模式 -net&#x3D;container:Name_or_ID 容器和另外一个容器共享Network namespace。kubernetes中的pod就是多个容器共享一个Network namespace。创建的容器不会创建自己的网卡，配置自己的IP，而是和一个指定的容器共享IP、端口范围。 none模式 -net&#x3D;none 容器有独立的Network namespace，并没有对其进行任何网络设置，如分配veth pair和网桥连接，配置IP等。该模式关闭了容器的网络功能。 bridge模式 -net&#x3D;bridge （默认模式）。此模式会为每一个容器分配、设置IP等，并将容器连接到一个docker0虚拟网桥，通过docker0网桥以及Iptable nat表配置与宿主机通信。 Macvlan network 无 容器具备Mac地址，使其显示为网络上的物理设备 Overlay 无 （覆盖网络）：利用VXLAN实现的bridge模式 Bridge模式默认的网络模式。bridge模式下容器没有一个公有ip,只有宿主机可以直接访问,外部主机是不可见的,但容器通过宿主机的NAT规则后可以访问外网。 Bridge桥接模式的实现步骤 Docker Daemon利用veth pair技术，在宿主机上创建两个虚拟网络接口设备，假设为veth0 和veth1。而veth pair技术的特性可以保证无论哪一个veth接收到网络报文，都会将报文传输给另一方。 Docker Daemon将veth0附加到Docker Daemon创建的docker0网桥上。保证宿主机的网络报 文可以发往veth0; Docker Daemon 将veth1添加到Docker Container所属的namespace下，并被改名为eth0。 如此一来，保证宿主机的网络报文若发往veth0则立即会被eth0接收，实现宿主机到Docker Container网络的联通性;同时也保证Docker Container单独使用eth0，实现容器网络环境的隔离性。Bridge桥接模式的缺陷Docker Container不具有一个公有IP，即和宿主机eth0不处于同一个网段。导致的结果是宿主机以外的世界不能直接和容器进行通信。 注：eth设备是成双成对出现的，一端是容器内部命名为eth0，一端是加入到网桥并命名的veth(通常命名为veth)，它们组成了一个数据传输通道，一端进一端出，veth设备连接了两个网络设备并实现了数据通信。 Host网络模式 host模式相当于Vmware中的NAT模式，与宿主机在同一个网络中，但没有独立IP地址。 启动容器使用host模式，容器将不会获得一个独立的Network Namespace，而是和宿主机共用一个Network Namespace。 容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口。除此之外容器的其他方面，比如文件系统、进程列表等还是和宿主机隔离。 使用host模式的容器可以直接使用宿主机的IP地址与外界通信，容器内部的服务端口也可以使用宿主机的端口，不需要进行NAT，host最大的优势就是网络性能比较好，docker host上已经使用的端口就不能再用了，网络的隔离性不好。 host网络模式需要在容器创建时指定–network&#x3D;host host模式是bridge桥接模式很好的补充。采用host模式的Docker Container，可以直接使用宿主机的IP地址与外界进行通信，若宿主机的eth0是一个公有IP，那么容器也拥有这个公有IP。同时容器内服务的端口也可以使用宿主机的端口，无需额外进行NAT转换。 host模式可以让容器共享宿主机网络栈,这样的好处是外部主机与容器直接通信,但是容器的网络缺少隔离性。 Host网络模式的缺陷使用Host模式的容器不再拥有隔离、独立的网络环境。虽然可以让容器内部的服务和传统情况无差别、无改造的使用，但是由于网络隔离性的弱化，该容器会与宿主机共享竞争网络栈的使用; 另外，容器内部将不再拥有所有的端口资源，原因是部分端口资源已经被宿主机本身的服务占用，还有部分端口已经用以bridge网络模式容器的端口映射。 Container网络模式Container网络模式没有改善容器与宿主机以外世界通信的情况(和桥接模式一样，不能连接宿主机以外的其他设备)。这个模式指定新创建的容器和已经存在的一个容器共享一个Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的IP，而是和一个指定的容器共享IP、端口范围等。 同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过lo网卡设备通信。 None模式使用none模式，Docker容器拥有自己的Network Namespace，但是，并不为Docker容器进行任何网络配置。Docker容器没有网卡、IP、路由等信息。需要我们自己为Docker容器添加网卡、配置IP等。这种网络模式下容器只有lo回环网络，没有其他网卡。none模式可以在容器创建时通过– network&#x3D;none来指定。这种类型的网络没有办法联网，封闭的网络能很好的保证容器的安全性 网络基本用法（这部分稍作改动）。 镜像拉取与容器创建12345# 拉取镜像docker pull nginx:1.19.3-alpine# 运行镜像docker run -itd -name nginx1 nginx:1.19.3-alpine 其创建流程如下： 创建一对虚拟接口&#x2F;网卡，也就是veth pair，分别放到本地主机和新容器中; 本地主机一端桥接到默认的 docker0 或指定网桥上，并具有一个唯一的名字，如 vetha596da4; 容器一端放到新容器中，并修改名字作为 eth0，这个网卡&#x2F;接口只在容器的名字空间可见; 从网桥可用地址段中(也就是与该bridge对应的network)获取一个空闲地址分配给容器的 eth0，并配置默认路由到桥接网卡 vetha596da4。 容器就可以使用 eth0 虚拟网卡来连接其他容器和其他网络。 如果不指定–network，创建的容器默认都会挂到 docker0 上，使用本地主机上 docker0 接口的 IP 作为 所有容器的默认网关。 多容器之间通讯1234567891011121314docker run -itd -name nginx1 nginx:1.19.3-alpinedocker run -itd -name nginx2 nginx:1.19.3-alpinedocker network inspect bridge# 新建bridge网络, 并将一个运行中的容器连接到该网络docker network create -d bridge test-bridgedocker run -itd -name nginx3 -network test-bridge nginx:1.19.3-alpinedocker network inspect test-bridgedocker network connect test-bridge nginx2 Docker网络命令汇总（这部分稍作改动）。个人感觉这部分有哪些命令不知道的，直接-h看一下或者查阅官方文档是最好的。如下： 1234567891011121314151617[root@node1 ~]# docker network -hFlag shorthand -h has been deprecated, please use --helpUsage: docker network COMMANDManage networksCommands: connect Connect a container to a network create Create a network disconnect Disconnect a container from a network inspect Display detailed information on one or more networks ls List networks prune Remove all unused networks rm Remove one or more networksRun &#x27;docker network COMMAND --help&#x27; for more information on a command.","categories":[{"name":"docker","slug":"docker","permalink":"https://cezz.github.io/categories/docker/"}],"tags":[]},{"title":"naabu源码分析","slug":"go/naabu源码分析","date":"2022-11-18T12:06:18.000Z","updated":"2023-05-04T09:58:02.052Z","comments":true,"path":"2022/11/18/go/naabu源码分析/","link":"","permalink":"https://cezz.github.io/2022/11/18/go/naabu%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","excerpt":"","text":"参数解析1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374使用方法:./naabu-2.1.1 [flags]Flags:INPUT:-host string[] 扫描目标, 支持域名或IP地址-list, -l string 从文件读取扫描目标 (file)-exclude-hosts, -eh string 排除扫描目标, 以逗号分隔-exclude-file, -ef string 从文件读取要排除的扫描目标 (file)PORT:-port, -p string 指定扫描端口 (80,443, 100-200)-top-ports, -tp string 默认top100 (default 100)-exclude-ports, -ep string 需要排除的扫描端口, 以逗号分隔-ports-file, -pf string 从文件读取扫描端口 (file)-port-threshold, -pts int 跳过主机端口扫描的端口阈值 (暂不知道作用)-exclude-cdn, -ec 跳过 CDN 的完整端口扫描 (只检查 80,443)-display-cdn, -cdn 展示正在使用的cdnRATE-LIMIT:-c int general internal worker threads (default 25)-rate int packets to send per second (default 1000)OUTPUT:-o, -output string 指定结果输出文件 (可选参数)-json 以json格式输出结果-csv 以csv格式输出结果CONFIGURATION:-scan-all-ips, -sa 扫描与dns记录的所有ip-ip-version, -iv string[] 指定ipv4还是ipv6 - (default 4)-scan-type, -s string 扫描类型, 默认syn半连接 (SYN/CONNECT)-source-ip string 来源IP端口 (x.x.x.x:yyy)-interface-list, -il 列出可用网卡和公共IP-interface, -i string 指定用于端口扫描的网卡-nmap 直接调用namp扫描, 需注意已标位弃用 (nmap must be installed) - Deprecated-nmap-cli string 对找到的结果运行nmap命令 (example: -nmap-cli &#x27;nmap -sV&#x27;)-r string 自定义域名解析 (comma separated or from file)-proxy string socks5 代理 (ip[:port] / fqdn[:port]-proxy-auth string socks5 代理认证 (username:password)-resume 通过resume.cfg恢复扫描-stream 流模式 (disables resume, nmap, verify, retries, shuffling, etc)-passive 使用shodan的数据接口显示被动开放端口-irt, -input-read-timeout duration 输入超时时间 (default 3m0s)-no-stdin 禁用标准处理HOST-DISCOVERY:-sn, -host-discovery 仅执行主机探活-Pn, -skip-host-discovery 跳过主机探活-ps, -probe-tcp-syn string[] TCP SYN Ping (host discovery needs to be enabled)-pa, -probe-tcp-ack string[] TCP ACK Ping (host discovery needs to be enabled)-pe, -probe-icmp-echo ICMP echo request Ping (host discovery needs to be enabled)-pp, -probe-icmp-timestamp ICMP timestamp request Ping (host discovery needs to be enabled)-pm, -probe-icmp-address-mask ICMP address mask request Ping (host discovery needs to be enabled)-arp, -arp-ping ARP ping (host discovery needs to be enabled)-nd, -nd-ping IPv6 Neighbor Discovery (host discovery needs to be enabled)OPTIMIZATION:-retries int 端口扫描重试次数 (default 3)-timeout int 超时等待时间, 单位为毫秒 (default 1000)-warm-up-time int 扫描阶段之间的时间 (default 2)-ping 进行ping探活-verify 使用tcp再次验证端口DEBUG:-health-check, -hc run diagnostic check up-debug 显示调试信息-verbose, -v 展示详细输出-no-color, -nc 在cli输出禁用着色-silent 在输出中仅展示结果-version 显示naabu的版本-stats 显示运行扫描的状态-si, -stats-interval int 显示统计信息更新之间等待的秒数 (default 5) 目录文件说明123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384├─cmd │ ├─functional-test │ │ │ main.go │ │ │ run.sh │ │ │ testcases.txt │ │ │ │ │ └─test-data │ │ request.txt │ │ │ ├─integration-test │ │ integration-test.go │ │ library.go │ │ │ └─naabu │ main.go │ ├─internal │ └─testutils │ integration.go │ └─pkg ├─israce // 竞争检测 │ norace.go │ race.go │ ├─privileges // 权限判定, 在windows, linux, darwin下是否具有相应的权限, syn扫描或全连接扫描 │ privileges.go │ privileges_darwin.go │ privileges_linux.go │ privileges_win.go │ ├─result │ results.go // 定义Result结构体 │ results_test.go │ ├─routing // 根据不同的操作系统选择不同的路由 │ router.go │ router_darwin.go │ router_linux.go │ router_windows.go │ ├─runner │ banners.go // 控制台输出运行信息, 网络环境, 扫描类型及网卡信息 │ banners_test.go │ default.go // 定义运行时的一些默认值, 如超时, 速率, 重试次数等 │ healthcheck.go // 进行naabu锁依赖的环境运行检查 │ ips.go // ip地址解析, 排除不在设置范围内的 │ ips_test.go │ nmap.go // 解析参数(nmap-cli), 并调用nmap │ nmap_test.go │ options.go // 命令行参数解析到结构体对象Options │ output.go // 定义Result结构体及将结果写文件保存的相关方法 │ output_test.go │ ports.go // 定义常见端口, 以及解析端口的方法 │ ports_test.go │ resume.go // 定义结构体ResumeCfg, 以及保存/读取/删除恢复配置文件 │ runner.go // 定义结构体Runner, 运行调度的核心, 还包括结果的处理等 │ targets.go // 目标对象解析,添加处理等, 保存到runner结构体对象中 │ targets_test.go │ util.go // 主要包括host转ip方法, 以及判断os是否支持的函数 │ util_test.go │ validate.go // 参数校验认证 │ validate_test.go │ ├─scan │ arp.go // arp报文组织发送 │ cdn.go // 检查传入的IP是否为cdn │ cdn_test.go │ connect.go // 建立完整的tcp连接, 用于判断端口是否开放 │ connect_test.go │ externalip.go // 通过公共api获取自己的ip出口地址 │ externalip_test.go │ icmp.go // 几种类型的icmp报文组织 │ ndp.go // ndp报文类型组织 │ option.go // 扫描的配置(超时时间,重试,速率,输出等配置) │ ping.go // ping报文组织及发送 │ ping_test.go │ scan.go // 定义scanner结构体, 另外包括各个扫描部分的调度 │ scan_unix.go // 在linux下 │ tcpsequencer.go // │ tcpsequencer_test.go │ └─utils util.go 源码分析先看下项目依赖 1234567891011121314151617require ( github.com/google/gopacket v1.1.19 // libpcap的go实现 github.com/phayes/freeport v0.0.0-20180830031419-95f893ade6f2 // 获取一个可用于tcp的端口 github.com/projectdiscovery/blackrock v0.0.0-20220628111055-35616c71b2dc // 伪随机的方式访问空间中的元素一次 github.com/projectdiscovery/cdncheck v0.0.4-0.20220322144854-b2d8ce308abb // 检查给定IP是否属于已知cnd范围内 github.com/projectdiscovery/clistats v0.0.8 // 命令行统计信息展示 github.com/projectdiscovery/fdmax v0.0.3 // 动态修改最大文件描述符 github.com/projectdiscovery/fileutil v0.0.3 // 文件处理工具 github.com/projectdiscovery/goflags v0.1.1 // 命令行参数解析 github.com/projectdiscovery/gologger v1.1.4 // 日志处理 github.com/projectdiscovery/iputil v0.0.0-20220712175312-b9406f31cdd8 // 用于处理ips和cidr github.com/projectdiscovery/networkpolicy v0.0.2-0.20220525172507-b844eafc878d // 网络代理 github.com/remeh/sizedwaitgroup v1.0.0 // 速率控制 //go.uber.org/ratelimit v0.2.0 // indirect // 速率控制 golang.org/x/net v0.1.0 // go网络库的补充 golang.org/x/sys v0.1.0 // 与操作系统低级别交互的go补充包) 程序入口cmd/naabu/main.go 12345678910111213141516171819202122232425262728293031323334353637383940414243func main() &#123; // 1. 解析命令行参数或从配置文件读取 options := runner.ParseOptions() // 2. 新建runner naabuRunner, err := runner.NewRunner(options) if err != nil &#123; gologger.Fatal().Msgf(&quot;Could not create runner: %s\\n&quot;, err) &#125; // 3. 读取退出信号, 优雅退出 c := make(chan os.Signal, 1) signal.Notify(c, os.Interrupt) go func() &#123; for range c &#123; // 退出时打印结果 naabuRunner.ShowScanResultOnExit() gologger.Info().Msgf(&quot;CTRL+C pressed: Exiting\\n&quot;) // 若是配置了恢复文件, 则进行恢复 if options.ResumeCfg.ShouldSaveResume() &#123; gologger.Info().Msgf(&quot;Creating resume file: %s\\n&quot;, runner.DefaultResumeFilePath()) err := options.ResumeCfg.SaveResumeConfig() if err != nil &#123; gologger.Error().Msgf(&quot;Couldn&#x27;t create resume file: %s\\n&quot;, err) &#125; &#125; // 退出时关闭runner naabuRunner.Close() os.Exit(1) &#125; &#125;() // 4. 扫描核心 err = naabuRunner.RunEnumeration() if err != nil &#123; gologger.Fatal().Msgf(&quot;Could not run enumeration: %s\\n&quot;, err) &#125; // 5. 完成后清除重启配置 // on successful execution remove the resume file in case it exists options.ResumeCfg.CleanupResumeConfig()&#125; pkg/runner/runner.go 1234567891011121314151617181920212223242526272829303132333435363738func (r *Runner) RunEnumeration() error &#123; ... // 1.如果支持syn半连接扫描 if privileges.IsPrivileged $$ r.options.ScanType == SynScan &#123;...&#125; ... // 2.设置了steam, 没太看懂这个有什么作用, 个人实际运行中添加了该参数会报错 if r.options.Stream&#123;...&#125; ... // 3. 设置并发控制 r.wgscan = sizedwaitgroup.New(r.options.Rate) r.limiter = ratelimit.New(context.Background(), int64(r.options.Rate), time.Second) ... // 4. 若设置了主机探活检测及判断是否支持发送原始数据包 if shouldDiscoverHosts &amp;&amp; shouldUseRawPackets &#123;...&#125; ... // 5. 选择是否为流模式和显示被动开放端口 switch &#123; case r.options.Stream &amp;&amp; !r.options.Passive: ... case r.options.Stream &amp;&amp; r.options.Passive: ... default: ... // 获取目标IP targets, targetsV4, targetsv6, err := r.GetTargetIps(ipsCallback) ... // 若设置了查看进度 // 处理核心 if shouldUseRawPackets &#123; r.RawSocketEnumeration(ip, port) &#125; else &#123; r.wgscan.Add() go r.handleHostPort(ip, port) &#125; &#125; &#125; 主机探活探活的顺序为： Icmp Echo Request Tcmp Timestamp Reqeust Icmp Netmask Request ARP Scan Syn Probes Ack Probes IPv6 NDP","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"}],"tags":[]},{"title":"katana源码分析","slug":"go/katana源码分析","date":"2022-11-09T10:50:29.000Z","updated":"2023-05-04T09:52:49.400Z","comments":true,"path":"2022/11/09/go/katana源码分析/","link":"","permalink":"https://cezz.github.io/2022/11/09/go/katana%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","excerpt":"","text":"个人对该项目比较感兴趣，争取做到时刻保持关注。因为自己也用go实现了类似的爬虫功能，但是一对比就有点相形见绌，故可以从中学到很多东西。目前本文基于katana-0.0.1（2022-11.7）进行分析，同时会关注后续版本。 参数解析参数解析，常用&#x2F;必备参数已加粗 input： -u：指定爬取url，支持string，string[] configuration：基本配置 -d：指定爬取深度，从0开始，默认是2 -jc：解析js和css标签，经测试默认解析了 -ct：指定抓取时间，单位为s -kf：指定是否抓取robots.txt或sitemap.xml文件中的链接 -mrs：解析的最大响应数据大小，默认为mb -timeout：超时时间 -aff：启用可选表单自动填写，暂不清楚有什么作用 -retry：请求重试次数：默认为1 -proxy：设置代理，支持http和socks5 -H：添加自定义请求头，格式为string[] -config：指定配置文件 -fc：指定自定义表单配置文件 headless：无头浏览器模式，linux暂时有点问题(Running as root without –no-sandbox is not supported.) -hl： -sc： sb scope：根据某种规则指定要爬取的url的范围 -cs：根据正则匹配范围内的url -cos：根据正则匹配范围外的url -fs：预定义范围字段，默认为”rdn”，(dn,rdn,fqdn) -ns：禁用基于主机的默认作用域(暂不不知道作用) -do：显示作用域内爬取的外部端点 filter： -f：定义在输出中展示的字段(url,path,fqdn,rdn,rurl,qurl,qpath,file,key,value,kv,dir,udir) -sf：定义在存储是保存的字段(url,path,fqdn,rdn,rurl,qurl,qpath,file,key,value,kv,dir,udir) -em：根据扩展名进行匹配，如php，html，js，理解为include -ef：根据扩展名过滤输出，如png， css，理解为exclude rate-limit： -c：并发数，默认为10 -p：并行数，默认为10 -rd：每个请求之间的请求延迟 -rl：每秒最大请求数，默认为150 -rlm：每分钟发送的最大请求数 output： -o：结果写入到指定文件 -j：以json格式写入 -nc：禁用输出内容着色 -silent：仅显示输出 -v：显示详细输出 -version：显示项目版本号目录文件说明1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586├─cmd│ ├─katana│ │ main.go│ ││ └─tools│ └─crawl-maze-score│ main.go│├─internal│ └─runner│ banner.go 启动时展示的自定义信息│ executer.go 根据并行度(parallelism)调用核心crawl│ options.go 解析命令行参数，进行相应的配置│ runner.go 最外层运行结构体Runner，包含属性crawlerOptions, stdin, crawler(核心), options│└─pkg ├─engine │ │ engine.go │ │ │ ├─common │ │ http.go 封装httpclient，配置transport，timeout，以及checkRedirect(如果绑定了回调，会执行该回调函数) │ │ │ ├─hybrid 两种模式之一(headless) │ │ crawl.go │ │ doc.go │ │ hijack.go │ │ hybrid.go │ │ │ ├─parser │ │ │ parser.go │ │ │ parser_test.go │ │ │ │ │ └─files │ │ request.go 抓取robots.txt或sitemap.xml的入口 │ │ robotstxt.go │ │ robotstxt_test.go │ │ sitemapxml.go │ │ sitemapxml_test.go │ │ │ └─standard 两种模式之一(standard) │ crawl.go 实际发起请求调用httpclient.Do的地方 │ doc.go │ standard.go 核心Crawl │ ├─navigation │ request.go 处理请求url │ response.go 处理响应 │ ├─output │ fields.go 输出字段格式处理 │ fields_test.go │ file_writer.go 写文件 │ format_json.go 处理成json格式 │ format_screen.go 终端输出格式整理 │ output.go write核心，定义了Writer接口 │ ├─types │ crawler_options.go 定义crawler的一些配置，包括公用options │ options.go 定义公用options │ └─utils 工具&#x27;类&#x27; │ formfill.go │ formfill_test.go │ regex.go │ utils.go │ utils_test.go │ ├─extensions │ extensions.go │ extensions_test.go │ ├─filters │ filters.go │ filters_test.go │ simple.go │ ├─queue 广度优先(优先级队列[最小堆])和深度优先(栈[双向链表])，对应两种模式 │ priority_queue.go 优先级队列实现 &quot;container/heap&quot; │ priority_queue_test.go │ queue.go 封装了两种模式，统一对外接口&quot;VarietyQueue&quot; │ stack.go 栈实现 &quot;container/list&quot; │ stack_test.go │ └─scope scope.go scope_test.go 源码分析首先看下项目的依赖：1234567891011121314151617181920212223require ( github.com/PuerkitoBio/goquery v1.8.0 // 页面解析库 github.com/go-rod/rod v0.112.0 // 操作浏览器的工具 github.com/json-iterator/go v1.1.12 // json解析器 github.com/logrusorgru/aurora v2.0.3+incompatible // 终端输出着色 github.com/lukasbob/srcset v0.0.0-20190730101422-86b742e617f3 // 解析HTML5 srcset github.com/pkg/errors v0.9.1 // 第三方异常处理包 github.com/projectdiscovery/fastdialer v0.0.17 // 快速发起请求 github.com/projectdiscovery/fileutil v0.0.3 // 文件处理工具 github.com/projectdiscovery/goflags v0.1.3 // 命令行参数解决 github.com/projectdiscovery/gologger v1.1.4 // 日志处理 github.com/projectdiscovery/hmap v0.0.2-0.20210917080408-0fd7bd286bfa github.com/projectdiscovery/ratelimit v0.0.1 // 并发控制(时间间隔) github.com/projectdiscovery/retryablehttp-go v1.0.2 // 可自动重试的http client github.com/projectdiscovery/stringsutil v0.0.2 // 字符串处理 github.com/remeh/sizedwaitgroup v1.0.0 // 并发控制(同一时间) github.com/rs/xid v1.4.0 // 生成唯一id github.com/shirou/gopsutil/v3 v3.22.10 // 跨平台进程和系统监控 github.com/stretchr/testify v1.8.1 // 测试框架 go.uber.org/multierr v1.8.0 // 多错误处理 golang.org/x/net v0.1.0 // 补充go网络库 gopkg.in/yaml.v3 v3.0.1 // 解析生成yaml数据) 从最简单的命令./katana -u https://tesla.com -d 1开始入手，分析代码的运行流程。程序入口cmd/katana/main.go12345678910111213141516171819202122232425262728293031323334353637var ( cfgFile string // 配置文件 options = &amp;types.Options&#123;&#125; // 基本的设置)func main() &#123; // 1. 读取命令行参数 if err := readFlags(); err != nil &#123; gologger.Fatal().Msgf(&quot;Could not read flags: %s\\n&quot;, err) &#125; // 2. 新建一个runner对象, 包含爬虫配置, 基本配置, 输入, 及爬虫核心 runner, err := runner.New(options) if err != nil || runner == nil &#123; gologger.Fatal().Msgf(&quot;could not create runner: %s\\n&quot;, err) &#125; defer runner.Close() // 3. 接收退出信号关闭整个channel // close handler go func() &#123; c := make(chan os.Signal, 1) signal.Notify(c, os.Interrupt, syscall.SIGTERM) go func() &#123; &lt;-c gologger.DefaultLogger.Info().Msg(&quot;- Ctrl+C pressed in Terminal&quot;) runner.Close() os.Exit(0) &#125;() &#125;() // 4. 爬虫执行ExecuteCrawling if err := runner.ExecuteCrawling(); err != nil &#123; gologger.Fatal().Msgf(&quot;could not execute crawling: %s&quot;, err) &#125;&#125; 接下来看看runner的New和Close做了什么，在internal/runner/runner.go下： 注：之后只会贴出核心逻辑，其他代码将会省去。 12345678910111213141516171819202122232425262728// 先熟悉Runner结构体type Runner struct &#123; crawlerOptions *types.CrawlerOptions // 爬虫的相关设置, 如输出, 限速等 stdin bool // 是否有输入(具体作用待定) crawler engine.Engine // 爬虫核心, 实现了Crawl(string) error和Close() error接口 options *types.Options // 基本的设置, 从命令行读取的参数都保存在该结构体对象中&#125;func New(options *types.Options) (*Runner, error) &#123; ... // 1. 创建爬虫的相关设置对象 crawlerOptions, err := types.NewCrawlerOptions(options) ... // 2. 选择不同的模式, 一种是Headless, 一种是standard标准模式 carwler, err = hybrid.New(crawlerOptions) ... crawler, err = standard.New(crawlerOptions) ...&#125;func (r *Runner) Close() error &#123; // TODO: 这里用到了多错误处理模块multierr, 之后在进一步学学 return multierr.Combine( r.crawler.Close(), r.crawlerOptions.Close(), )&#125; 爬虫核心接下来就到了核心部分，只要实现了文件pkg/engine/engine.go中的接口Engine就可以嵌入自己的爬虫，之后主要分析标准模式下的实现。 12345678910111213141516171819202122232425// Engine的实现如下, 所处文件位于pkg/engine/engine.gotype Engine interface &#123; Crawl(string) error Close() error&#125;// 统一外部调用的方法ExecuteCrawling实现如下, 所处文件位于internal/runner/executer.gofunc (r *Runner) ExecuteCrawling() error &#123; // 1. 解析输入的url列表, 返回的数据类型为[]string inputs := r.parseInputs() ... // 2. 这里使用了并行参数Parallelism(-p)创建了几个调用Crawl方法的goroutine wg := sizedwaitgroup.New(r.options.Parallelism) for _, input := range inputs &#123; wg.Add() go func(input string) &#123; defer wg.Done() // 3. 调用具体的Crawl方法 r.crawler.Crawl(input) &#125;(input) &#125; wg.wait() ...&#125; 现在来看看标准模式下的Crawl的具体实现，位于文件pkg/engine/standard/standard.go下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556func (c *Crawler) Crawl(rootURL string) error &#123; // 1. 解析根url parsed, err := url.Parse(rootURL) ... // 2. 创建队列, 这里根据配置文件中的设置广度优先还是深度优先 // 广度优先使用的优先级队列, 深度优先使用的是栈 // 这里返回的结构体VarietyQueue对象的指针 queue := queue.New(c.options.Options.Strategy) // 将进一步封装的请求结构体navigation.Request放入到队列中 queue.Push(navigation.Request&#123;Method: http.MethodGet, URL: rootURL, Depth: 0&#125;, 0) // 解析响应的回调函数, 会将新的url封装成navigation.Request后放入到队列 parseResponseCallback := c.makeParseResponseCallback(queue) ... // 3. 若是指定了参数knownFiles(-kf), 会调用该方法 parseResponseCallback(nr) ... // 4. 使用retryablehttp新建httpclient, 这里需注意的是传进去的参数func绑定到了httpclient的属性CheckRedirect下 // httpclient.Do会调用标准库下httpclient的Do方法, 进而调用CheckRedirect httpclient, _, err := common.BuildClient(c.options.Dialer, c.options.Options, func(resp *http.Response, depth int) &#123; body, _ := io.ReadAll(resp.Body) reader, _ := goquery.NewDocumentFromReader(bytes.NewReader(body)) // 解析响应, 这里分为三大类, 主要是响应头解析, 响应体解析及js的一些解析 // 然后将回调函数parseResponseCallback传进去, 这里深度+1 // 整体而言这部分设计较为巧妙, 之后可深入研究下 parser.ParseResponse(navigation.Response&#123;Depth: depth + 1, Options: c.options, RootHostname: hostname, Resp: resp, Body: body, Reader: reader&#125;, parseResponseCallback) &#125;) ... // 5. 消费队列里构造的消息(navigation.Request) // 使用了sizedwaitgroup限制并发数, 具体值来自参数Concurrency(-c) // TODO: 注意这里还使用了atomic来标识任务的执行状态，之后再看看 wg := sizedwaitgroup.New(c.options.Options.Concurrency) ... for &#123; // 出队消息 item := queue.Pop() req, ok := item.(navigation.Request) ... wg.Add() go func() &#123; defer wg.Done() ... // 控制每秒最大并发数 c.options.RateLimit.Take() ... // 实际发起http request的方法, 返回的是navigation.Response结构体对象 resp, err := c.makeRequest(ctx, req, hostname, req.Depth, httpclient) ... // 对响应进行解析 parser.ParseResponse(resp, parseResponseCallback) &#125;() &#125;&#125; 最后再来看看发起请求makeRequest与解析响应ParseResponse都做了哪些事吧。 123456789101112131415161718192021222324252627282930313233// makeRequest 位于文件pkg/engine/standard/crawl.go下func (c *Crawler) makeRequest(ctx context.Context, request navigation.Request, rootHostname string, depth int, httpclient *retryablehttp.Client) (navigation.Response, error) &#123; ... // 1. 将当前深度传入到上下文中, 并封装request请求 ctx = context.WithValue(ctx, navigation.Depth&#123;&#125;, depth) httpReq, err := http.NewRequestWithContext(ctx, request.Method, request.URL, nil) ... // 2. 发起请求, 最终会调用标准库的Do方法 resp, err := httpclient.Do(req) ... // 3. 读取响应得限制大小, 也可通过参数设置(-mrs) limitReader := io.LimitReader(resp.Body, int64(c.options.Options.BodyReadSize)) data, err := io.ReadAll(limitReader) ... return response, nil&#125;// ParseResponse 位于文件pkg/engine/parser/parser.gofunc ParseResponse(resp navigation.Response, callback func(navigation.Request)) &#123; // responseParsers存的是结构体responseParser, 包含两个属性 // 一个是解析类型parserType, 一个是解析函数parserFunc // 注: 一开始注册的响应回调函数是在具体的parserFunc中执行的 for _, parser := range responseParsers &#123; switch &#123; case parser.parserType == headerParser &amp;&amp; resp.Resp != nil: parser.parserFunc(resp, callback) case parser.parserType == bodyParser &amp;&amp; resp.Reader != nil: parser.parserFunc(resp, callback) case parser.parserType == contentParser &amp;&amp; len(resp.Body) &gt; 0: parser.parserFunc(resp, callback) &#125; &#125;&#125; 结果输出写结果是在makeParseResponseCallback中调用的，正好上面只是一笔带过，下面详细分析下，该方法位于文件pkg/engine/standard/standard.go下： 1234567891011121314151617func (c *Crawler) makeParseResponseCallback(queue *queue.VarietyQueue) func(nr navigation.Request) &#123; return func(nr navigation.Request) &#123; ... // 1. 如果是空url或者重复的url直接return if !c.options.UniqueFilter.UniqueURL(nr.RequestURL()) &#123;return&#125; ... // 2. 对结果url进行验证过滤后写入到输出中, result为output.Result结构体对象 c.options.OutputWriter.Write(result) ... // 3. 如果当前深度大于设置的最大深度或没在范围内则直接返回, 否则将其放入队列中 if nr.Depth &gt;= c.options.Options.MaxDepth || !scopeValidated &#123; return &#125; queue.Push(nr, nr.Depth) &#125;&#125; 总结目前只是过了一下standard模式下程序的运行流程，之后再分析下headless下所做的工作，初次之外项目里还做了很多其他的操作，比如选择url范围，过滤，解析等等，要深入了解可以自己参照着实现一个，也是学习效率最快的方式了吧。顺便一提我个人运行headless模式时，报了个Running as root without --no-sandbox is not supported的错误，当时想着之后有时间再折腾折腾，没想到官方发布了0.0.2版本把这个问题修复了，不得不感叹效率之高。","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"}],"tags":[]},{"title":"记一次oracle数据备份还原的操作","slug":"其他/记一次oracle数据备份还原的操作","date":"2022-10-20T15:01:43.000Z","updated":"2023-02-05T16:53:01.597Z","comments":true,"path":"2022/10/20/其他/记一次oracle数据备份还原的操作/","link":"","permalink":"https://cezz.github.io/2022/10/20/%E5%85%B6%E4%BB%96/%E8%AE%B0%E4%B8%80%E6%AC%A1oracle%E6%95%B0%E6%8D%AE%E5%A4%87%E4%BB%BD%E8%BF%98%E5%8E%9F%E7%9A%84%E6%93%8D%E4%BD%9C/","excerpt":"","text":"背景 oracle版本：12.2.0 目的：将一个用户的表结构和数据复制到另一个用户下(全量备份) 当前环境为虚拟机，已提前做好快照，避免中途出现问题 如果对oracle不熟，最好还是了解下用户，表空间和表之间的关系 数据备份和数据还原下仅列出主要命令，调试用到的命令见其他数据备份1. 管理员登录1sqlplus sys/123456@orcl as sysdba; 2. 创建备份目录123select * from dba_directories;create directory backup as &#x27;d:\\backup&#x27;; 3. 赋于要导出数据表所属用户权限1grant read,write on directory backup to C##USER1; 4. 数据备份1expdp C##USER1/123456@orcl directory=backup dumpfile=backup.dmp logfile=export.log 数据备份并没有遇到多大的阻碍，一路执行就成功了，这里贴出导出成功的日志文件：1234567891011121314151617181920212223242526272829303132333435363738394041424344;;; Export: Release 12.2.0.1.0 - Production on 星期一 10月 31 10:54:38 2022Copyright (c) 1982, 2017, Oracle and/or its affiliates. All rights reserved.;;; 连接到: Oracle Database 12c Enterprise Edition Release 12.2.0.1.0 - 64bit Production启动 &quot;C##LEGACY&quot;.&quot;SYS_EXPORT_SCHEMA_01&quot;: C##LEGACY/********@orcl directory=bpdata1 dumpfile=backup.dmp logfile=export.log 处理对象类型 SCHEMA_EXPORT/TABLE/TABLE_DATA处理对象类型 SCHEMA_EXPORT/TABLE/INDEX/STATISTICS/INDEX_STATISTICS处理对象类型 SCHEMA_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS处理对象类型 SCHEMA_EXPORT/STATISTICS/MARKER处理对象类型 SCHEMA_EXPORT/SYSTEM_GRANT处理对象类型 SCHEMA_EXPORT/ROLE_GRANT处理对象类型 SCHEMA_EXPORT/DEFAULT_ROLE处理对象类型 SCHEMA_EXPORT/PRE_SCHEMA/PROCACT_SCHEMA处理对象类型 SCHEMA_EXPORT/TABLE/TABLE处理对象类型 SCHEMA_EXPORT/TABLE/COMMENT处理对象类型 SCHEMA_EXPORT/TABLE/IDENTITY_COLUMN处理对象类型 SCHEMA_EXPORT/TABLE/INDEX/INDEX处理对象类型 SCHEMA_EXPORT/TABLE/CONSTRAINT/CONSTRAINT处理对象类型 SCHEMA_EXPORT/TABLE/CONSTRAINT/REF_CONSTRAINT. . 导出了 &quot;C##LEGACY&quot;.&quot;MSC_HUA_HISTORY&quot; 14.58 GB 71276923 行. . 导出了 &quot;C##LEGACY&quot;.&quot;ROSHAN_CUSTOMERS_ARCHIVE&quot; 2.877 GB 20218000 行. . 导出了 &quot;C##LEGACY&quot;.&quot;CELL_TOWERS&quot; 1.080 GB 16865669 行. . 导出了 &quot;C##LEGACY&quot;.&quot;NEW_CELL_IDS&quot; 2.318 MB 14745 行. . 导出了 &quot;C##LEGACY&quot;.&quot;MSC_DATA&quot; 124.4 KB 246 行. . 导出了 &quot;C##LEGACY&quot;.&quot;MCC_MNC_OPERATOR&quot; 158.0 KB 1511 行. . 导出了 &quot;C##LEGACY&quot;.&quot;DJANGO_ADMIN_LOG&quot; 41.49 KB 145 行. . 导出了 &quot;C##LEGACY&quot;.&quot;DJANGO_SESSION&quot; 21.28 KB 14 行. . 导出了 &quot;C##LEGACY&quot;.&quot;AUTH_USER&quot; 10.00 KB 2 行. . 导出了 &quot;C##LEGACY&quot;.&quot;QUERY_TASK&quot; 9.156 KB 1 行. . 导出了 &quot;C##LEGACY&quot;.&quot;AUTH_PERMISSION&quot; 8.781 KB 32 行. . 导出了 &quot;C##LEGACY&quot;.&quot;DJANGO_MIGRATIONS&quot; 8.437 KB 25 行. . 导出了 &quot;C##LEGACY&quot;.&quot;DJANGO_CONTENT_TYPE&quot; 6.257 KB 8 行. . 导出了 &quot;C##LEGACY&quot;.&quot;AUTH_GROUP&quot; 0 KB 0 行. . 导出了 &quot;C##LEGACY&quot;.&quot;AUTH_GROUP_PERMISSIONS&quot; 0 KB 0 行. . 导出了 &quot;C##LEGACY&quot;.&quot;AUTH_USER_GROUPS&quot; 0 KB 0 行. . 导出了 &quot;C##LEGACY&quot;.&quot;AUTH_USER_USER_PERMISSIONS&quot; 0 KB 0 行已成功加载/卸载了主表 &quot;C##LEGACY&quot;.&quot;SYS_EXPORT_SCHEMA_01&quot; ******************************************************************************C##LEGACY.SYS_EXPORT_SCHEMA_01 的转储文件集为: C:\\BACKUP\\BACKUP.DMP作业 &quot;C##LEGACY&quot;.&quot;SYS_EXPORT_SCHEMA_01&quot; 已于 星期一 10月 31 10:56:19 2022 elapsed 0 00:01:38 成功完成 数据还原 注：下述sql命令均在sys账号下执行 1. 新建表空间123create tablespace bpdatafile &#x27;C:/backup/bp.DBF&#x27;size 100M autoextend on next 50M maxsize unlimited; 2. 创建用户并赋权12345678create user C##USER2 identified by &quot;123456&quot;default tablespace bpprofile DEFAULTACCOUNT UNLOCK;grant dba to C##USER2;grant resource to C##USER2; 3.数据还原1impdp C##USER2/123456@orcl directory=backup dumpfile=backup.dmp remap_schema=C##LEGACY:C##WYX logfile=import.log 若已有相同的数据表(此时会报ORA-39151错误)，则添加下述参数：table_exists_action=replace skip：跳过并处理下一个对象 append：为表增加数据 truncate：清空表，然后为其增加数据 replace：删除已存在表，重新建表并追加数据 本以为到此应该能够成功进行还原了，没想到报了一个数据文件无法扩展的问题，找了下资料发现oracle里一个数据文件最大为32G，故根据提示在对应的表空间新增数据文件： 1alter tablespace &quot;USERS&quot; add datafile &#x27;C:\\APP\\ORACLE\\ORADATA\\ORCL\\USERS02.DBF&#x27; size 100m autoextend on next 100m maxsize unlimited; 至此，已经能成功导入还原了： 123456789101112131415161718192021222324252627282930313233343536373839404142;;; Import: Release 12.2.0.1.0 - Production on 星期一 10月 31 18:51:06 2022Copyright (c) 1982, 2017, Oracle and/or its affiliates. All rights reserved.;;; 连接到: Oracle Database 12c Enterprise Edition Release 12.2.0.1.0 - 64bit Production已成功加载/卸载了主表 &quot;C##LEGACY&quot;.&quot;SYS_IMPORT_FULL_01&quot; ORA-39146: 方案 &quot;C##WYX2&quot; 不存在启动 &quot;C##LEGACY&quot;.&quot;SYS_IMPORT_FULL_01&quot;: C##WYX/********@orcl directory=bpdata1 dumpfile=backup.dmp remap_schema=C##WYX2:C##LEGACY logfile=import.log 处理对象类型 SCHEMA_EXPORT/SYSTEM_GRANT处理对象类型 SCHEMA_EXPORT/ROLE_GRANT处理对象类型 SCHEMA_EXPORT/DEFAULT_ROLE处理对象类型 SCHEMA_EXPORT/PRE_SCHEMA/PROCACT_SCHEMA处理对象类型 SCHEMA_EXPORT/TABLE/TABLE处理对象类型 SCHEMA_EXPORT/TABLE/TABLE_DATA. . 导入了 &quot;C##WYX&quot;.&quot;MSC_HUA_HISTORY&quot; 14.58 GB 71276923 行. . 导入了 &quot;C##WYX&quot;.&quot;ROSHAN_CUSTOMERS_ARCHIVE&quot; 2.877 GB 20218000 行. . 导入了 &quot;C##WYX&quot;.&quot;CELL_TOWERS&quot; 1.080 GB 16865669 行. . 导入了 &quot;C##WYX&quot;.&quot;NEW_CELL_IDS&quot; 2.318 MB 14745 行. . 导入了 &quot;C##WYX&quot;.&quot;MSC_DATA&quot; 124.4 KB 246 行. . 导入了 &quot;C##WYX&quot;.&quot;MCC_MNC_OPERATOR&quot; 158.0 KB 1511 行. . 导入了 &quot;C##WYX&quot;.&quot;DJANGO_ADMIN_LOG&quot; 41.49 KB 145 行. . 导入了 &quot;C##WYX&quot;.&quot;DJANGO_SESSION&quot; 21.28 KB 14 行. . 导入了 &quot;C##WYX&quot;.&quot;AUTH_USER&quot; 10.00 KB 2 行. . 导入了 &quot;C##WYX&quot;.&quot;QUERY_TASK&quot; 9.156 KB 1 行. . 导入了 &quot;C##WYX&quot;.&quot;AUTH_PERMISSION&quot; 8.781 KB 32 行. . 导入了 &quot;C##WYX&quot;.&quot;DJANGO_MIGRATIONS&quot; 8.437 KB 25 行. . 导入了 &quot;C##WYX&quot;.&quot;DJANGO_CONTENT_TYPE&quot; 6.257 KB 8 行. . 导入了 &quot;C##WYX&quot;.&quot;AUTH_GROUP&quot; 0 KB 0 行. . 导入了 &quot;C##WYX&quot;.&quot;AUTH_GROUP_PERMISSIONS&quot; 0 KB 0 行. . 导入了 &quot;C##WYX&quot;.&quot;AUTH_USER_GROUPS&quot; 0 KB 0 行. . 导入了 &quot;C##WYX&quot;.&quot;AUTH_USER_USER_PERMISSIONS&quot; 0 KB 0 行处理对象类型 SCHEMA_EXPORT/TABLE/COMMENT处理对象类型 SCHEMA_EXPORT/TABLE/IDENTITY_COLUMN处理对象类型 SCHEMA_EXPORT/TABLE/INDEX/INDEX处理对象类型 SCHEMA_EXPORT/TABLE/CONSTRAINT/CONSTRAINT处理对象类型 SCHEMA_EXPORT/TABLE/INDEX/STATISTICS/INDEX_STATISTICS处理对象类型 SCHEMA_EXPORT/TABLE/CONSTRAINT/REF_CONSTRAINT处理对象类型 SCHEMA_EXPORT/TABLE/STATISTICS/TABLE_STATISTICS处理对象类型 SCHEMA_EXPORT/STATISTICS/MARKER作业 &quot;C##LEGACY&quot;.&quot;SYS_IMPORT_FULL_01&quot; 已于 星期一 10月 31 19:00:59 2022 elapsed 0 00:09:49 成功完成 其他123456789101112131415161718192021222324252627282930select * from dba_directories;select * from dba_tablespaces;select * from dba_data_files;select * from dba_users;alter tablespace &quot;USERS&quot; drop datafile 23;SELECT T.TABLESPACE_NAME,D.FILE_NAME,D.AUTOEXTENSIBLE,D.BYTES,D.MAXBYTES,D.STATUSFROM DBA_TABLESPACES T,DBA_DATA_FILES DWHERE T.TABLESPACE_NAME =D.TABLESPACE_NAMEORDER BY TABLESPACE_NAME,FILE_NAME;SELECT a.tablespace_name &quot;表空间名&quot;, total &quot;表空间大小&quot;, free &quot;表空间剩余大小&quot;, (total - free) &quot;表空间使用大小&quot;, total / (1024 * 1024 * 1024) &quot;表空间大小(G)&quot;, free / (1024 * 1024 * 1024) &quot;表空间剩余大小(G)&quot;, (total - free) / (1024 * 1024 * 1024) &quot;表空间使用大小(G)&quot;, round((total - free) / total, 4) * 100 &quot;使用率 %&quot; FROM (SELECT tablespace_name, SUM(bytes) free FROM dba_free_space GROUP BY tablespace_name) a, (SELECT tablespace_name, SUM(bytes) total FROM dba_data_files GROUP BY tablespace_name) b WHERE a.tablespace_name = b.tablespace_name;","categories":[{"name":"其他","slug":"其他","permalink":"https://cezz.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[]},{"title":"如何控制并发速率2.0","slug":"go/如何控制并发速率2.0","date":"2022-10-06T05:11:03.000Z","updated":"2023-02-05T16:54:32.191Z","comments":true,"path":"2022/10/06/go/如何控制并发速率2.0/","link":"","permalink":"https://cezz.github.io/2022/10/06/go/%E5%A6%82%E4%BD%95%E6%8E%A7%E5%88%B6%E5%B9%B6%E5%8F%91%E9%80%9F%E7%8E%872.0/","excerpt":"","text":"之前有记录过在go中如何控制并发速率，要么就是通过带缓冲的channel，要么就是通过协程池。不论是通过什么方式，选择最适合在当前场景使用的即可，下面记录下学习过程中发现的开源项目中不同的实现方式。 ratelimit 来自projectdiscovery/ratelimit 个人理解该项目的特点是能控制的是每隔一段时间(自己定义)，起多少个并发，之前起的goroutine还在执行的话也没有影响，故如果goroutine执行的若是比较耗时的操作，那么会不会存在goroutine的数量一直在增加，消耗完所有内存，导致程序崩溃的情况。 不过这主要还是和使用方式有关，排除上述疑问的话，这个实现速率控制的方式也非常值得学习 源码分析123456789101112131415161718192021222324252627282930313233343536type Limiter struct &#123; maxCount int64 // 定义的最大并发数 count int64 // 当前剩余的令牌数(token) ticker *time.Ticker // 定时器，执行定时任务(标准库) tokens chan struct&#123;&#125; // 无缓冲channel，用于获取令牌 ctx context.Context // 上下文，终止定时器及创建的子协程&#125;func (limiter *Limiter) run() &#123; for &#123; // 当剩余的令牌数小于等于零时，等待设置的时间间隔后，重置剩余令牌数 if limiter.count &lt;= 0 &#123; &lt;-limiter.ticker.C limiter.count = limiter.maxCount &#125; select &#123; // 接收退出信号，关闭定时器并返回 case &lt;-limiter.ctx.Done(): limiter.ticker.Stop() return // 获取 case limiter.tokens &lt;- struct&#123;&#125;&#123;&#125;: limiter.count-- // 每过一段时间(设置的时间间隔)，重置剩余令牌数 // 与其他case是否执行无关，当其他case执行的时间小于该间隔，则其他case不会被执行 case &lt;-limiter.ticker.C: limiter.count = limiter.maxCount &#125; &#125;&#125;// Take one token from the bucketfunc (rateLimiter *Limiter) Take() &#123; &lt;-rateLimiter.tokens&#125; 使用方式官方示例中还有两个新建Limiter的方法，一个是控制并发速率和时间间隔的New，一个是不做任何控制的NewUnlimited，如下： 123456789101112131415161718192021222324252627// New creates a new limiter instance with the tokens amount and the intervalfunc New(ctx context.Context, max int64, duration time.Duration) *Limiter &#123; limiter := &amp;Limiter&#123; maxCount: max, count: max, ticker: time.NewTicker(duration), tokens: make(chan struct&#123;&#125;), ctx: ctx, &#125; go limiter.run() return limiter&#125;// NewUnlimited create a bucket with approximated unlimited tokensfunc NewUnlimited(ctx context.Context) *Limiter &#123; limiter := &amp;Limiter&#123; maxCount: math.MaxInt64, count: math.MaxInt64, ticker: time.NewTicker(time.Millisecond), tokens: make(chan struct&#123;&#125;), ctx: ctx, &#125; go limiter.run() return limiter&#125; 个人写的一个使用案例如下，还是得多思考程序的一个运行流程： 123456789101112131415161718192021222324252627282930313233343536373839404142434445func main() &#123; expected := 5 * time.Second limiter := New(context.Background(), 5, expected) start := time.Now() for i := 0; i &lt; 20; i++ &#123; limiter.Take() go func(_i int) &#123; fmt.Println(_i, &quot;+++&quot;, time.Since(start)) time.Sleep(10 * time.Second) fmt.Println(_i, &quot;---&quot;, time.Since(start)) &#125;(i) &#125; took := time.Since(start) fmt.Println(took) limiter.Take() took = time.Since(start) fmt.Println(took) select &#123; &#125;&#125;// 部分输出结果如下：// 1 +++ 0s// 0 +++ 0s// 3 +++ 0s// 2 +++ 0s// 4 +++ 0s// 6 +++ 5.0139749s// 5 +++ 5.0139749s// 8 +++ 5.0139749s// 7 +++ 5.0139749s// 9 +++ 5.0139749s// 4 --- 10.0149828s// 10 +++ 10.0149828s// 11 +++ 10.0149828s// 1 --- 10.0149828s// 2 --- 10.0149828s// 3 --- 10.0149828s// 0 --- 10.0149828s// 13 +++ 10.0149828s// 12 +++ 10.0149828s// 14 +++ 10.0149828s sizedwaitgroup 来自remeh/sizedwaitgroup 这个项目是对标准库sync.WaitGroup进行了进一步的封装，定义了一个大小和控制并发的channel，从实现上来看还是非常简单易懂，就不做注释了 对比ratelimit，个人理解这个是严格控制了同一时刻goroutine的并发数 源码分析12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667// SizedWaitGroup has the same role and close to the// same API as the Golang sync.WaitGroup but adds a limit of// the amount of goroutines started concurrently.type SizedWaitGroup struct &#123; Size int current chan struct&#123;&#125; wg sync.WaitGroup&#125;// New creates a SizedWaitGroup.// The limit parameter is the maximum amount of// goroutines which can be started concurrently.func New(limit int) SizedWaitGroup &#123; size := math.MaxInt32 // 2^31 - 1 if limit &gt; 0 &#123; size = limit &#125; return SizedWaitGroup&#123; Size: size, current: make(chan struct&#123;&#125;, size), wg: sync.WaitGroup&#123;&#125;, &#125;&#125;// Add increments the internal WaitGroup counter.// It can be blocking if the limit of spawned goroutines// has been reached. It will stop blocking when Done is// been called.//// See sync.WaitGroup documentation for more information.func (s *SizedWaitGroup) Add() &#123; s.AddWithContext(context.Background())&#125;// AddWithContext increments the internal WaitGroup counter.// It can be blocking if the limit of spawned goroutines// has been reached. It will stop blocking when Done is// been called, or when the context is canceled. Returns nil on// success or an error if the context is canceled before the lock// is acquired.//// See sync.WaitGroup documentation for more information.func (s *SizedWaitGroup) AddWithContext(ctx context.Context) error &#123; select &#123; case &lt;-ctx.Done(): return ctx.Err() case s.current &lt;- struct&#123;&#125;&#123;&#125;: break &#125; s.wg.Add(1) return nil&#125;// Done decrements the SizedWaitGroup counter.// See sync.WaitGroup documentation for more information.func (s *SizedWaitGroup) Done() &#123; &lt;-s.current s.wg.Done()&#125;// Wait blocks until the SizedWaitGroup counter is zero.// See sync.WaitGroup documentation for more information.func (s *SizedWaitGroup) Wait() &#123; s.wg.Wait()&#125; 使用方式1234567891011121314151617181920212223242526272829303132func query(i int) &#123; fmt.Println(i) time.Sleep(5 * time.Second)&#125;func main() &#123; swg := New(5) for i := 0; i &lt; 50; i++ &#123; swg.Add() go func(i int) &#123; defer swg.Done() query(i) &#125;(i) &#125;&#125;// 部分输出如下// 0 5.0046797s// 1 5.0046797s// 2 5.0048117s// 3 5.0046797s// 4 5.0048117s// 6 10.020529s// 8 10.020529s// 9 10.020529s// 7 10.020529s// 5 10.020529s// 14 15.0282816s// 12 15.0283974s// 11 15.0283974s// 10 15.0283974s// 13 15.0283974s 总结通过上述案例可以发现，不论是通过哪种方式去控制并发速率，它们都是通过channel去进行控制的，区别在于ratelimit是使用的无缓冲的channel，而sizedwaitgroup使用的是有缓冲的channel。故回归到本质，熟练掌握基础，深刻理解底层实现才是后期不断进阶的基石。","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"}],"tags":[]},{"title":"Linux常用命令之--ldd","slug":"其他/Linux常用命令之——ldd","date":"2022-10-02T03:08:31.000Z","updated":"2023-02-05T16:51:23.520Z","comments":true,"path":"2022/10/02/其他/Linux常用命令之——ldd/","link":"","permalink":"https://cezz.github.io/2022/10/02/%E5%85%B6%E4%BB%96/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E4%B9%8B%E2%80%94%E2%80%94ldd/","excerpt":"","text":"背景ldd是用于查看可执行文件的动态链接库依赖。(也可使用pmap进行查看)Q：什么是动态链接呢？ 有动态链接就有静态链接。静态链接是把依赖的第三方库函数打包到一起，其最后生成的可执行文件非常大。动态链接并不将那些库文件直接拿过来，而是在运行时，发现用到某些库中的某些函数时，再从第三方库中读取自己所需的方法。 动态链接库，linux下的后缀为so(Shared Object)，windows下的后缀为dll(Dynamic Link Libaray)。 注：更多动态链接相关内容可参考下述文章：https://zhuanlan.zhihu.com/p/235551437 使用可以使用ldd查看文件的动态链接依赖，如查看ls依赖的结果如下： 1234567891011(venvStudy) [root@node1 build_so]# ldd /bin/ls linux-vdso.so.1 =&gt; (0x00007ffef8adb000) libselinux.so.1 =&gt; /lib64/libselinux.so.1 (0x00007f3809d7d000) libcap.so.2 =&gt; /lib64/libcap.so.2 (0x00007f3809b78000) libacl.so.1 =&gt; /lib64/libacl.so.1 (0x00007f380996f000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f38095a1000) libpcre.so.1 =&gt; /lib64/libpcre.so.1 (0x00007f380933f000) libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007f380913b000) /lib64/ld-linux-x86-64.so.2 (0x00007f3809fa4000) libattr.so.1 =&gt; /lib64/libattr.so.1 (0x00007f3808f36000) libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007f3808d1a000) 通常安装某软件若是报错缺失某个依赖文件时，再结合apt-file查看文件所在包，然后使用apt进行安装。 注：Ubuntu下使用apt-file涉及到的命令如下： apt install apt-file apt-file update apt-file search libpthread.so.0 CentOS下使用命令yum provides libpthread.so.0 扩展在技术交流群看到其他人为了防止python代码泄露，有把python代码打包成动态链接库so的，自己不知道还可以这样操作，在此进行记录下。需要先安装Cython，该库是通过类似python的语法去编写c扩展并可以被python调用。其即具备了python快速开发的特点，又可以让代码运行起来像c一样快，同时还可以方便的调用c library。安装命令如下：pip install Cython -i [https://pypi.mirrors.ustc.edu.cn/simple](https://pypi.mirrors.ustc.edu.cn/simple) 快速开始新建文件hello.py，该文件为被打包的目标文件： 12def hello(name): print(f&quot;hello, &#123;name&#125;&quot;) 新建文件setup.py，该文件是调用Cython进行打包的文件： 123456789from distutils.core import setupfrom Cython.Build import cythonizeif __name__ == &#x27;__main__&#x27;: file_name = &#x27;hello.py&#x27; # 文件名 build_dir = &#x27;&#x27; # 文件目录 build_tmp_dir = &#x27;temp&#x27; # 编译的临时文件目录 setup(ext_modules=cythonize(file_name), script_args=[&quot;build_ext&quot;, &quot;-b&quot;, build_dir, &quot;-t&quot;, build_tmp_dir]) 接下来直接执行python setup.py，可以看到打包编译的过程，如果没有报错的话结果输出如下： 12345678(venvStudy) [root@node1 build_so]# lltotal 284drwxr-xr-x 3 root root 4096 Oct 2 11:53 build-rw-r--r-- 1 root root 140877 Oct 2 11:53 hello.c-rwxr-xr-x 1 root root 130968 Oct 2 11:53 hello.cpython-37m-x86_64-linux-gnu.so-rw-r--r-- 1 root root 46 Oct 2 11:40 hello.py-rw-r--r-- 1 root root 428 Oct 2 11:53 setup.py-rw-r--r-- 1 root root 37 Oct 2 11:38 test.py 此时已经生成了动态链接库so文件，可以将hello.py删除，也可以正常调用hello，build目录下是生成的临时文件。到这里只是大概了解了如何将python代码打包为so文件，想要更好的工程实践见下一部分内容。 工程实践可使用下述代码进行打包，来自[https://github.com/ArvinMei/py2so/blob/master/py2so.py](https://github.com/ArvinMei/py2so/blob/master/py2so.py)。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import sys, os, shutil, timefrom distutils.core import setupfrom Cython.Build import cythonizestarttime = time.time()setupfile= os.path.join(os.path.abspath(&#x27;.&#x27;), __file__)def getpy(basepath=os.path.abspath(&#x27;.&#x27;), parentpath=&#x27;&#x27;, name=&#x27;&#x27;, build_dir=&quot;build&quot;, excepts=(), copyOther=False, delC=False): &quot;&quot;&quot; 获取py文件的路径 :param basepath: 根路径 :param parentpath: 父路径 :param name: 文件/夹 :param excepts: 排除文件 :param copy: 是否copy其他文件 :return: py文件的迭代器 &quot;&quot;&quot; fullpath = os.path.join(basepath, parentpath, name) for fname in os.listdir(fullpath): ffile = os.path.join(fullpath, fname) if os.path.isdir(ffile) and ffile != os.path.join(basepath, build_dir) and not fname.startswith(&#x27;.&#x27;): for f in getpy(basepath, os.path.join(parentpath, name), fname, build_dir, excepts, copyOther, delC): yield f elif os.path.isfile(ffile): # print(&quot;\\t&quot;, basepath, parentpath, name, ffile) ext = os.path.splitext(fname)[1] if ext == &quot;.c&quot;: if delC and os.stat(ffile).st_mtime &gt; starttime: os.remove(ffile) elif ffile not in excepts and ext not in(&#x27;.pyc&#x27;, &#x27;.pyx&#x27;): # print(&quot;\\t\\t&quot;, basepath, parentpath, name, ffile) if ext in(&#x27;.py&#x27;, &#x27;.pyx&#x27;) and not fname.startswith(&#x27;__&#x27;): yield os.path.join(parentpath, name, fname) elif copyOther: dstdir = os.path.join(basepath, build_dir, parentpath, name) if not os.path.isdir(dstdir): os.makedirs(dstdir) shutil.copyfile(ffile, os.path.join(dstdir, fname)) else: passif __name__ == &quot;__main__&quot;: currdir = os.path.abspath(&#x27;.&#x27;) parentpath = sys.argv[1] if len(sys.argv)&gt;1 else &quot;.&quot; currdir, parentpath = os.path.split(currdir if parentpath == &quot;.&quot; else os.path.abspath(parentpath)) build_dir = os.path.join(parentpath, &quot;build&quot;) build_tmp_dir = os.path.join(build_dir, &quot;temp&quot;) print(&quot;start:&quot;, currdir, parentpath, build_dir) os.chdir(currdir) try: #获取py列表 module_list = list(getpy(basepath=currdir,parentpath=parentpath, build_dir=build_dir, excepts=(setupfile))) print(module_list) setup(ext_modules = cythonize(module_list),script_args=[&quot;build_ext&quot;, &quot;-b&quot;, build_dir, &quot;-t&quot;, build_tmp_dir]) module_list = list(getpy(basepath=currdir, parentpath=parentpath, build_dir=build_dir, excepts=(setupfile), copyOther=True)) except Exception as ex: print(&quot;error! &quot;, ex) finally: print(&quot;cleaning...&quot;) module_list = list(getpy(basepath=currdir, parentpath=parentpath, build_dir=build_dir, excepts=(setupfile), delC=True)) if os.path.exists(build_tmp_dir): shutil.rmtree(build_tmp_dir) print(&quot;complate! time:&quot;, time.time()-starttime, &#x27;s&#x27;)","categories":[{"name":"其他","slug":"其他","permalink":"https://cezz.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[]},{"title":"Linux常用命令之--sar","slug":"其他/Linux常用命令之——sar","date":"2022-09-28T11:53:13.000Z","updated":"2023-02-05T16:50:05.252Z","comments":true,"path":"2022/09/28/其他/Linux常用命令之——sar/","link":"","permalink":"https://cezz.github.io/2022/09/28/%E5%85%B6%E4%BB%96/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E4%B9%8B%E2%80%94%E2%80%94sar/","excerpt":"","text":"sar(system activity reporter 系统活动情况报告)，用于提取在一段时间内系统的性能分析报告，包括：文件的读写情况，系统调用的使用情况，磁盘I&#x2F;O，CPU效率，内存使用状况，进程活动及IPC有关的活动。 安装使用 yum install sysstat&#x2F;apt-get install sysstat 修改文件/etc/default/sysstat中的内容为ENANBLED=&quot;true&quot; 重启服务systemctl restart sysstat命令参数sar -h的输出见下，使用方式及参数说明都挺直观。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051Usage: sar [ options ] [ &lt;interval&gt; [ &lt;count&gt; ] ]Main options and reports: -b I/O and transfer rate statistics -B Paging statistics -d Block device statistics -F [ MOUNT ] Filesystems statistics -H Hugepages utilization statistics -I &#123; &lt;int&gt; | SUM | ALL | XALL &#125; Interrupts statistics -m &#123; &lt;keyword&gt; [,...] | ALL &#125; Power management statistics Keywords are: CPU CPU instantaneous clock frequency FAN Fans speed FREQ CPU average clock frequency IN Voltage inputs TEMP Devices temperature USB USB devices plugged into the system -n &#123; &lt;keyword&gt; [,...] | ALL &#125; Network statistics Keywords are: DEV Network interfaces EDEV Network interfaces (errors) NFS NFS client NFSD NFS server SOCK Sockets (v4) IP IP traffic (v4) EIP IP traffic (v4) (errors) ICMP ICMP traffic (v4) EICMP ICMP traffic (v4) (errors) TCP TCP traffic (v4) ETCP TCP traffic (v4) (errors) UDP UDP traffic (v4) SOCK6 Sockets (v6) IP6 IP traffic (v6) EIP6 IP traffic (v6) (errors) ICMP6 ICMP traffic (v6) EICMP6 ICMP traffic (v6) (errors) UDP6 UDP traffic (v6) -q Queue length and load average statistics -r Memory utilization statistics -R Memory statistics -S Swap space utilization statistics -u [ ALL ] CPU utilization statistics -v Kernel table statistics -w Task creation and system switching statistics -W Swapping statistics -y TTY device statistics 常用命令查看CPU使用率sar 1 3默认显示的是cpu使用率信息，等同于sar -u 1 31234567Linux 4.15.0-173-generic (zw) 10/03/2022 _x86_64_ (16 CPU)08:07:19 AM CPU %user %nice %system %iowait %steal %idle08:07:20 AM all 17.87 0.00 2.05 0.00 0.00 80.0708:07:21 AM all 15.10 0.00 0.94 0.00 0.00 83.9608:07:22 AM all 16.56 0.00 1.69 0.00 0.00 81.74Average: all 16.51 0.00 1.56 0.00 0.00 81.92 %user：用户模式下消耗的CPU时间比例 %nice：通过nice改变了进程调度优先级的进程，在用户模式下消耗的CPU时间比例 %system：系统模式下消耗的CPU时间比例 %iowait：CPU等待磁盘I&#x2F;O导致空闲状态消耗的时间比例 %steal：利用xen等操作系统虚拟化技术，等待其他虚拟CPU计算占用的时间比例 %idle：CPU空闲时间比例 若%iowait的值过高，表示磁盘存在I&#x2F;O瓶颈 若%idle的值高但系统响应慢时，可能是CPU等待分配内存，此时应加大内存容量 若%idle的值持续低于1，则系统CPU的处理能力相对较低，考虑CPU的资源 I&#x2F;O和传输速率统计sar -b 1 3 1234567Linux 4.15.0-173-generic (zw) 10/03/2022 _x86_64_ (16 CPU)08:20:24 AM tps rtps wtps bread/s bwrtn/s08:20:25 AM 6.00 0.00 6.00 0.00 80.0008:20:26 AM 0.00 0.00 0.00 0.00 0.0008:20:27 AM 0.00 0.00 0.00 0.00 0.00Average: 2.00 0.00 2.00 0.00 26.67 tps：每秒钟物理设备的I&#x2F;O传输总量 rtps：每秒钟从物理设备读入的数据总量 wtps：每秒钟向物理设备写入的数据总量 bread&#x2F;s：每秒钟从物理设备读入的数据量，单位为：块&#x2F;s bwrtn&#x2F;s：每秒钟向物理设备写入的数据量，单位为：块&#x2F;s 内存利用率sar -r 1 3 1234567Linux 4.15.0-173-generic (zw) 10/03/2022 _x86_64_ (16 CPU)08:27:46 AM kbmemfree kbavail kbmemused %memused kbbuffers kbcached kbcommit %commit kbactive kbinact kbdirty08:27:47 AM 3897560 65082240 94987480 96.06 11224640 47914160 120160988 120.74 40025904 50646580 180808:27:48 AM 3404600 64589496 95480440 96.56 11224640 47914440 120226200 120.81 40517296 50646796 208408:27:49 AM 3465888 64650784 95419152 96.50 11224640 47914440 120163888 120.74 40456772 50646796 2084Average: 3589349 64774173 95295691 96.37 11224640 47914347 120183692 120.76 40333324 50646724 1992 kbmemfree：基本等同于free中的值free，不包括buffer和cache的空间 kbmemused：基本等同于free中的值used，包括buffer和cache的空间 %memused：物理内存总量，是kbmemused和内存总量的(不包括swap)的百分比 kbbuffers和kbcached：就是free中的buffer和cache kbcommit：保证当前系统所需的内存，即为了确保不溢出而需要的内存(RAM + swap) %commit：是kbcommit与内存总量(包括swap)的百分比 排查技巧 怀疑CPU存在瓶颈，可用sar -u和sar -q等查看 怀疑内存存在瓶颈，可用sar -B、sar -r和sar -W等查看 怀疑I&#x2F;O存在瓶颈，可用sar -b、sar -u和sar -d等查看","categories":[{"name":"其他","slug":"其他","permalink":"https://cezz.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[]},{"title":"Django Admin自定义按钮取消强制选择对象","slug":"django/Django Admin自定义按钮取消强制选择对象","date":"2022-09-11T14:03:11.000Z","updated":"2023-02-05T16:12:28.224Z","comments":true,"path":"2022/09/11/django/Django Admin自定义按钮取消强制选择对象/","link":"","permalink":"https://cezz.github.io/2022/09/11/django/Django%20Admin%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8C%89%E9%92%AE%E5%8F%96%E6%B6%88%E5%BC%BA%E5%88%B6%E9%80%89%E6%8B%A9%E5%AF%B9%E8%B1%A1/","excerpt":"","text":"当创建自定义按钮，点击时默认至少需要选择一个选项。若要取消该选择，当只使用django原生admin的时候只需要重写changelist_view即可，而若使用了其他组件如simpleui时，则还需要修改其他东西。本文记录在使用了simpleui的情况下，如何取消点击自定义按钮时的强制选择。 1. 默认情况下创建自定义按钮如下 2. 修改simpleui的actions.html路径如下：\\venv\\Lib\\site-packages\\simpleui\\templates\\admin\\actions.html来到第413行，可能因simpleui版本不同而具体行数不一样，添加修改后如下： 这里只是加了一个判断，自定义按钮的名字以fc_开头的话则直接调用点击事件 123456789101112131415161718//TODO 需要做国际化if (data_name.substr(0, 3) == &quot;fc_&quot;) &#123; // 强制运行，不用选择数据，按钮名data_name必须以&quot;fc_&quot;开头 done.call(this)&#125; else if (checkbox_checked == 0 &amp;&amp; data_name != &quot;add_item&quot; &amp;&amp; !_action.customButton[data_name].action_url) &#123; _vue.$alert(getLanuage(&quot;Please select at least one option!&quot;), &#x27;&#x27;, &#123; type: &#x27;warning&#x27; &#125;)&#125; else if (confirm) &#123; _vue.$confirm(confirm, &#x27;提示&#x27;, &#123; confirmButtonText: &#x27;确定&#x27;, cancelButtonText: &#x27;取消&#x27;, type: &#x27;warning&#x27; &#125;).then(() =&gt; done.call(this)); &#125; else &#123; done.call(this)&#125; 3. 重写changelist_view方法首先按钮定义如下，为一个简单的跳转操作，需要注意新增了一个动态属性acts_on_all 12345def fc_prev(self, request, queryset): return HttpResponseRedirect(&quot;/admin/data/querytask/&quot;)fc_prev.short_description = &quot;返回查询任务页&quot;fc_prev.type = &quot;primary&quot;fc_prev.acts_on_all = True 然后重写changelist_view： 1234567891011def changelist_view(self, request, extra_context=None): try: action = self.get_actions(request)[request.POST[&quot;action&quot;]][0] action_acts_on_all = action.acts_on_all except (KeyError, AttributeError): action_acts_on_all = False if action_acts_on_all: post = request.POST.copy() post.setlist(ACTION_CHECKBOX_NAME, self.model.objects.all()[:1].values_list(&quot;id&quot;, flat=True)) request.POST = post return super(MscHuaHistoryAdmin, self).changelist_view(request, extra_context) 到此，已经实现了取消自定义按钮强制选择对象的情况了，代码比较简单，主要也是参考了Stack Overflow上的回答，链接如下。 4. 参考https://stackoverflow.com/questions/4500924/django-admin-action-without-selecting-objectshttps://blog.csdn.net/qq_42761569&#x2F;article&#x2F;details&#x2F;121495074https://gitee.com/bode135/bddjango/blob/master/bddjango/adminclass","categories":[{"name":"django","slug":"django","permalink":"https://cezz.github.io/categories/django/"}],"tags":[]},{"title":"Django静态文件404","slug":"django/Django静态文件404","date":"2022-09-03T05:46:51.000Z","updated":"2023-01-30T15:40:16.969Z","comments":true,"path":"2022/09/03/django/Django静态文件404/","link":"","permalink":"https://cezz.github.io/2022/09/03/django/Django%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6404/","excerpt":"","text":"首先明白一点，在django中把debug改为false的话，django将不再为我们处理静态文件，我们需要使用web服务器进行代理静态资源，这时就需要去设置静态文件的路径，下面介绍如何设置 注：可以参考Stack Overflow上的回答https://stackoverflow.com/questions/5836674/why-does-debug-false-setting-make-my-django-static-files-access-fail 1. settings修改新增静态文件目录配置： 1STATIC_ROOT = os.path.join(BASE_DIR, &#x27;static&#x27;) 2. 静态文件收集执行下述命令，将静态文件会收集到第一步设置的目录中 1python manage.py collectstatic 3. 配置路由url123456from django.views import staticfrom django.urls import re_pathurlpatterns = [ re_path(&#x27;^static/(?P&lt;path&gt;.*)&#x27;, static.serve, &#123;&#x27;document_root&#x27;: settings.STATIC_ROOT&#125;)] 4. web服务器配置下面简单给出nginx的配置 123location /static &#123; alias /data/wwwroot/project/static;&#125;","categories":[{"name":"django","slug":"django","permalink":"https://cezz.github.io/categories/django/"}],"tags":[]},{"title":"Django中QuerySet的两大特性","slug":"django/Django中QuerySet的两大特性","date":"2022-08-30T12:08:33.000Z","updated":"2023-01-30T15:36:51.880Z","comments":true,"path":"2022/08/30/django/Django中QuerySet的两大特性/","link":"","permalink":"https://cezz.github.io/2022/08/30/django/Django%E4%B8%ADQuerySet%E7%9A%84%E4%B8%A4%E5%A4%A7%E7%89%B9%E6%80%A7/","excerpt":"","text":"查询集查询集也称查询结果集，QuerySet，表示从数据库中获取的对象集合，在管理器上调用某些过滤器方法会返回查询集，查询集可以含有零个，一个或多个过滤器。当调用如下过滤器方法时，Django会返回查询集(而不是简单的列表)： all()：返回所有数据 filter()：返回满足条件的数据 exclude()：返回满足条件之外的数据 order_by()：对结果进行排序 返回单个值的过滤器如下： get()：返回单个满足条件的对象 若未找到会抛出DoesNotExist异常 若找到多条会抛出MultipleObjectsReturned异常 count()：返回当前查询结果的总条数 aggregate()：聚合，返回一个字典 注：判断某一个查询集中是否有数据可以使用exists()方法，有则返回True，反之返回False 两大特性 惰性执行：创建查询集不会访问数据库，直到用数据时，才会访问数据库，调用数据的情况包括迭代、序列化、与if合用。 1234567# 执行下面的语句数据库并不会进行查询books = BookInfo.objects.all()# 只有当真正使用时，才会真正去数据库进行查询for b in books: print(b) 缓存：使用同一个查询集，第一次使用时会发生数据库的查询，然后把结果缓存下来，再次使用查询集时会使用缓存的数据。 12345# 进行数据库实际查询遍历，保存结果到books，会进行数据库实际交互books = [b.id for b in BookInfo.objects.all()]# 再次调用books，不再进行数据库查询，而是使用缓存结果print(books) 注：对查询集进行取下标或切片操作，等同于sql中的limit和offset","categories":[{"name":"django","slug":"django","permalink":"https://cezz.github.io/categories/django/"}],"tags":[]},{"title":"SSL_TLS相关内容梳理","slug":"其他/SSL_TLS相关内容梳理","date":"2022-08-14T02:21:02.000Z","updated":"2023-01-29T12:51:56.522Z","comments":true,"path":"2022/08/14/其他/SSL_TLS相关内容梳理/","link":"","permalink":"https://cezz.github.io/2022/08/14/%E5%85%B6%E4%BB%96/SSL_TLS%E7%9B%B8%E5%85%B3%E5%86%85%E5%AE%B9%E6%A2%B3%E7%90%86/","excerpt":"","text":"证书文件格式说明： .key：私钥文件，通常使用rsa算法，私钥需要自己保存，无需提交给ca机构 .crt：证书文件，certificate的缩写 .csr：证书签名请求(证书请求文件)，含有公钥信息 .crl：证书吊销列表 .pem：用于导出，导入证书时候的证书格式，是.key和.crt的合体 Q：什么是数字签名，有什么作用？作用：验证消息的来源，以及证明消息是否被篡改 签名：用私钥对消息的哈希值进行加密称为签名，只有拥有私钥的用户可以生成签名 生成签名的步骤： 对消息进行哈希计算，得到哈希值 利用私钥对哈希值进行加密，生成签名 将签名附加在消息后面，一起发送过去 验证签名：用公钥解密签名这一步称为验证签名，所有用户都可以验证签名（因为公钥是公开的） 验证签名的步骤： 收到消息后，提取消息中的签名 用公钥对签名进行解密，得到哈希值1 对消息中的正文进行哈希计算，得到哈希值2 比较哈希值1和哈希值2，如果相同，则验证成功 Q：什么是证书，如何验证证书？证书：实际上就是公钥的数字签名，是对公钥合法性提供证明的技术。它包括公钥本身，公钥的数字签名，公钥拥有者的信息等等。 生成证书的步骤： 服务器将公钥A给CA（公钥是服务器的） CA用自己的私钥B给公钥A加密，生成数字签名A CA把公钥A，数字签名A，附加一些服务器信息整合在一起，生成证书，发回给服务器 注：私钥B是用于加密公钥A的，私钥B和公钥A并不是配对的 验证证书的数字签名需要另一个公钥，保证这个公钥的合法性则需要第三方认证机构，即CA。CA能够认定公钥确实属于此人，并能生成公钥的数字签名。CA有国际性组织和政府设立的组织，也有通过提供认证服务来盈利的组织。 验证证书的步骤： 客户端得到证书 客户端得到证书的公钥B（通过CA或其他途径） 客户端用公钥B对证书中的数字签名解密，得到哈希值 客户端对公钥进行哈希计算 两个哈希值对比，如果相同，则证书合法 注：公钥B和上述的私钥B是配对的，分别用于对证书的验证（解密）和生成（加密） 另外，当用户私钥丢失，被盗时，认证机构需要对证书进行作废。要作废证书，认证机构需要制作一张证书作废清单（Certificate Revocation List），检查CRL。我们在验证证书的合法性时，除了验证其是否在有效期内，还需要查询其CRL，确认证书是否有效。 Q：单向认证 &amp; 双向认证 &amp; 不认证 单向认证：指的是只有一个对象校验对端的整数合法性，通常是客户端来校验服务器的合法性。那么client需要一个ca.crt，服务端需要server.crt、server.key，当然也可以是服务端校验客户端。 双向认证：指的是相互校验，服务器需要校验每个client证书，client也需要校验服务器证书 不认证：指的是不相互校验证书，但仍然使用TLS连接Q：单向认证流程？ client_hello：客户端发起请求，以明文传输请求信息，包含版本信息，加密套件候选列表，压缩算法候选列表，随机数，扩展字段等信息 server_hello + server_certificate + server_hello_done server_hello，服务端返回协商的信息结果，包括选择使用的协议版本version，选择的加密套件cipher suite，选择的压缩算法compression method、随机数random_S等，其中随机数用于后续的密钥协商 server_certificates，服务端配置对应的证书链，用于身份验证与密钥交换 server_hello_done，通知客户端server_hello信息发送结束 证书校验 证书&#x2F;证书链的可信性 证书是否吊销revocation，有两类方式离线CRL与在线OCSP，不同客户端行为不同 有效期expire date，证书是否在有效时间范围 域名damain，检查证书域名是否与当前的访问域名匹配(CN字段) client_key_exchange + change_cipher_spec + encrypted_handshake_message client_key_exchange：合法性验证通过之后，客户端计算产生随机数字pre-master，并用证书公钥加密，发送给服务器 此时客户端已经获取全部的计算协商密钥需要的信息：两个明文随机数random_C和random_S与自己计算产生的pre-master，计算得到协商密钥enc_key=Func(...) change_cipher_spec：客户端通知服务器后续的通信都采用协商的通信密钥和加密算法进行加密通信 encrypted_handshake_message：结合之前所有通信参数的hash值与其他相关信息生成一段数据，采用协商密钥session secret与算法进行加密，然后发送给服务器用于数据与握手验证 change_cipher_spec + encrypted_handshake_message 服务器用私钥解密加密的pre-master数据，基于之前交换的两个明文随机数random_C和random_S，计算得到协商密钥enc_key=Func(...) 计算之前所有接收信息的哈希值，然后解密客户端发送的change_cipher_spec以告知客户端后续的通信都采用协商的密钥与算法进行加密通信 change_cipher_spec，验证通过之后，服务器同样发送change_cipher_spec以告知客户端后续的通信都采用协商的密钥与算法进行加密通信 encrypted_handshake_message，服务器也结合所有当前的通信参数信息生成一段数据并采用协商密钥session secret与算法加密并发送到客户端 握手结束：客户端计算所有接收信息的哈希值，并采用协商密钥解密encrypted_handshake_message，验证服务器发送的数据和密钥，验证通过则握手完成 加密通信：开始使用协商密钥与算法进行加密通信","categories":[{"name":"其他","slug":"其他","permalink":"https://cezz.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[]},{"title":"gRPC如何做身份认证？","slug":"grpc/gRPC如何做身份认证？","date":"2022-08-10T14:05:51.000Z","updated":"2022-10-10T14:07:46.851Z","comments":true,"path":"2022/08/10/grpc/gRPC如何做身份认证？/","link":"","permalink":"https://cezz.github.io/2022/08/10/grpc/gRPC%E5%A6%82%E4%BD%95%E5%81%9A%E8%BA%AB%E4%BB%BD%E8%AE%A4%E8%AF%81%EF%BC%9F/","excerpt":"","text":"当上线gRPC服务到生产环境的时候，首先需要考虑的就是数据的安全，那么如何保证呢，下面以python为例，进行简单介绍。 RPC的认证方式RPC服务一般在服务内网使用，不过也有存在于外网的情况，不论是哪种RPC服务，走http2.0或是其他基于TCP实现socket的协议，在部署到生产环境的时候还是需要考虑身份认证加密的，以此来保证数据的安全。 基于SSL&#x2F;TLS的通道加密通常身份认证机制是通过SSL&#x2F;TLS对传输通道加密，以防止请求和响应消息中的敏感数据泄露。使用的场景主要有三种： 后端微服务直接开放给端侧，例如手机app、tv、多屏等，没有统一的API Gateway&#x2F;SLB做安全接入和认证 后端微服务直接开放给DMZ部署的管理或者运维类Portal 后端微服务直接开放给第三方合作伙伴&#x2F;渠道 除了上述常用的跨网络场景之外，对于一些安全等级要求比较高的业务场景，即便是内网通信，只要跨主机&#x2F;VM&#x2F;容器等，都强制要求对传输通道进行加密。在该场景下，即便只存在内网各模块的RPC调用，仍然需要进行加密。针对敏感数据的单独加密有些RPC调用并不涉及敏感数据的传输，或者敏感字段占比较低，为了最大程度的提升吞吐量，降低调用时延，通常会采用HTTP&#x2F;TCP+敏感字段单独加密的方式。既保证了敏感信息的传输安全，同时也降低了采用SSL&#x2F;TLS加密通道带来的性能损耗，对于JDK原生的SSL类库，这种性能提升尤为明显。 采用该方案主要有两个缺点： 对敏感信息的识别可能存在偏差，容易遗漏或者过度保护，需要解读数据和隐私保护方面的法律法规，而且不同国家对敏感数据的定义也不同，这会为识别带来很多困难。 接口升级时容易遗漏，例如开发新增字段，忘记识别是否未敏感数据。 gRPC认证的的具体流程对于gRPC，SSL&#x2F;TLS协议也是基本的身份加密认证方法，SSL&#x2F;TLS协议采用公钥加密，客户端向服务端索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。SSL&#x2F;TLS分为单向认证和双向认证，在实际业务中，单向认证使用较多，即客户端认证服务端，服务端不认证客户端，认证流程如下： 客户端向服务端传送客户端SSL协议的版本号，支持的加密算法种类，产生的随机数，以及其他可选信息 服务端返回握手应答，向客户端传送确认SSL协议的版本号、加密算法的种类、随机数以及其他相关信息 服务端向客户端发送自己的公钥 客户端对服务端的证书进行认证，服务端的合法性校验包括：证书是否过期、发行服务器证书的CA是否可靠、发行者证书的公钥能否正确解开服务器证书的“发行者的数字签名”、服务器证书上的域名是否和服务器的实际域名相匹配等 客户端随机生成一个用于后面通讯的“对称密码”，然后用服务端的公钥对其加密，将加密后的“预主密码”传给服务端 服务端用自己的私钥解开加密的“预主密码”，然后执行一系列步骤来产生主密码 客户端向服务端发出信息，指明后面的数据通讯将使用主密码为对称密钥，同时通知服务器客户端的握手过程结束 服务端向客户端发出信息，指明后面的数据通讯将使用主密码为对称密钥，同时通知客户端服务端的握手过程结束 SSL的握手部分结束，SSL安全通道简历，客户端和服务端开始使用相同的对称密钥对数据进行加密，然后通过socket进行传输 具体示例生成证书1openssl req -newkey rsa:2048 -nodes -keyout server.key -x509 -days 3650 -out server.crt 在执行生成证书的过程中，需要填入Country Name、State or Province Name、Locality Name、Organization Name、Organization Unit Name、Common Name、Email Address等等，这些可以按需填入，或者留空也行。 注：其中的Common Name支持在客户端连接的时候指定连接的名字，可以自己定义之后填上，否则留空的话可能自动获取不到 代码实现下面模拟一个任务的grpc调用，服务端将流式响应任务的进度信息proto定义如下： 12345678910111213141516syntax = &quot;proto3&quot;;service Task &#123; rpc StartScan(TaskInfoRequest) returns(stream CommonResponse);&#125;message TaskInfoRequest &#123; string task_id = 1; string data = 2;&#125;message CommonResponse &#123; int32 code = 1; string msg = 2; string progress = 3;&#125; 注：执行下述命令生成python的proto序列化协议源代码python -m grpc_tools.protoc --python_out=. --grpc_python_out=. -I. task.proto 服务端代码server.py如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748import randomimport timefrom concurrent import futuresimport grpcfrom proto import task_pb2, task_pb2_grpcclass TaskServicer(task_pb2_grpc.TaskServicer): def StartScan(self, request, context): progress = 0 while progress &lt; 100: resp = &#123; &quot;code&quot;: 200, &quot;msg&quot;: &quot;succeed&quot;, &quot;progress&quot;: str(progress) &#125; feature = task_pb2.CommonResponse(**resp) tmp = random.randint(1, 10) progress += tmp time.sleep(5) yield featuredef serve(): server = grpc.server(futures.ThreadPoolExecutor(max_workers=10), options=[ # (&quot;grpc.max_send_message_length&quot;, 100 * 1024 * 1024), # (&quot;grpc.max_receive_message_length&quot;, 100 * 1024 * 1024) ]) task_pb2_grpc.add_TaskServicer_to_server(TaskServicer(), server) with open(&quot;./server.key&quot;, &quot;rb&quot;) as f: private_key = f.read() with open(&quot;./server.crt&quot;, &quot;rb&quot;) as f: certificate_chain = f.read() server_credentials = grpc.ssl_server_credentials(((private_key, certificate_chain), )) server.add_secure_port(&quot;[::]:50051&quot;, server_credentials) server.start() print(&quot;gRPC服务端已开启，端口为50051...&quot;) server.wait_for_termination()if __name__ == &#x27;__main__&#x27;: serve() 客户端代码client.py如下所示： 123456789101112131415161718192021222324252627282930313233343536import grpcfrom proto import task_pb2, task_pb2_grpcdef get_progress(*host): with open(&quot;server.crt&quot;, &quot;rb&quot;) as f: trusted_certs = f.read() credentials = grpc.ssl_channel_credentials(root_certificates=trusted_certs) with grpc.secure_channel(&quot;localhost:50001&quot;, credentials) as channel: stub = task_pb2_grpc.TaskStub(channel) req = &#123; &quot;task_id&quot;: &quot;24dsad&quot;, &quot;data&quot;: &quot;12&quot; &#125; features = stub.StartScan(task_pb2.TaskInfoRequest(**req)) for feature in features: print(feature.progress)def run(): with grpc.insecure_channel(&quot;localhost:50001&quot;) as channel: stub = task_pb2_grpc.TaskStub(channel) req = &#123; &quot;task_id&quot;: &quot;1&quot;, &quot;data&quot;: &quot;my test&quot; &#125; features = stub.StartScan(task_pb2.TaskInfoRequest(**req)) for feature in features: print(feature.progress)if __name__ == &#x27;__main__&#x27;: run() 按照上述实现，即完成了gRPC的认证加密。 抓包分析运行上述的代码，进行抓包如下，确认gRPC通信已通过SSL&#x2F;TLS加密认证。","categories":[{"name":"grpc","slug":"grpc","permalink":"https://cezz.github.io/categories/grpc/"}],"tags":[]},{"title":"什么是gRPC，什么场景下使用gRPC？","slug":"grpc/什么是gRPC，什么场景下使用？","date":"2022-08-06T01:29:10.000Z","updated":"2022-10-10T14:02:01.261Z","comments":true,"path":"2022/08/06/grpc/什么是gRPC，什么场景下使用？/","link":"","permalink":"https://cezz.github.io/2022/08/06/grpc/%E4%BB%80%E4%B9%88%E6%98%AFgRPC%EF%BC%8C%E4%BB%80%E4%B9%88%E5%9C%BA%E6%99%AF%E4%B8%8B%E4%BD%BF%E7%94%A8%EF%BC%9F/","excerpt":"","text":"gRPC什么是RPCRPC指的是远程过程调用（Remote Procedure Call），能在本地调用其他服务器上的函数，它的调用包含了传输协议和编码协议等，而开发人员无需额外地为这个过程进行编码。 什么是gRPCgRPC是一个高性能、开源和通用的RPC框架，面向移动和基于HTTP&#x2F;2设计，并且提供了多种语言的支持。 gRPC基于HTTP&#x2F;2标准设计，有着如双向流、流控、头部压缩、单TCP连接上的多路复用请求等特性。这些特性使得其在移动设备上表现更好，在一定的情况下更节省空间占用。 gRPC的接口描述语言IDL(Interface description language)使用的是protubuf，都是由google开源的。 gRPC调用模型 客户端（gRPC Stub）在程序中调用某方法，发起RPC调用 对请求信息使用protobuf进行对象序列化压缩（IDL） 服务端（gRPC Server）接收到请求后，解码请求体，进行业务逻辑处理并返回 对响应结果使用protobuf进行对象序列化压缩（IDL） 客户端接收到服务端响应，解码请求体。回调被调用的A方法，唤醒正在等待响应（阻塞）的客户端调用并返回响应结果。 Protobuf什么是ProtbufProtobuf Buffers（Protobuf）是一种与语言、平台无关，可扩展的序列化结构数据的数据描述语言。常用于通信协议，数据存储等，相较于JSON、XML、它更小，更快。 基本语法123456789101112131415syntax = &quot;proto3&quot;;package helloworld;service Greeter &#123; rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;&#125;message HelloRequest &#123; string name = 1;&#125;message HelloReply &#123; string message = 1;&#125; 首先需要声明使用的语法版本，不声明的话默认使用的是proto2。目前主流使用的为proto3 定义名为Greeter的RPC服务（Service），其包含RPC方法SayHello，入参为HelloRequest消息体，出参为HelloReply消息体 定义HelloRequest、HelloReply消息体，每一个消息体的字段包含三个属性：类型、字段名称、字段编号。在消息体的定义上，除类型以外均不可重复。 在编写完proto文件后，一般会进行编译和生成对应语言的proto文件操作，这个时候Protobuf的编译器会根据选择的语言不同，调用的插件情况，生成相应语言的Service Interface Code和Stubs。 基本数据类型 Proto Type C++ Type Java Type Go Type PHP Type double double double float64 float float float float float32 float int32 int32 int int32 integer int64 int64 long int64 integer&#x2F;string uint32 uint32 int uint32 integer uint64 uint64 long uint64 integer&#x2F;string sint32 int32 int int32 integer sint64 int64 long int64 integer&#x2F;string fixed32 uint32 int uint32 integer fixed64 uint64 long uint64 integer&#x2F;string sfixed32 int32 int int32 integer sfixed64 int64 long int64 integer&#x2F;string bool bool boolean bool boolean string string String string string bytes string ByteString []byte string 什么场景下使用gRPC？gRPC与RESTful API对比 特性 gRPC RESTful API 规范 必须.proto 可选OpenAPI 协议 HTTP&#x2F;2 任意版本的HTTP协议 有效载荷 Protobuf（小、二进制） JSON（大、易读） 浏览器支持 否（需要grpc-web） 是 流传输 客户端、服务端、双向 客户端、服务端 代码生成 是 OpenAPI+第三方工具 使用场景分析 低延时，高可用的分布式系统 移动端与云服务端的通讯 使用protobuf，独立于语言的协议，支持多语言之间的通讯 可以分层扩展，如：身份验证，负载均衡，日志记录，监控等","categories":[{"name":"grpc","slug":"grpc","permalink":"https://cezz.github.io/categories/grpc/"}],"tags":[]},{"title":"让邮件变得简单-zmail","slug":"python/让邮件变得简单-zmail","date":"2022-07-02T03:13:38.000Z","updated":"2022-07-10T23:17:11.453Z","comments":true,"path":"2022/07/02/python/让邮件变得简单-zmail/","link":"","permalink":"https://cezz.github.io/2022/07/02/python/%E8%AE%A9%E9%82%AE%E4%BB%B6%E5%8F%98%E5%BE%97%E7%AE%80%E5%8D%95-zmail/","excerpt":"","text":"前言由之前的爬虫需要获取邮箱验证码得以延伸，当时简单实现了一个支持pop3协议的邮件接收功能，但是不足点还有很多，扩展性也不强。比如支持的邮件服务商有限，功能针对性过强，换一个场景的话就无法使用了。于是整理了下思路，考虑到重复造轮子的话意义不大，现阶段不如多汲取已有轮子的优点，多进行积累未来才能造功能更强大完善的轮子。本着这样的想法，找到了一个收发邮件的第三方模块[zmail](https://github.com/zhangyunhao116/zmail)，目前该项目虽已不再维护，不过功能依然很强大可用，后续有需求也可进行修改升级。该模块本质上还是调用的python的标准库smtplib,poplib。 简单分析目录结构1234567891011121314│─ zmail│ __init__.py│ abc.py│ api.py│ compat.py│ exceptions.py│ helpers.py│ info.py│ mime.py│ parser.py│ server.py│ settings.py│ structures.py│ utils.py abc.py快速开始下面简单列举下如何使用该模块进行收发邮件，其他详细功能可以参考作者文档或阅读源码。发送邮件12345678910111213141516import zmailmail = &#123; &quot;subject&quot;: &quot;Hello&quot;, # 邮件主题 &quot;content_text&quot;: &quot;send message test&quot;, # 邮件内容 &quot;attachments&quot;: [&quot;/tmp/test.py&quot;, &quot;/tmp/1.jpg&quot;], # 附件内容(最好使用绝对路径) &quot;from&quot;: &quot;Name &lt;your email account&gt;&quot; # 自定义发送者&#125;server = zmail.server(&quot;your email&quot;, &quot;your password&quot;)# 批量发送server.send_mail([&quot;send email&quot;], mail)# 添加抄送server.send_mail([&quot;send email&quot;], mail, cc=[&quot;send email2&quot;]) 接收邮件123456789101112131415import zmailserver = zamil.server(&quot;your email&quot;, &quot;your password&quot;)# 获取最新邮件mail = server.get_latest() # 根据id取邮件mail = server.get_mail(2)# 根据(subject,after,before,sender)取邮件mail = server.get_mails(subject=&quot;Github&quot;, start_time=&quot;2022-6-1&quot;, sender=&quot;github&quot;, start_index=1, end_index=10)# 获取邮箱信息mailbox_info = server.stat() 解析邮件zamil将接收到的邮件映射为了一个字典，可直接获取到对应字段的值。1234567891011import zmailserver = zamil.server(&quot;your email&quot;, &quot;your password&quot;)mail = server.get_latest()# 打印邮件zmail.show(mail)# 查看邮件所有内容for k, v in mail.items(): print(k, v) 支持的邮件服务商另外将该模块支持的邮件服务商列出，方便以后有用到的话直接进行查阅。 ** 服务商地址** 发送邮件 接收邮件 备注 @163.com ✓ ✓ 需要应用专用密码 @126.com ✓ ✓ @qq.com ✓ ✓ pop3需要应用专用密码 @yeah.net ✓ ✓ @gmail.com ✓ ✓ 需要应用专用密码 @sina.com ✓ ✓ @outlook ✓ ✓ 需要应用专用密码 @hotmail ✓ ✓ 需要额外设置 支持的企业邮箱、 ** 名称** 使用示例 腾讯企业邮箱 zmail.server(‘username’,’psw’,config&#x3D;’qq’) 阿里企业邮箱 zmail.server(‘username’,’psw’,config&#x3D;’ali’) 网易企业邮箱 zmail.server(‘username’,’psw’,config&#x3D;’163’) 谷歌企业邮箱 zmail.server(‘username’,’psw’,config&#x3D;’google’) 总结以上只是简单列出zmail的发送和接收功能，更多详细的内容还需参考原作者的项目。通过上述发送和接收邮件的案例可以看出，它为我们省去很很多繁琐的工作，例如编解码，解析及构造邮件等。很多时候我们不可避免的需要重复造轮子，通过不断的学习积累更好的第三方模块，才能使我们的轮子造的有意义。","categories":[{"name":"python","slug":"python","permalink":"https://cezz.github.io/categories/python/"}],"tags":[]},{"title":"爬取github的关键字搜索结果","slug":"爬虫/爬取github的关键字搜索结果","date":"2022-06-13T14:51:06.000Z","updated":"2022-07-10T23:14:14.528Z","comments":true,"path":"2022/06/13/爬虫/爬取github的关键字搜索结果/","link":"","permalink":"https://cezz.github.io/2022/06/13/%E7%88%AC%E8%99%AB/%E7%88%AC%E5%8F%96github%E7%9A%84%E5%85%B3%E9%94%AE%E5%AD%97%E6%90%9C%E7%B4%A2%E7%BB%93%E6%9E%9C/","excerpt":"","text":"背景功能：根据github搜索关键字得到的结果进行解析，提取需要的字段，整个过程均自动化。思路： 在页面上模拟操作，此过程中使用抓包工具Fiddler分析相关反爬策略 可先获取到结果页面，进行离线解析，暂不依赖网络环境，提供工作效率 补充完善抓取策略，比如并发，代理池。后续思考使用框架是不是效率更高 注：github官方有提供APIserarch-code，但是其不能在全部的公共库中搜索，故使用爬虫爬取搜索数据，官方有提供API优先考虑能否从API中获取到的需要的数据。 安装依赖依赖的模块有requests，beautifulsoup4以及解析器lxml。 12345pip install requestspip install beautifulsoup4pip install lxml 登录认证首先在页面上模拟搜索关键字结果，发现type为code类型的需要登录认证，然后在页面上登录，并通过Fiddler抓包发现发现最终提交数据的url是session，且需要提交下图所示的数据，经测试提交关键信息即可。 1234commit: Sign inauthenticity_token: your tokenlogin: your usernamepassword: your password 上面所需要提交的数据发现authenticity_token不知道从哪里来，因为请求的url是login，而实际提交的url是session，很有可能是在请求登录页的时候动态生成的，去页面上搜索一下token果然有该参数。 至此，前路基本已经铺平，只需要进行实现即可，这里注意使用requests包中的session对象，该对象能够保持会话，就不用重复登录了。 具体实现个人认为主要分为2个部分： 获取到结果前：包括登录认证，获取所有请求链接等 获取到结果后：包括页面的解析，字段提取等 这里贴出多线程版本的代码，虽然优化空间还有很大，但也基本能运行： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139import jsonimport refrom queue import Queuefrom threading import Threadfrom urllib import parseimport requestsimport urllib3from bs4 import BeautifulSoupurllib3.disable_warnings()USERNAME = &quot;&quot;PASSWD = &quot;&quot;KEYWORD = &quot;&quot;PROXY = &#123;&#125; # https://free.kuaidaili.com/free/inha/class GithubCrawl: def __init__(self, username, passwd, keyword): self.username = username self.passwd = passwd self.queue = Queue() self.session = requests.Session() self.result = [] self.threads = 5 self.output_file = &quot;./temp.txt&quot; self.login_url = &quot;https://github.com/login&quot; self.post_url = &quot;https://github.com/session&quot; self.search_url = f&quot;https://github.com/search?q=&#123;keyword&#125;&amp;type=code&quot; self.headers = &#123; &quot;Referer&quot;: &quot;https://github.com/&quot;, &quot;Host&quot;: &quot;github.com&quot;, &quot;User-Agent&quot;: &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36&quot;, &#125; self.proxy = PROXY @staticmethod def _parse_content(tags): content = &quot;&quot; for tag in tags: content += tag.text return content def _get_token(self): resp = self.session.get(self.login_url, headers=self.headers, verify=False, proxies=self.proxy) soup = BeautifulSoup(resp.text, &quot;lxml&quot;) token = soup.find(&quot;input&quot;, attrs=&#123;&quot;name&quot;: &quot;authenticity_token&quot;&#125;).get(&quot;value&quot;) print(f&quot;token is: &#123;token&#125;&quot;) return token def login(self, token): post_data = &#123; &#x27;commit&#x27;: &#x27;Sign in&#x27;, &#x27;login&#x27;: self.username, &#x27;password&#x27;: self.passwd, &#x27;authenticity_token&#x27;: token &#125; resp = self.session.post(self.post_url, data=post_data, headers=self.headers, verify=False, proxies=self.proxy) if resp.status_code == 200: print(&quot;successful set up a session on github...&quot;) self.get_urls() def get_urls(self): resp = self.session.get(self.search_url, headers=self.headers, verify=False, proxies=self.proxy) soup = BeautifulSoup(resp.text, &quot;lxml&quot;) if re.search(&quot;login&quot;, soup.title.text, re.I): raise ConnectionError(&quot;the session is closed, please check network or add proxy!&quot;) total_pages = soup.find(attrs=&#123;&quot;aria-label&quot;: &quot;Pagination&quot;&#125;).text.split(&quot; &quot;)[-2] for i in range(1, int(total_pages) + 1): _url = self.search_url + f&quot;&amp;p=&#123;i&#125;&quot; print(f&quot;add the url to queue: &#123;_url&#125;&quot;) self.queue.put(_url) def get_data(self): while True: if self.queue.empty(): break url = self.queue.get() print(f&quot;get url: &#123;url&#125;&quot;) self.parse_search_page(url) def parse_search_page(self, url): resp = self.session.get(url, headers=self.headers, verify=False, proxies=self.proxy) soup = BeautifulSoup(resp.text, &quot;lxml&quot;) items = soup.find_all(class_=&quot;code-list-item&quot;) if not items: print(f&quot;not found data in the page &#123;url&#125;...&quot;) return print(f&quot;start parse url: &#123;url&#125;&quot;) for item in items: text_small = item.find(class_=&quot;text-small&quot;).text.strip().split(&quot;/&quot;) lang = item.find(attrs=&#123;&quot;itemprop&quot;: &quot;programmingLanguage&quot;&#125;) data = &#123; &quot;author_favicon&quot;: item.find(&quot;img&quot;).attrs[&quot;src&quot;], &quot;author&quot;: text_small[0].strip(), &quot;repository&quot;: text_small[1].strip(), &quot;filename&quot;: item.find(class_=&quot;text-normal&quot;).text.strip(), &quot;filepath&quot;: parse.urljoin(&quot;https://github.com&quot;, item.find(class_=&quot;text-normal&quot;).a.attrs[&quot;href&quot;]), &quot;content&quot;: self._parse_content(item.find_all(class_=&quot;blob-code&quot;)), &quot;language&quot;: lang.text if lang else lang, &quot;updated_at&quot;: item.find(class_=&quot;updated-at&quot;).find(class_=&quot;no-wrap&quot;).attrs[&quot;datetime&quot;] &#125; print(data) self.result.append(json.dumps(data)) def write_to_file(self): try: with open(self.output_file, &quot;w&quot;, encoding=&quot;utf-8&quot;) as f: f.writelines([line + &quot;\\n&quot; for line in self.result]) print(&quot;finished...&quot;) except Exception as e: print(&quot;write result to file failed...&quot;) raise e def start(self): token = self._get_token() self.login(token) t_list = [] for i in range(self.threads): t = Thread(target=self.get_data) t_list.append(t) t.start() for t in t_list: t.join() print(&quot;all task finished...&quot;) self.write_to_file()def main(): crawler = GithubCrawl(USERNAME, PASSWD, KEYWORD) crawler.start()if __name__ == &#x27;__main__&#x27;: main() 后续追加本以为到此大功告成，没成想交给同事运行测试的时候发现报错了，经个人简单排查后发现github对新设备登录有认证要求，需要提供邮件的验证码，故目前还得将自动化获取验证码这一步添加上去。 继续使用Fiddler进行抓包分析，发现验证设备提交的url是/sessions/verified-device，并需要提交下列数据。 12authentictiy_token: your tokenopt: your verification code 注：这里的authentictiy_token不是之前&#x2F;login页面的，而是在&#x2F;sessions&#x2F;verified-device页面中新生成的 最后，这里简单给出通过pop3协议获取邮箱验证码的代码，代码中确保了获取到的是在请求github页面后收到的验证码邮件，此外，还需在修改下上述github的login方法，完整代码见git。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192# email infoEMAIL_ACCOUNT = &quot;&quot;AUTH_CODE = &quot;&quot; # must authorization codePOP3_SSL_SERVER = &quot;&quot;PROTOCOL = &quot;pop3&quot;class EmailReceiver: def __init__(self, email_account, auth_code, pop3_ssl_server, send_login_time, protocol=&quot;pop3&quot;): self.email_account = email_account self.auth_code = auth_code self.pop3_ssl_server = pop3_ssl_server self.send_login_time = send_login_time self.email_total_number = None self.session = self.login_pop3() if protocol == &quot;pop3&quot; else None if not self.session: raise ConnectionError(&quot;[Email Receiver] failed connect to the email server&quot;) def login_pop3(self): a = poplib.POP3_SSL(self.pop3_ssl_server) a.user(self.email_account) a.pass_(self.auth_code) resp, mails, octets = a.list() self.email_total_number = len(mails) print(f&quot;[Email Receiver] the number of email is: &#123;self.email_total_number&#125;&quot;) return a if resp.decode(&quot;utf-8&quot;) == &quot;+OK&quot; else None def logout(self): if self.session: self.session.quit() @staticmethod def decode_str(s): value, charset = decode_header(s)[0] if charset: value = value.decode(charset) return value @staticmethod def _is_latest_email(content, send_login_time) -&gt; bool: date = content.get(&quot;Received&quot;, &quot;&quot;) ret = re.search(r&quot;(?:\\d+:)&#123;2,&#125;?\\d+&quot;, date) if not ret: print(f&quot;[Email Receiver] get the latest email recv time failed, date: &#123;date&#125;&quot;) return False recv_email_time = ret.group() time_diff = datetime.strptime(recv_email_time, &quot;%H:%M:%S&quot;) - datetime.strptime(send_login_time, &quot;%H:%M:%S&quot;) print(f&quot;recv: &#123;recv_email_time&#125;, login: &#123;send_login_time&#125;, &#123;time_diff&#125;&quot;) if time_diff.days &lt; 0: print(&quot;[Email Receiver] the latest email received was not after logged into github&quot;) return time_diff.days == 0 def _is_github_verify_email(self, content) -&gt; bool: subject = self.decode_str(content.get(&quot;Subject&quot;, &quot;&quot;)) from_ = self.decode_str(content.get(&quot;From&quot;, &quot;&quot;)) ret = re.search(r&quot;\\[GitHub] Please verify your device&quot;, subject) if not ret: print(f&quot;[Email Receiver] the latest email is not from github, subject: &#123;subject&#125;, From: &#123;from_&#125;&quot;) return False return True @staticmethod def get_email_content(session, total_number): print(f&quot;[Email Receiver] curr total_number is: &#123;total_number&#125;&quot;) resp, lines, octets = session.retr(total_number) msg_content = b&quot;\\r\\n&quot;.join(lines).decode(&quot;utf-8&quot;, &quot;ignore&quot;) content = Parser().parsestr(msg_content) return content def get_verification_code(self): content = self.get_email_content(self.session, self.email_total_number) flag = False for index in range(5): if self._is_github_verify_email(content) and self._is_latest_email(content, self.send_login_time): flag = True break time.sleep(6) temp_session = poplib.POP3_SSL(self.pop3_ssl_server) temp_session.user(self.email_account) temp_session.pass_(self.auth_code) emails, _ = temp_session.stat() if emails &gt; self.email_total_number: content = self.get_email_content(temp_session, emails) temp_session.quit() verification_code = re.search(r&quot;Verification code: (\\d+)&quot;, str(content)) if flag and verification_code: return verification_code.groups()[0] print(&quot;[Email Receiver] get github verification code failed, try 5 times&quot;) 注：经个人测试，使用poplib在同一次连接中无法实时获取最新邮件，目前的解决方法是重新建立了临时的连接进行获取。后续发现有python的第三方模块zmail支持实时获取，简单研究了下，详见后续文章。","categories":[{"name":"python","slug":"python","permalink":"https://cezz.github.io/categories/python/"},{"name":"爬虫","slug":"python/爬虫","permalink":"https://cezz.github.io/categories/python/%E7%88%AC%E8%99%AB/"}],"tags":[]},{"title":"快速上手BeautifulSoup4","slug":"爬虫/BeautifulSoup4解析","date":"2022-06-08T13:03:11.000Z","updated":"2022-07-03T13:25:05.188Z","comments":true,"path":"2022/06/08/爬虫/BeautifulSoup4解析/","link":"","permalink":"https://cezz.github.io/2022/06/08/%E7%88%AC%E8%99%AB/BeautifulSoup4%E8%A7%A3%E6%9E%90/","excerpt":"","text":"安装安装BeautifulSoup可通过系统的包管理工具安装： 1apt-get install Python-bs4 或者通过python的包管理工具pip进行安装： 1pip install beautifulsoup4 -i http://mirrors.aliyun.com/pypi/simple/ 安装解析器python内置了HTML解析器，若要使用第三方的解析器，如lxml，则需根据操作系统和python的版本选择对应的包进行安装，若要离线安装，windows下可点击该链接下载。 123apt-get install Python-lxmlpip install lxml 或纯python实现的html5lib，其解析方式与浏览器相同。 123apt-get install Python-html5libpip install html5lib 解析器 使用方法 优势 劣势 python标准库 BeautifulSoup(html, ‘html.parser’) python的内置标准库执行速度适中文档容错能力强 Python2.7.3或3.2.2前的版本中文容错能力差 lxml HTML解析器 BeautifulSoup(html, ‘lxml’) 速度快文档容错能力强 需要安装c语言库 lxml XML解析器 BeautifulSoup(html, [‘lxml’, ‘xml’]) 速度快唯一支持XML的解析器 需要安装c语言库 html5lib BeautifulSoup(html, ‘html5lib’) 最好的容错性以浏览器的方式解析文档生成HTML5格式的文档 速度慢不依赖外部扩展 使用技巧假设有一个网页html，创建一个BeautifulSoup对象，并指定解析器。 123456789from bs4 import BeautifulSoupsoup = BeautifulSoup(html, &quot;lxml)soup.prettify() # 缩进打印soup.title # 获取title标签的内容soup.div # 获取第一个div标签的内容soup.find(id=&quot;uq&quot;) # 获取id=&quot;u1&quot;的标签soup.find_all(class_=&quot;item&quot;) # 查找所有class属性有item的标签 注：灵活利用IDE的打断点进行debug可以快速调试，拿到自己需要的元素 对象种类~将复杂HTML文档转换成一个复杂的树形结构，每个节点都是python对象，所有对象可以归为以下四类： TagTag通俗点讲就是HTML中的一个个标签，它的类型是bs4.element.Tag，对于Tag有两个重要的属性，是name和attrs。 123456# 每个tag都有自己的名字，通过.name来获取tag.name# 一个tag可能有多个属性，其操作方式与字典相同，也可以通过点的方式获取tag[&quot;class&quot;]tag.attrs 注：如果标签中某个属性有多值，则解析后返回的类型是list，但是转换的文档是xml时除外。 NavigableString用于获取标签内部的文字，如下： 123soup.title.stringprint(type(bs.title.string)) BeautifulSoup表示的是一个文档的全部内容，大部分时候可以将其看作为一个特殊的Tag，可通过以下方式获取其名称和属性： 1234soup.namesoup.attrsprint(type(soup)) Comment是一个特殊类型的NavigableString对象，其输出的内容不包括注释符号 12345soup.a # &lt;a class=&quot;mnav&quot;&gt;&lt;!--新闻--&gt;&lt;/a&gt;soup.a.string # 新闻print(type(soup.a.string)) # &lt;class &#x27;bs4.element.Comment&#x27;&gt; 遍历文档树子节点.contents和.children contents：获取Tag的所有子节点，返回一个list 123soup.contentssoup.contents[0].name children：获取Tag的所有子节点，返回一个生成器 12for child in soup.body.children: print(child) .descendants .contents和.children属性仅包含tag的直接子节点，.descendants可以对所有tag的子孙节点进行递归循环。 .string 如果tag只有一个子节点，这个tag可以使用.string方法获取，如果有多个子节点，则返回为None .strings和.stripped_strings 若果tag中包含多个字符串，可以使用.strings循环获取 如果字符串包含很多空格或空行，可以使用.stripped_strings去除 父节点.parent 通过.parent获取某个元素的父节点 顶层节点的父节点是BeautifulSoup对象 BeautifulSoup对象的.parent是None .parents 通过.parents可以递归获取元素的所有父节点 兄弟节点.next_sibling和.previous_sibling 使用 .next_sibling 和 .previous_sibling 属性来查询兄弟节点 .next_siblings和.previous_siblings 通过 .next_siblings 和 .previous_siblings 属性可以对当前节点的兄弟节点迭代输出 搜索文档树这里主要列举find_all和find方法以及CSS选择器，其他方法可参考官方文档。 find_allfind_all(name, attrs, recursive, text, **kwargs) name参数 字符串过滤：会查找与字符串完全匹配的内容 12a_list = soup.find_all(&quot;a&quot;)print(a_list) 正则表达式过滤：如果传入的是正则表达式，那么BeautifulSoup4会通过search()来匹配内容 123a_list = soup.find_all(re.compile(&quot;a&quot;))for item in a_list: print(item) 列表：如果传入一个列表，BeautifulSoup4将会与列表中的任一元素匹配到的节点返回 123a_list = soup.find_all([&quot;meta&quot;, &quot;link&quot;])for item in a_list: print(item) 方法：传入一个方法，根据方法来匹配 123456def name_is_exists(tag): return tag.has_attr(&quot;name&quot;)a_list = soup.find_all(name_is_exists)for item in a_list: print(item) kwargs如果一个指定名字的参数不是搜索内置的参数名,搜索时会把该参数当作指定名字tag的属性来搜索 123456789101112# 查询id=head的Tagt_list = soup.find_all(id=&quot;head&quot;)print(t_list)# 查询href属性包含ss1.bdstatic.com的Tagt_list = soup.find_all(href=re.compile(&quot;http://news.baidu.com&quot;))print(t_list)# 查询所有包含class的Tag(注：class要加上_进行区分)t_list = soup.find_all(class_=True)for item in t_list: print(item) attrs不是所有的属性都可以使用上面的方式进行搜索，比如HTML的data-*属性，这时可以使用attrs参数，定义一个字典来搜索包含特殊属性的tag。 123t_list = soup.find_all(attrs=&#123;&quot;data-foo&quot;:&quot;value&quot;&#125;)for item in t_list: print(item) string通过string参数可以搜索文档中的字符串内容，与name参数的可选值一样，string参数接收字符串，正则表达式，列表，True。 12345t_list = soup.find_all(string=&quot;Elsie&quot;) t_list = soup.find_all(string=[&quot;Tillie&quot;, &quot;Elsie&quot;, &quot;Lacie&quot;])t_list = soup.find_all(string=re.compile(&quot;Dormouse&quot;)) limit传入一个limit参数来限制返回的数量。 123t_list = soup.find_all(&quot;a&quot;, limit=2)for item in t_list: print(item) recursive默认会检索当前tag的所有子孙节点，如果只想搜索直接子节点，可以使用该参数。 1soup.html.find_all(recursive=False) findfind( name , attrs , recursive , string , **kwargs )返回符合条件的第一个Tag，即当我们要取一个值的时候就可以用该方法 1soup.find(&quot;head&quot;).find(&quot;title&quot;) CSS选择器 通过tag标签名查找 123soup.select(&quot;title&quot;)soup.select(&quot;a&quot;) 通过tag标签逐层查找： 123soup.select(&quot;body a&quot;)soup.select(&quot;html head title&quot;) 找到某个tag标签下的直接子标签： 123soup.select(&quot;head &gt; title&quot;)soup.select(&quot;p &gt; #link1&quot;) 找到兄弟节点标签： 123soup.select(&quot;#link1 ~ .sister&quot;)soup.select(&quot;#link1 + .sister&quot;) 通过class属性查找： 123soup.select(&quot;.sister&quot;)soup.select(&quot;[class~=sister]&quot;) 通过tag的id查找： 123soup.select(&#x27;#link1&#x27;)soup.select(&quot;a#link2&quot;) 同时用多种css选择器查询： 1soup.select(&quot;#link1,#link2&quot;) 通过是否存在某个属性来查找： 1soup.select(&quot;a[href]&quot;) 通过属性的值来查找： 1234567soup.select(&#x27;a[href=&quot;http://example.com/elsie&quot;]&#x27;)soup.select&#x27;a[href^=&quot;http://example.com&quot;]&#x27;)soup.select(&#x27;a[href$=&quot;tillie&quot;]&#x27;)soup.select(&#x27;a[href*=&quot;.com/el&quot;]&#x27;) 通过语言设置来查找： 1234567891011multilingual_markup = &quot;&quot;&quot; &lt;p lang=&quot;en&quot;&gt;Hello&lt;/p&gt; &lt;p lang=&quot;en-us&quot;&gt;Howdy, y&#x27;all&lt;/p&gt; &lt;p lang=&quot;en-gb&quot;&gt;Pip-pip, old fruit&lt;/p&gt; &lt;p lang=&quot;fr&quot;&gt;Bonjour mes amis&lt;/p&gt;&quot;&quot;&quot;multilingual_soup = BeautifulSoup(multilingual_markup)multilingual_soup.select(&#x27;p[lang|=en]&#x27;)# [&lt;p lang=&quot;en&quot;&gt;Hello&lt;/p&gt;,# &lt;p lang=&quot;en-us&quot;&gt;Howdy, y&#x27;all&lt;/p&gt;,# &lt;p lang=&quot;en-gb&quot;&gt;Pip-pip, old fruit&lt;/p&gt;] 返回查找到的元素的第一个 1soup.select_one(&quot;.sister&quot;) 修改文档树BeautifulSoup的强项是文档树的搜索，但同时也可以方便的修改文档树，这部分可详细参考官方文档。","categories":[{"name":"python","slug":"python","permalink":"https://cezz.github.io/categories/python/"},{"name":"爬虫","slug":"python/爬虫","permalink":"https://cezz.github.io/categories/python/%E7%88%AC%E8%99%AB/"}],"tags":[]},{"title":"项目实战：go语言实现redis(四)","slug":"go/项目实战：go语言实现redis(四)","date":"2022-05-27T12:51:46.000Z","updated":"2022-06-28T15:48:16.023Z","comments":true,"path":"2022/05/27/go/项目实战：go语言实现redis(四)/","link":"","permalink":"https://cezz.github.io/2022/05/27/go/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%EF%BC%9Ago%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0redis(%E5%9B%9B)/","excerpt":"","text":"背景本系列文章记录如何基于go语言实现Redis，从整体设计到具体细节实现，不仅可以有效的锻炼自己的编码能力，又能加深对redis的认识。文章主要从整体设计思路入手，记录关键的设计步骤，详细的实现可以参考github上的相关代码。主体上有下面几个部分： TCP服务器(一)：支持同时监听多个TCP连接，并进行相关处理 Redis协议解析器(一)：实现相关Handler，命令解析及响应处理 内存数据库(二)：实现数据库，注册相关命令，完成支持对数据库的增删改查 Redis持久化(三)：实现redis中的持久化功能aof **Redis集群(四)**：本文将通过一致性哈希的方式实现cluster集群 本章的项目目录结构如下，在前一篇的基础上新增了cluster相关文件： 1234567891011121314151617181920212223242526272829303132333435363738394041424344├─aof│├─cluster│ client_pool.go│ cluster_database.go│ com.go│ del.go│ keys.go│ ping.go│ rename.go│ router.go│├─config│├─database│├─datastruct│ └─dict│├─interface│ ├─database│ ││ ├─dict│ ││ ├─resp│ ││ └─tcp│├─lib│├─resp│ ├─connection│ ││ ├─handler│ ││ ├─parser│ ││ └─reply│├─tcp││ go.mod│ main.go│ redis.conf 实现一致性hash结构体定义在文件lib/comsistenthash/comsistenthash.go中定义结构体NodeMap，包含下面几个属性，并进行初始化，此处设置了一个默认的哈希函数crc32.ChecksumIEEE。 hashFunc：类型为func，需要指定一个hash函数 nodeHashs：类型为int类型的切片，存储节点哈希后的值，且该切片有序的 nodehashMap：类型为map，key为哈希值，value是节点的地址 123456789101112131415161718192021// HashFunc defines function to generate hash codetype HashFunc func(data []byte) uint32// NodeMap stores nodes and you can pick node from NodeMaptype NodeMap struct &#123; hashFunc HashFunc nodeHashs []int // sorted nodehashMap map[int]string&#125;// NewNodeMap creates a new NodeMapfunc NewNodeMap(fn HashFunc) *NodeMap &#123; m := &amp;NodeMap&#123; hashFunc: fn, nodehashMap: make(map[int]string), &#125; if m.hashFunc == nil &#123; m.hashFunc = crc32.ChecksumIEEE &#125; return m&#125; 方法实现需要实现添加节点到哈希环中和从哈希环取出节点的方法： 12345678// IsEmpty returns if there is no node in NodeMapfunc (m *NodeMap) IsEmpty() bool &#123;&#125;// AddNode add the given nodes into consistent hash circlefunc (m *NodeMap) AddNode(keys ...string) &#123;&#125;// PickNode gets the closest item in the hash to the provided key.func (m *NodeMap) PickNode(key string) string &#123;&#125; 集群核心架构连接池为了支持高并发的连接及能够对连接进行复用，此处引进了一个第三方连接池，通过命令go get &quot;github.com/jolestar/go-commons-pool/v2&quot;进行下载。另外，在cluster/client_pool.go中定义结构体connectionFactory实现其接口PooledObjectFactory。 12345678910111213type connectionFactory struct &#123; Peer string&#125;func (f *connectionFactory) MakeObject(ctx context.Context) (*pool.PooledObject, error) &#123;&#125;func (f *connectionFactory) DestroyObject(ctx context.Context, object *pool.PooledObject) error &#123;&#125;func (f *connectionFactory) ValidateObject(ctx context.Context, object *pool.PooledObject) bool &#123;&#125;func (f *connectionFactory) ActivateObject(ctx context.Context, object *pool.PooledObject) error &#123;&#125;func (f *connectionFactory) PassivateObject(ctx context.Context, object *pool.PooledObject) error &#123;&#125; 实现ClusterDatabase需要对原来单体的Database进行进一步封装，新建文件cluster/cluster_database.go。 1234567891011121314151617181920212223242526272829303132333435// ClusterDatabase represents a node of godis cluster// it holds part of data and coordinates other nodes to finish transactionstype ClusterDatabase struct &#123; self string nodes []string peerPicker *consistenthash.NodeMap peerConnection map[string]*pool.ObjectPool db databaseface.Database&#125;// MakeClusterDatabase creates and starts a node of clusterfunc MakeClusterDatabase() *ClusterDatabase &#123; cluster := &amp;ClusterDatabase&#123; self: config.Properties.Self, db: database.NewStandaloneDatabase(), peerPicker: consistenthash.NewNodeMap(nil), peerConnection: make(map[string]*pool.ObjectPool), &#125; nodes := make([]string, 0, len(config.Properties.Peers)+1) for _, peer := range config.Properties.Peers &#123; nodes = append(nodes, peer) &#125; nodes = append(nodes, config.Properties.Self) cluster.peerPicker.AddNode(nodes...) ctx := context.Background() for _, peer := range config.Properties.Peers &#123; cluster.peerConnection[peer] = pool.NewObjectPoolWithDefaultConfig(ctx, &amp;connectionFactory&#123; Peer: peer, &#125;) &#125; cluster.nodes = nodes return cluster&#125; 另外还需实现以下几个方法。 12345678// Close stops current node of clusterfunc (cluster *ClusterDatabase) Close() &#123;&#125;// Exec executes command on clusterfunc (cluster *ClusterDatabase) Exec(c resp.Connection, cmdLine [][]byte) (result resp.Reply) &#123;&#125;// AfterClientClose does some clean after client close connectionfunc (cluster *ClusterDatabase) AfterClientClose(c resp.Connection) &#123;&#125; 操作连接池cluster/com.go 1234567891011func (cluster *ClusterDatabase) getPeerClient(peer string) (*client.Client, error) &#123;&#125;func (cluster *ClusterDatabase) returnPeerClient(peer string, peerClient *client.Client) error &#123;&#125;// relay relays command to peer// select db by c.GetDBIndex()// cannot call Prepare, Commit, execRollback of self nodefunc (cluster *ClusterDatabase) relay(peer string, c resp.Connection, args [][]byte) resp.Reply &#123;&#125;// broadcast broadcasts command to all node in clusterfunc (cluster *ClusterDatabase) broadcast(c resp.Connection, args [][]byte) map[string]resp.Reply &#123;&#125; 指令路由需要根据不同的指令，操作对应的节点，这里需要有一个全局的方式，找到执行指令的相关函数，新建文件cluster/router.go。 123456789101112131415161718192021222324252627func makeRouter() map[string]CmdFunc &#123; routerMap := make(map[string]CmdFunc) routerMap[&quot;ping&quot;] = ping routerMap[&quot;del&quot;] = Del routerMap[&quot;exists&quot;] = defaultFunc routerMap[&quot;type&quot;] = defaultFunc routerMap[&quot;rename&quot;] = Rename routerMap[&quot;renamenx&quot;] = Rename routerMap[&quot;set&quot;] = defaultFunc routerMap[&quot;setnx&quot;] = defaultFunc routerMap[&quot;get&quot;] = defaultFunc routerMap[&quot;getset&quot;] = defaultFunc routerMap[&quot;flushdb&quot;] = FlushDB return routerMap&#125;// relay command to responsible peer, and return its reply to clientfunc defaultFunc(cluster *ClusterDatabase, c resp.Connection, args [][]byte) resp.Reply &#123; key := string(args[1]) peer := cluster.peerPicker.PickNode(key) return cluster.relay(peer, c, args)&#125; 修改特殊的指令操作，分别在下述文件中添加对应的函数。 cluster/ping.go：直接执行即可 cluster/del.go：需要广播至集群的所有节点 cluster/rename.go：需要找到键所在的节点执行，并处理重命名后更换节点的情况 cluster/keys.go：需要广播至集群的所有节点 1234567891011func ping(cluster *ClusterDatabase, c resp.Connection, cmdAndArgs [][]byte) resp.Reply &#123;&#125;// Del atomically removes given writeKeys from cluster, writeKeys can be distributed on any node// if the given writeKeys are distributed on different node, Del will use try-commit-catch to remove themfunc Del(cluster *ClusterDatabase, c resp.Connection, args [][]byte) resp.Reply &#123;&#125;// Rename renames a key, the origin and the destination must within the same nodefunc Rename(cluster *ClusterDatabase, c resp.Connection, args [][]byte) resp.Reply &#123;&#125;// FlushDB removes all data in current databasefunc FlushDB(cluster *ClusterDatabase, c resp.Connection, args [][]byte) resp.Reply &#123;&#125; 启用集群模式要使用集群需要修改resp/handler/handler.go中初始化Database的逻辑。 1234567891011121314// MakeHandler creates a RespHandler instancefunc MakeHandler() *RespHandler &#123; var db databaseface.Database if config.Properties.Self != &quot;&quot; &amp;&amp; len(config.Properties.Peers) &gt; 0 &#123; db = cluster.MakeClusterDatabase() &#125; else &#123; db = database.NewStandaloneDatabase() &#125; return &amp;RespHandler&#123; db: db, &#125;&#125; 总结至此，基于go语言实现redis的项目已基本完成了。项目中有许多值得学习的地方，例如整个架构的设计，整体功能的切分及具体实现。每一步的过程都需要有自己的思考，而不是按部就班，随便记录以下就完了，记录下这个系列的文章，也是为了以后的回顾，温故而知新才能不断的加深影响提高自己。不过项目也依然有很多需要优化的地方，这个可以参考开源的项目godis。","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"},{"name":"项目实战","slug":"go/项目实战","permalink":"https://cezz.github.io/categories/go/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"}],"tags":[]},{"title":"hexo+github page博客搭建","slug":"其他/hexo+github page博客搭建","date":"2022-05-23T03:39:36.000Z","updated":"2023-05-04T10:13:00.146Z","comments":true,"path":"2022/05/23/其他/hexo+github page博客搭建/","link":"","permalink":"https://cezz.github.io/2022/05/23/%E5%85%B6%E4%BB%96/hexo+github%20page%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/","excerpt":"","text":"环境准备 需要安装以下组件： Node.js git 在cmd窗口验证执行以下命令查看是否安装成功node -v、npm -v、git --version 创建github pages仓库 本地安装hexo：npm install -g hexo-clihexo inithexo ghexo s 部署hexo到github page 安装hexo-deployer-gitnpm install hexo-deployer-git --save修改_conifg.yml文件末尾的Deployment部分，如下： 1234deploy: type: git repository: git@github.com:用户名/用户名.github.io.git branch: master 完成后运行hexo d将网站上传部署到github page此时访问https://用户名.github.io就可以访问hexo网站了 绑定域名 先注册并解析域名，个人从腾讯云购买。进入本地博客文件夹的source目录，新建CNAME文件(无后缀)，内容为自己的域名。可在github仓库页面找到Settings然后下拉找到Github Pages开启HTTPS 开始使用发布文章创建新博客：hexo new &quot;My New Blog&quot;执行以下命令渲染文章并将其部署到GitHub Pages： 12hexo g # 生成页面hexo d # 部署发布 hexo d网站设置包括网站名称、描述、作者、链接样式等，全部在网站目录下的_config.yml文件中，参考官方文档进行编辑。更换主题在Themes|Hexo 选择一个喜欢的主题，个人选择了pure，执行以下命令git clone https://github.com/cofess/hexo-theme-pure.git themes/pure然后修改_config.yml中的theme为新主题pure即可常用命令 12345678hexo new &quot;name&quot; # 新建文章hexo new page &quot;name&quot; # 新建页面hexo g # 生成页面hexo d # 部署hexo g -d # 生成页面并部署hexo s # 本地预览hexo clean # 清楚缓存和已生成的静态文件hexo help # 帮助","categories":[{"name":"其他","slug":"其他","permalink":"https://cezz.github.io/categories/%E5%85%B6%E4%BB%96/"}],"tags":[]},{"title":"项目实战：go语言实现redis(三)","slug":"go/项目实战：go语言实现redis(三)","date":"2022-05-21T02:14:09.000Z","updated":"2022-06-28T15:53:39.796Z","comments":true,"path":"2022/05/21/go/项目实战：go语言实现redis(三)/","link":"","permalink":"https://cezz.github.io/2022/05/21/go/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%EF%BC%9Ago%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0redis(%E4%B8%89)/","excerpt":"","text":"背景本系列文章记录如何基于go语言实现Redis，从整体设计到具体细节实现，不仅可以有效的锻炼自己的编码能力，又能加深对redis的认识。文章主要从整体设计思路入手，记录关键的设计步骤，详细的实现可以参考github上的相关代码。主体上有下面几个部分： TCP服务器(一)：支持同时监听多个TCP连接，并进行相关处理 Redis协议解析器(一)：实现相关Handler，命令解析及响应处理 内存数据库(二)：实现数据库，注册相关命令，完成支持对数据库的增删改查 **Redis持久化(三)**：实现redis中的持久化功能aof Redis集群(四) 本章的项目目录结构如下，主要是在前一篇文章新增了aof相关文件： 1234567891011121314151617181920212223242526272829303132333435├─aof│ aof.go│├─config│├─database│├─datastruct│ └─dict│├─interface│ ├─database│ ││ ├─dict│ ││ ├─resp│ ││ └─tcp│├─lib│├─resp│ ├─connection│ ││ ├─handler│ ││ ├─parser│ ││ └─reply│├─tcp│ │ go.mod│ main.go│ redis.conf 命令记录与恢复需要实现一个AofHandler结构体，由它封装命令保存及数据恢复的相关方法，然后在初始化Database的时候将AofHandler进行注册。在文件aof/aof.go中的实现如下。 12345678910111213141516// CmdLine is alias for [][]byte, represents a command linetype CmdLine = [][]bytetype payload struct &#123; cmdLine CmdLine dbIndex int&#125;// AofHandler receive msgs from channel and write to AOF filetype AofHandler struct &#123; db databaseface.Database aofChan chan *payload aofFile *os.File aofFilename string currentDB int&#125; 另外初始化AofHandler的时候还需要考虑根据已有的Aof文件进行恢复，以及启用一个协程不断的记录执行过的命令。 1234567891011121314151617// NewAOFHandler creates a new aof.AofHandlerfunc NewAOFHandler(db databaseface.Database) (*AofHandler, error) &#123; handler := &amp;AofHandler&#123;&#125; handler.aofFilename = config.Properties.AppendFilename handler.db = db handler.LoadAof() aofFile, err := os.OpenFile(handler.aofFilename, os.O_APPEND|os.O_CREATE|os.O_RDWR, 0600) if err != nil &#123; return nil, err &#125; handler.aofFile = aofFile handler.aofChan = make(chan *payload, aofQueueSize) go func() &#123; handler.handleAof() &#125;() return handler, nil&#125; 另外还需实现下述方法： AddAof：如果配置中开启Aof的话，将执行的命令发送到channel中 handleAof：从channel中读取数据，并写入到文件当中 LoadAof：从文件中读取命令，然后执行123456789// AddAof send command to aof goroutine through channelfunc (handler *AofHandler) AddAof(dbIndex int, cmdLine CmdLine) &#123;&#125;// handleAof listen aof channel and write into filefunc (handler *AofHandler) handleAof() &#123;&#125;// LoadAof read aof filefunc (handler *AofHandler) LoadAof() &#123;&#125; 底层指令集修改首先修改database/db.go中的结构体DB，新增属性addAof，以便指令集中的方法能够调用到addAof，需要修改的地方如下，另外初始化该方法的工作将在后续完成。123456789101112131415// DB stores data and execute user&#x27;s commandstype DB struct &#123; index int data iDict.Dict // key -&gt; DataEntity addAof func(CmdLine)&#125;// makeDB create DB instancefunc makeDB() *DB &#123; db := &amp;DB&#123; data: dict.MakeSyncDict(), addAof: func(line CmdLine) &#123;&#125;, &#125; return db&#125; 在database/string.go中对应的需要记录该指令的方法中添加Addof：123456789101112131415// execSet sets string value and time to live to the given keyfunc execSet(db *DB, args [][]byte) resp.Reply &#123; ... db.addAof(utils.ToCmdLine2(&quot;set&quot;, args...)) ...&#125;// execSetNX sets string if not existsfunc execSetNX(db *DB, args [][]byte) resp.Reply &#123; ... db.addAof(utils.ToCmdLine2(&quot;setnx&quot;, args...)) ...&#125;... 注：同样的database/keys.go中的相关方法也许调用Addof方法。 调用AofHandler初始化database时将AofHandler注册到Database结构体中，然后把方法Addof赋值给DB结构体，这样上述指令集就能调用到该方法了。文件database/databse.go中需要修改的地方如下。 12345678910111213141516171819202122232425// Database is a set of multiple database settype Database struct &#123; dbSet []*DB aofHandler *aof.AofHandler // handle aof persistence&#125;// NewDatabase creates a redis database,func NewDatabase() *Database &#123; ... if config.Properties.AppendOnly &#123; aofHandler, err := aof.NewAOFHandler(mdb) if err != nil &#123; panic(err) &#125; mdb.aofHandler = aofHandler for _, db := range mdb.dbSet &#123; // avoid closure singleDB := db singleDB.addAof = func(line CmdLine) &#123; mdb.aofHandler.AddAof(singleDB.index, line) &#125; &#125; &#125; return mdb&#125; 注：上述for循环遍历数据库的切片时，需要暂时把db赋值给一个临时变量，不然拿到的db都是最后一个值，这是go语言中循环变量的作用域导致的，需要注意。 在go语言的for循环中，循环内部创建的函数变量都是共享同一内存地址，for循环总是使用同一块内存去接收循环中的变量的值。不管循环多少次，变量的内存地址都是相同的。 此处使用的解决方法就是用一个临时变量进行赋值保存记录。 总结redis支持两种持久化的方式，一种是aof，它对数据有修改的相关指令记录到文件中，重新执行这些命令达到数据恢复的效果。另一种是rdb，这种方式是记录了内存快照，在指定的时间间隔内，将内存中的数据写入到磁盘中，就是在指定目录下生产一个dump.rdb文件，通过加载该文件进行恢复数据。本文基于go语言实现了aof持久化功能，通过可插拔的方式集成到之前已基本实现的单体redis当中。接下来将实现redis的集群模式。","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"},{"name":"项目实战","slug":"go/项目实战","permalink":"https://cezz.github.io/categories/go/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"}],"tags":[]},{"title":"项目实战：go语言实现redis(二)","slug":"go/项目实战：go语言实现redis(二)","date":"2022-05-12T15:06:31.000Z","updated":"2022-06-28T15:56:20.131Z","comments":true,"path":"2022/05/12/go/项目实战：go语言实现redis(二)/","link":"","permalink":"https://cezz.github.io/2022/05/12/go/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%EF%BC%9Ago%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0redis(%E4%BA%8C)/","excerpt":"","text":"背景本系列文章记录如何基于go语言实现Redis，从整体设计到具体细节实现，不仅可以有效的锻炼自己的编码能力，又能加深对redis的认识。文章主要从整体设计思路入手，记录关键的设计步骤，详细的实现可以参考github上的相关代码。主体上有下面几个部分： TCP服务器(一)：支持同时监听多个TCP连接，并进行相关处理 Redis协议解析器(一)：实现相关Handler，命令解析及响应处理 **内存数据库(二)**：实现数据库，注册相关命令，完成支持对数据库的增删改查 Redis持久化(三) Redis集群(四) 本章的项目目录结构如下： 123456789101112131415161718192021222324252627282930313233343536373839404142├─config│├─database│ command.go│ database.go│ db.go│ echo_database.go│ keys.go│ ping.go│ string.go│├─datastruct│ └─dict│ simple_dict.go│ sync_dict.go│├─interface│ ├─database│ ││ ├─dict│ │ dict.go│ ││ ├─resp│ ││ └─tcp│├─lib│├─resp│ ├─connection│ ││ ├─handler│ ││ ├─parser│ ││ └─reply│├─tcp│ │ go.mod│ main.go│ redis.conf 数据底层存储定义及实现Dict接口在interface/dict/dict.go中定义Dict接口，包含下述方法： 1234567891011121314151617// Consumer is used to traversal dict, if it returns false the traversal will be breaktype Consumer func(key string, val interface&#123;&#125;) bool// Dict is interface of a key-value data structuretype Dict interface &#123; Get(key string) (val interface&#123;&#125;, exists bool) Len() int Put(key string, val interface&#123;&#125;) (result int) PutIfAbsent(key string, val interface&#123;&#125;) (result int) PutIfExists(key string, val interface&#123;&#125;) (result int) Remove(key string) (result int) ForEach(consumer Consumer) Keys() []string RandomKeys(limit int) []string RandomDistinctKeys(limit int) []string Clear()&#125; 然后在datastruct/dict/sync_dict.go中实现一个并发安全的dict。 123456789101112131415161718192021222324252627282930313233343536373839404142// SyncDict wraps a map, it is not thread safetype SyncDict struct &#123; m sync.Map&#125;// MakeSyncDict makes a new mapfunc MakeSyncDict() *SyncDict &#123; return &amp;SyncDict&#123;&#125;&#125;// Get returns the binding value and whether the key is existfunc (dict *SyncDict) Get(key string) (val interface&#123;&#125;, exists bool) &#123;&#125;// Len returns the number of dictfunc (dict *SyncDict) Len() int &#123;&#125;// Put puts key value into dict and returns the number of new inserted key-valuefunc (dict *SyncDict) Put(key string, val interface&#123;&#125;) (result int) &#123;&#125;// PutIfAbsent puts value if the key is not exists and returns the number of updated key-valuefunc (dict *SyncDict) PutIfAbsent(key string, val interface&#123;&#125;) (result int) &#123;&#125;// PutIfExists puts value if the key is exist and returns the number of inserted key-valuefunc (dict *SyncDict) PutIfExists(key string, val interface&#123;&#125;) (result int) &#123;&#125;// Remove removes the key and return the number of deleted key-valuefunc (dict *SyncDict) Remove(key string) (result int) &#123;&#125;// Keys returns all keys in dictfunc (dict *SyncDict) Keys() []string &#123;&#125;// ForEach traversal the dictfunc (dict *SyncDict) ForEach(consumer iDict.Consumer) &#123;&#125;// RandomKeys randomly returns keys of the given number, may contain duplicated keyfunc (dict *SyncDict) RandomKeys(limit int) []string &#123;&#125;// RandomDistinctKeys randomly returns keys of the given number, won&#x27;t contain duplicated keyfunc (dict *SyncDict) RandomDistinctKeys(limit int) []string &#123;&#125;// Clear removes all keys in dictfunc (dict *SyncDict) Clear() &#123;&#125; 注：非并发安全的实现可参考datastruct/dict/simple_dict.go 定义DB结构体在database/db.go定义DB结构体，它是对底层Dict相关操作的进一步封装，根据接收到的实际命令找到对应的方法并执行，其核心是Exec方法。 12345678910111213141516171819202122232425262728293031323334// DB stores data and execute user&#x27;s commandstype DB struct &#123; index int data dict.Dict // key -&gt; DataEntity&#125;// makeDB create DB instancefunc makeDB() *DB &#123; db := &amp;DB&#123;data: dict.MakeSyncDict()&#125; return db&#125;// Exec executes command within one databasefunc (db *DB) Exec(c resp.Connection, cmdLine [][]byte) resp.Reply &#123;&#125;// GetEntity returns DataEntity bind to given keyfunc (db *DB) GetEntity(key string) (*database.DataEntity, bool) &#123;&#125;// PutEntity a DataEntity into DBfunc (db *DB) PutEntity(key string, entity *database.DataEntity) int &#123;&#125;// PutIfExists edit an existing DataEntityfunc (db *DB) PutIfExists(key string, entity *database.DataEntity) int &#123;&#125;// Remove the given key from dbfunc (db *DB) Remove(key string) &#123;&#125;// Removes the given keys from dbfunc (db *DB) Removes(keys ...string) (deleted int) &#123;&#125;// Flush clean databasefunc (db *DB) Flush() &#123;&#125;func validateArity(arity int, cmdArgs [][]byte) bool &#123;&#125; 命令注册及实现命令的注册database/command.go主要包含以下三个部分： cmdTable：类型为字典，功能为存储命令及对应命令的结构体 command：类型为结构体，包含命令对应的实际方法以及参数数量 RegisterCommand：类型为一个函数，用于实现命令注册全局表中1234567891011121314151617var cmdTable = make(map[string]*command)type command struct &#123; executor ExecFunc arity int // allow number of args, arity &lt; 0 means len(args) &gt;= -arity&#125;// RegisterCommand registers a new command// arity means allowed number of cmdArgs, arity &lt; 0 means len(args) &gt;= -arity.// for example: the arity of `get` is 2, `mget` is -2func RegisterCommand(name string, executor ExecFunc, arity int) &#123; name = strings.ToLower(name) cmdTable[name] = &amp;command&#123; executor: executor, arity: arity, &#125;&#125; 命令的实现ping的实现与注册在文件database/ping.go中的init()方法下将命令及其对应的处理函数注册到全局表中：123456func init() &#123; RegisterCommand(&quot;ping&quot;, Ping, -1)&#125;// Ping the serverfunc Ping(db *DB, args [][]byte) resp.Reply &#123;&#125; keys指令集的实现与注册在文件database/keys.go中的init()方法下将命令及其对应的处理函数注册到全局表中：123456789func init() &#123; RegisterCommand(&quot;Del&quot;, execDel, -2) RegisterCommand(&quot;Exists&quot;, execExists, -2) RegisterCommand(&quot;Keys&quot;, execKeys, 2) RegisterCommand(&quot;FlushDB&quot;, execFlushDB, -1) RegisterCommand(&quot;Type&quot;, execType, 2) RegisterCommand(&quot;Rename&quot;, execRename, 3) RegisterCommand(&quot;RenameNx&quot;, execRenameNx, 3)&#125; 并实现相关函数：1234567891011121314151617181920// execDel removes a key from dbfunc execDel(db *DB, args [][]byte) resp.Reply &#123;&#125;// execExists checks if a is existed in dbfunc execExists(db *DB, args [][]byte) resp.Reply &#123;&#125;// execFlushDB removes all data in current dbfunc execFlushDB(db *DB, args [][]byte) resp.Reply &#123;&#125;// execType returns the type of entity, including: string, list, hash, set and zsetfunc execType(db *DB, args [][]byte) resp.Reply &#123;&#125;// execRename a keyfunc execRename(db *DB, args [][]byte) resp.Reply &#123;&#125;// execRenameNx a key, only if the new key does not existfunc execRenameNx(db *DB, args [][]byte) resp.Reply &#123;&#125;// execKeys returns all keys matching the given patternfunc execKeys(db *DB, args [][]byte) resp.Reply &#123;&#125; string指令集的实现与注册在文件database/string.go中的init()方法下将命令及其对应的处理函数注册到全局表中：1234567func init() &#123; RegisterCommand(&quot;Get&quot;, execGet, 2) RegisterCommand(&quot;Set&quot;, execSet, -3) RegisterCommand(&quot;SetNx&quot;, execSetNX, 3) RegisterCommand(&quot;GetSet&quot;, execGetSet, 3) RegisterCommand(&quot;StrLen&quot;, execStrLen, 2)&#125; 并实现相关函数：12345678910111213141516func (db *DB) getAsString(key string) ([]byte, reply.ErrorReply) &#123;&#125;// execGet returns string value bound to the given keyfunc execGet(db *DB, args [][]byte) resp.Reply &#123;&#125;// execSet sets string value and time to live to the given keyfunc execSet(db *DB, args [][]byte) resp.Reply &#123;&#125;// execSetNX sets string if not existsfunc execSetNX(db *DB, args [][]byte) resp.Reply &#123;&#125;// execGetSet sets value of a string-type key and returns its old valuefunc execGetSet(db *DB, args [][]byte) resp.Reply &#123;&#125;// execStrLen returns len of string value bound to the given keyfunc execStrLen(db *DB, args [][]byte) resp.Reply &#123;&#125; 实现数据库核心在database/database.go中定义结构体Database，需实现第一篇文章中定义的Database接口，并进行初始化，创建16个数据库表，另外还需要注意执行命令时所在db的选择，这里封装了一个选择db的函数execSelect。123456789101112131415161718192021222324252627282930// Database is a set of multiple database settype Database struct &#123; dbSet []*DB&#125;// NewDatabase creates a redis database,func NewDatabase() *Database &#123; mdb := &amp;Database&#123;&#125; if config.Properties.Databases == 0 &#123; config.Properties.Databases = 16 &#125; mdb.dbSet = make([]*DB, config.Properties.Databases) for i := range mdb.dbSet &#123; singleDB := makeDB() singleDB.index = i mdb.dbSet[i] = singleDB &#125; return mdb&#125;// Exec executes command// parameter `cmdLine` contains command and its arguments, for example: &quot;set key value&quot;func (mdb *Database) Exec(c resp.Connection, cmdLine [][]byte) (result resp.Reply) &#123;&#125;// Close graceful shutdown databasefunc (mdb *Database) Close() &#123;&#125;func (mdb *Database) AfterClientClose(c resp.Connection) &#123;&#125;func execSelect(c resp.Connection, mdb *Database, args [][]byte) resp.Reply &#123;&#125; 然后将resp/handler/handler.go中的初始化数据库改为上述实现的数据库即可。总结到目前为止一个单体的redis应用已基本完成，可以暂不关注每个方法的具体实现，但是一定要理解整个调用逻辑，做到融会贯通。首先处理TCP连接，选择对应的handler，由handler初始化database，同时对conn封装，选择对应的数据库执行命令，在项目一开始运行的时候会将代码中已实现的命令注册到全局表中。接下来将实现redis的持久化与集群的相关功能。","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"},{"name":"项目实战","slug":"go/项目实战","permalink":"https://cezz.github.io/categories/go/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"}],"tags":[]},{"title":"项目实战：go语言实现redis(一)","slug":"go/项目实战：go语言实现redis(一)","date":"2022-05-08T14:41:18.000Z","updated":"2022-06-28T16:06:11.479Z","comments":true,"path":"2022/05/08/go/项目实战：go语言实现redis(一)/","link":"","permalink":"https://cezz.github.io/2022/05/08/go/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%EF%BC%9Ago%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0redis(%E4%B8%80)/","excerpt":"","text":"背景本系列文章记录如何基于go语言实现Redis，从整体设计到具体细节实现，不仅可以有效的锻炼自己的编码能力，又能加深对redis的认识。文章主要从整体设计思路入手，记录关键的设计步骤，详细的实现可以参考github上的相关代码。主体上有下面几个部分： **TCP服务器(一)**：支持同时监听多个TCP连接，并进行相关处理 **Redis协议解析器(一)**：实现相关Handler，命令解析及响应处理 内存数据库(二) Redis持久化(三) Redis集群(四) 实现TCP服务器项目初始化，主要包括相关配置，日志处理，以及定义相关接口或结构体。当前目录结构如下： 12345678910111213141516├─config│ config.go│├─interface│ └─tcp│ handler.go│├─lib│├─tcp│ echo.go│ server.go│ | go.mod| main.go| redis.conf 项目初始化配置文件解析在config/config.go文件中定义Redis相关服务端属性如下： 123456789101112131415161718package config// ServerProperties defines global config propertiestype ServerProperties struct &#123; Bind string `cfg:&quot;bind&quot;` Port int `cfg:&quot;port&quot;` AppendOnly bool `cfg:&quot;appendOnly&quot;` AppendFilename string `cfg:&quot;appendFilename&quot;` MaxClients int `cfg:&quot;maxclients&quot;` RequirePass string `cfg:&quot;requirepass&quot;` Databases int `cfg:&quot;databases&quot;` Peers []string `cfg:&quot;peers&quot;` Self string `cfg:&quot;self&quot;`&#125;// Properties holds global config propertiesvar Properties *ServerProperties 另外，还需要实现配置文件解析的相关方法： 1234567891011121314151617// SetupConfig read config file and store properties into Propertiesfunc SetupConfig(configFilename string) &#123; file, err := os.Open(configFilename) if err != nil &#123; panic(err) &#125; defer file.Close() Properties = parse(file)&#125;func parse(src io.Reader) *ServerProperties &#123; config := &amp;ServerProperties&#123;&#125; ... ... ... return config&#125; 为了防止没有配置文件的情况下也能正常初始化，可以添加如下代码： 12345678func init() &#123; // default config Properties = &amp;ServerProperties&#123; Bind: &quot;127.0.0.1&quot;, Port: 6379, AppendOnly: false, &#125;&#125; 接口定义在interface/tcp/handler.go中需要定义相关接口，以规范化处理tcp的连接： 12345// Handler represents application server over tcptype Handler interface &#123; Handle(ctx context.Context, conn net.Conn) Close() error&#125; TCP服务实现并发处理tcp连接在tcp/server.go中实现以下两个函数，用于处理tcp连接，此处主要依赖标准库net： 12345678910111213141516171819202122232425262728293031323334// Config stores tcp handler propertiestype Config struct &#123; Address string `yaml:&quot;address&quot;` MaxConnect uint32 `yaml:&quot;max-connect&quot;` Timeout time.Duration `yaml:&quot;timeout&quot;`&#125;// ListenAndServeWithSignal binds port and handle requests, blocking until receive stop signalfunc ListenAndServeWithSignal(cfg *Config, handler tcp.Handler) error &#123; closeChan := make(chan struct&#123;&#125;) ... listener, err := net.Listen(&quot;tcp&quot;, cfg.Address) ... ListenAndServe(listener, handler, closeChan) return nil&#125;// ListenAndServe binds port and handle requests, blocking until closefunc ListenAndServe(listener net.Listener, handler tcp.Handler, closeChan &lt;-chan struct&#123;&#125;) &#123; go func()&#123; &lt;-closeChan listener.Close() handler.Close() &#125; ... for &#123; conn, err := listener.Accept() ... go func() &#123; handler.Handle(ctx, conn) &#125;() &#125; ....&#125; main函数入口实现此时main.go中需要调用的函数已基本实现，后续修改只需传入对应的Handler即可： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package mainimport ( &quot;fmt&quot; &quot;go-redis/config&quot; &quot;go-redis/lib/logger&quot; &quot;go-redis/tcp&quot; EchoHandler &quot;go-redis/tcp&quot; &quot;os&quot;)const configFile string = &quot;redis.conf&quot;var defaultProperties = &amp;config.ServerProperties&#123; Bind: &quot;0.0.0.0&quot;, Port: 6379,&#125;func fileExists(filename string) bool &#123; info, err := os.Stat(filename) return err == nil &amp;&amp; !info.IsDir()&#125;func main() &#123; logger.Setup(&amp;logger.Settings&#123; Path: &quot;logs&quot;, Name: &quot;godis&quot;, Ext: &quot;log&quot;, TimeFormat: &quot;2006-01-02&quot;, &#125;) if fileExists(configFile) &#123; config.SetupConfig(configFile) &#125; else &#123; config.Properties = defaultProperties &#125; err := tcp.ListenAndServeWithSignal( &amp;tcp.Config&#123; Address: fmt.Sprintf(&quot;%s:%d&quot;, config.Properties.Bind, config.Properties.Port), &#125;, EchoHandler.MakeHandler()) if err != nil &#123; logger.Error(err) &#125;&#125; echoHandler示例新建文件tcp/echo.go，定义结构体EchoHandler与EchoClient： 1234567891011121314151617181920212223// EchoHandler echos received line to client, using for testtype EchoHandler struct &#123; activeConn sync.Map closing atomic.Boolean&#125;// MakeHandler creates EchoHandlerfunc MakeHandler() *EchoHandler &#123; return &amp;EchoHandler&#123;&#125;&#125;// EchoClient is client for EchoHandler, using for testtype EchoClient struct &#123; Conn net.Conn Waiting wait.Wait&#125;// Close close connectionfunc (c *EchoClient) Close() error &#123; c.Waiting.WaitWithTimeout(10 * time.Second) c.Conn.Close() return nil&#125; EchoHandler实现了接口Handler，主要是将接收到的数据原样返回，详情如下： 123456789101112131415161718192021222324// Handle echos received line to clientfunc (h *EchoHandler) Handle(ctx context.Context, conn net.Conn) &#123; ... reader := bufio.NewReader(conn) for &#123; // may occurs: client EOF, client timeout, server early close msg, err := reader.ReadString(&#x27;\\n&#x27;) .... b := []byte(msg) _, _ = conn.Write(b) .... &#125;&#125;// Close stops echo handlerfunc (h *EchoHandler) Close() error &#123; h.closing.Set(true) h.activeConn.Range(func(key interface&#123;&#125;, val interface&#123;&#125;) bool &#123; client := key.(*EchoClient) _ = client.Close() return true &#125;) return nil&#125; 实现Redis协议解析器本章节主要新增了redis相关命令的解析，具体执行，以及响应处理等，相关目录结构如下： 1234567891011121314151617181920212223242526272829303132333435363738394041├─config│ config.go│├─database│ echo_database.go│├─interface│ ├─database│ │ database.go│ ││ ├─resp│ │ conn.go│ │ reply.go│ ││ └─tcp│ handler.go│├─lib│├─resp│ ├─connection│ │ conn.go│ ││ ├─handler│ │ handler.go│ ││ ├─parser│ │ parser.go│ ││ └─reply│ consts.go│ errors.go│ reply.go│└─tcp│ echo.go│ server.go│ | go.mod| main.go| redis.conf redis网络协议认识 正常回复：以”+”开头，以”\\r\\n”结尾的字符串形式 错误回复：以”-“开头，以”\\r\\n”结尾的字符串形式 整数：以”:”开头，以”\\r\\n”结尾的字符串形式 多行字符串：以”$”开头，后面跟实际发送的字节数，以”\\r\\n”结尾 数组：以”*”开头，后面跟成员个数 接口定义及实现Connection在interface/resp/conn.go中定义连接，主要包含三个方法，写数据、获取当前所在数据库的索引，以及选择数据库： 123456// Connection represents a connection with redis clienttype Connection interface &#123; Write([]byte) error GetDBIndex() int // used for multi database SelectDB(int)&#125; 在resp/connection/conn.go中创建Connection结构体并实现Connection接口 1234567891011121314151617181920212223242526// Connection represents a connection with a redis-clitype Connection struct &#123; conn net.Conn waitingReply wait.Wait // waiting until reply finished mu sync.Mutex // lock while handler sending response selectedDB int // selected db&#125;func NewConn(conn net.Conn) *Connection &#123; return &amp;Connection&#123;conn: conn,&#125;&#125;// RemoteAddr returns the remote network addressfunc (c *Connection) RemoteAddr() net.Addr &#123;&#125;// Close disconnect with the clientfunc (c *Connection) Close() error &#123;&#125;// Write sends response to client over tcp connectionfunc (c *Connection) Write(b []byte) error &#123;&#125;// GetDBIndex returns selected dbfunc (c *Connection) GetDBIndex() int &#123;&#125;// SelectDB selects a databasefunc (c *Connection) SelectDB(dbNum int) &#123;&#125; Reply在interface/resp/reply.go中定义接口Reply，用于处理基于resp协议的响应，主要包含ToBytes方法： 12345678910// Reply is the interface of redis serialization protocol messagetype Reply interface &#123; ToBytes() []byte&#125;// ErrorReply is an error and redis.Replytype ErrorReply interface &#123; Error() string ToBytes() []byte&#125; 在resp/reply下创建以下三个文件，分别用于实现具体的相关处理： consts.go：定义一些固定不变的响应 reply.go：定义正常执行命令时的响应 errors.go：定义发生错误时的响应 consts.go中的文件内容如下，其中的结构体都需要实现Reply接口： 1234567891011121314// PongReply is +PONGtype PongReply struct&#123;&#125;// OkReply is +OKtype OkReply struct&#123;&#125;// NullBulkReply is empty stringtype NullBulkReply struct&#123;&#125;// EmptyMultiBulkReply is a empty listtype EmptyMultiBulkReply struct&#123;&#125;// NoReply respond nothing, for commands like subscribetype NoReply struct&#123;&#125; reply.go中的文件内容如下，其中的结构体都需要实现Reply接口： 123456789101112131415161718192021222324// BulkReply stores a binary-safe stringtype BulkReply struct &#123; Arg []byte&#125;// MultiBulkReply stores a list of stringtype MultiBulkReply struct &#123; Args [][]byte&#125;// StatusReply stores a simple status stringtype StatusReply struct &#123; Status string&#125;// IntReply stores an int64 numbertype IntReply struct &#123; Code int64&#125;// StandardErrReply represents handler errortype StandardErrReply struct &#123; Status string&#125; errors.go中的文件内容如下，其中的结构体都需要实现Reply接口： 123456789101112131415161718// UnknownErrReply represents UnknownErrtype UnknownErrReply struct&#123;&#125;// ArgNumErrReply represents wrong number of arguments for commandtype ArgNumErrReply struct &#123; Cmd string&#125;// SyntaxErrReply represents meeting unexpected argumentstype SyntaxErrReply struct&#123;&#125;// WrongTypeErrReply represents operation against a key holding the wrong kind of valuetype WrongTypeErrReply struct&#123;&#125;// ProtocolErrReply represents meeting unexpected byte during parse requeststype ProtocolErrReply struct &#123; Msg string&#125; Database在interface/database/database.go定义接口Database，规范不同的数据库实现： 123456// Database is the interface for redis style storage enginetype Database interface &#123; Exec(client resp.Connection, args [][]byte) resp.Reply AfterClientClose(c resp.Connection) Close()&#125; 命令解析实现在文件resp/parser/parser.go实现下面的功能： 响应流式处理 Payload：包含正常响应或错误 readState：解析器状态 ParseStream：返回数据类型为Payload的channel 123456789101112131415161718192021222324// Payload stores redis.Reply or errortype Payload struct &#123; Data resp.Reply Err error&#125;type readState struct &#123; readingMultiLine bool expectedArgsCount int msgType byte args [][]byte bulkLen int64&#125;func (s *readState) finished() bool &#123; return s.expectedArgsCount &gt; 0 &amp;&amp; len(s.args) == s.expectedArgsCount&#125;// ParseStream reads data from io.Reader and send payloads through channelfunc ParseStream(reader io.Reader) &lt;-chan *Payload &#123; ch := make(chan *Payload) go parse0(reader, ch) return ch&#125; 命令读取及具体解析 readLine：精确读取一行数据 parseMultiBulkHeader：处理多行数据(“*”号开始)，改变解析器状态 parseBulkHeader：处理单个数据(“$”号开始)，改变解析器状态 parseSingleLineReply：处理客户端发送+ok -err :5的情况 1234567func readLine(bufReader *bufio.Reader, state *readState) ([]byte, bool, error) &#123;&#125;func parseMultiBulkHeader(msg []byte, state *readState) error &#123;&#125;func parseBulkHeader(msg []byte, state *readState) error &#123;&#125;func parseSingleLineReply(msg []byte) (resp.Reply, error) &#123;&#125; 解析实现 readBody：去除其他字符，解析命令内容 parse0：根据读取到的数据调用不同的解析方法，并将结果返回Payload的channel 1234// read the non-first lines of multi bulk reply or bulk replyfunc readBody(msg []byte, state *readState) error &#123;&#125;func parse0(reader io.Reader, ch chan&lt;- *Payload) &#123;&#125; 实现RespHandler在TCP层面处理用户发过来的数据，并调用resp协议解析器进行解析，然后根据对应的db去实际执行相关的命令，主要在Handle方法中实现。 1234567891011121314151617181920212223// RespHandler implements tcp.Handler and serves as a redis handlertype RespHandler struct &#123; activeConn sync.Map // *client -&gt; placeholder db databaseface.Database closing atomic.Boolean // refusing new client and new request&#125;// MakeHandler creates a RespHandler instancefunc MakeHandler() *RespHandler &#123; var db databaseface.Database db = database.NewEchoDatabase() return &amp;RespHandler&#123; db: db, &#125;&#125;func (h *RespHandler) closeClient(client *connection.Connection) &#123;&#125;// Handle receives and executes redis commandsfunc (h *RespHandler) Handle(ctx context.Context, conn net.Conn) &#123;&#125;// Close stops handlerfunc (h *RespHandler) Close() error &#123;&#125; EchoDatabase示例在database/echo_database.go中简单实现一个数据库，其实现了Database接口。这里只是方便做简单测试，下一篇文章将记录如何实现redis的内存数据库： 123456789101112131415161718type EchoDatabase struct &#123;&#125;func NewEchoDatabase() *EchoDatabase &#123; return &amp;EchoDatabase&#123;&#125;&#125;func (e EchoDatabase) Exec(client resp.Connection, args [][]byte) resp.Reply &#123; return reply.MakeMultiBulkReply(args)&#125;func (e EchoDatabase) AfterClientClose(c resp.Connection) &#123; logger.Info(&quot;EchoDatabase AfterClientClose&quot;)&#125;func (e EchoDatabase) Close() &#123; logger.Info(&quot;EchoDatabase Close&quot;)&#125;","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"},{"name":"项目实战","slug":"go/项目实战","permalink":"https://cezz.github.io/categories/go/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"}],"tags":[]},{"title":"go语言实现大根堆、小根堆及堆排序","slug":"go/go实现大根堆、小根堆及堆排序","date":"2022-03-18T13:07:38.000Z","updated":"2022-06-28T16:24:38.505Z","comments":true,"path":"2022/03/18/go/go实现大根堆、小根堆及堆排序/","link":"","permalink":"https://cezz.github.io/2022/03/18/go/go%E5%AE%9E%E7%8E%B0%E5%A4%A7%E6%A0%B9%E5%A0%86%E3%80%81%E5%B0%8F%E6%A0%B9%E5%A0%86%E5%8F%8A%E5%A0%86%E6%8E%92%E5%BA%8F/","excerpt":"","text":"二叉堆是一种特殊的堆，它满足两个性质：结构性和堆序性 结构性：二叉堆是一棵完全二叉树，完全二叉树可以用一个数组表示，不需要指针，所以效率更高。当用数组表示时，数组中任一位置i上的元素，其左子树在位置2i上，右子树在位置2i+1上，其父节点在位置i&#x2F;2上。 堆序性质：堆的最小值或最大值在根节点上，所以可以快速找到最大值或最小值。 最大堆和最小堆是二叉堆的两种形式： 最大堆：根节点的键值是所有堆节点键值中最大者的堆。 最小堆：根节点的键值是所有堆节点键值中最小者的堆。 最小堆实现插入和删除当向最小堆插入元素时： 将元素插入末尾 判断该元素是否需要上移(与父节点比较，如果比父节点小则上移) 重复上述步骤，直到满足最小堆特性 当向最小堆删除元素时： 删除堆顶元素 判断目前的堆顶元素是否需要下调(与子节点比较，和其中较小的节点交换位置) 重复上述步骤，直到满足最小堆特性 具体实现下面以求数据流中第k大的元素为问题实现一个最小堆，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253type minHeap struct &#123; k int // 容量 heap []int // heap数组&#125;func createMinHeap(k int, nums []int) *minHeap &#123; heap := &amp;minHeap&#123;k: k, heap: []int&#123;&#125;&#125; for _, n := range nums &#123; heap.add(n) &#125; return heap&#125;func (m *minHeap) add(num int) &#123; if len(m.heap) &lt; m.k &#123; m.heap = append(m.heap, num) m.up(len(m.heap) - 1) &#125; else if num &gt; m.heap[0] &#123; m.heap[0] = num m.down(0) &#125;&#125;// 元素上浮func (m *minHeap) up(i int) &#123; for i &gt; 0 &#123; parent := (i - 1) &gt;&gt; 1 // 找到父节点在heap数组中的位置 // 如果比父节点元素小，则交换位置并更新索引 if m.heap[parent] &gt; m.heap[i] &#123; m.heap[parent], m.heap[i] = m.heap[i], m.heap[parent] i = parent &#125; else &#123; break // 当前节点比父节点小，满足最小堆性质，退出 &#125; &#125;&#125;// 元素下沉(包括切片中第一个元素，索引为0)func (m *minHeap) down(i int) &#123; for 2*i+1 &lt; len(m.heap) &#123; // 左子节点越界，则退出循环 child := 2*i + 1 // 左子节点在heap切片中的位置 if child+1 &lt; len(m.heap) &amp;&amp; m.heap[child+1] &lt; m.heap[child] &#123; child++ // 如果右子节点没有越界，且值比左子节点更小，则选择下沉右子节点 &#125; // 将当前元素与子节点最大元素对比，然后交换并更新索引 if m.heap[i] &gt; m.heap[child] &#123; m.heap[child], m.heap[i] = m.heap[i], m.heap[child] i = child &#125; else &#123; break // 子节点都比自己大，满足最小堆属性，退出 &#125; &#125;&#125; 应用如果要求输出数据流中的第k大元素，正好可以使用最小堆实现： 123456789101112type KthLargest struct &#123; heap *minHeap&#125;func Constructor(k int, nums []int) KthLargest &#123; return KthLargest&#123;heap: createMinHeap(k, nums)&#125;&#125;func (k *KthLargest) Add(val int) int &#123; k.heap.add(val) return k.heap.heap[0]&#125; 使用heap包实现heap源码中定义了一个Interface接口，该接口一共包含5个方法，定义一个实现了该接口的结构体就实现了一个二叉堆。container/heap/heap.go 12345678// Note that Push and Pop in this interface are for package heap&#x27;s// implementation to call. To add and remove things from the heap,// use heap.Push and heap.Pop.type Interface interface &#123; sort.Interface Push(x interface&#123;&#125;) // add x as element Len() Pop() interface&#123;&#125; // remove and return element Len() - 1.&#125; sort/sort.go 1234567891011121314151617181920212223242526// An implementation of Interface can be sorted by the routines in this package.// The methods refer to elements of the underlying collection by integer index.type Interface interface &#123; // Len is the number of elements in the collection. Len() int // Less reports whether the element with index i // must sort before the element with index j. // // If both Less(i, j) and Less(j, i) are false, // then the elements at index i and j are considered equal. // Sort may place equal elements in any order in the final result, // while Stable preserves the original input order of equal elements. // // Less must describe a transitive ordering: // - if both Less(i, j) and Less(j, k) are true, then Less(i, k) must be true as well. // - if both Less(i, j) and Less(j, k) are false, then Less(i, k) must be false as well. // // Note that floating-point comparison (the &lt; operator on float32 or float64 values) // is not a transitive ordering when not-a-number (NaN) values are involved. // See Float64Slice.Less for a correct implementation for floating-point values. Less(i, j int) bool // Swap swaps the elements with indexes i and j. Swap(i, j int)&#125; 定义一个最大堆，实现上述接口如下： 12345678910111213141516171819202122232425262728293031323334type MaxHeap []intfunc (h MaxHeap) Len() int &#123; return len(h)&#125;func (h MaxHeap) Less(i, j int) bool &#123; return h[i] &gt; h[j] // 因为实现最大堆，所以使用大于号&#125;func (h *MaxHeap) Swap(i, j int) &#123; (*h)[i], (*h)[j] = (*h)[j], (*h)[i]&#125;func (h *MaxHeap) Push(x interface&#123;&#125;) &#123; *h = append(*h, x.(int))&#125;// Pop 弹出堆顶元素func (h *MaxHeap) Pop() interface&#123;&#125; &#123; res := (*h)[len(*h)-1] *h = (*h)[:len(*h)-1] return res&#125;func main() &#123; h := &amp;MaxHeap&#123;3, 1, 2, 5&#125; heap.Init(h) heap.Push(h, 8) for h.Len() &gt; 0 &#123; fmt.Printf(&quot;%d &quot;, heap.Pop(h)) &#125;&#125; 堆排序堆排序是一种选择排序，它的最坏、最好、平均时间复杂度均为O(nlogn)，它也是不稳定排序。 排序的过程主要由构建初始堆，交换堆顶元素和末尾元素并重建堆两部分组成 升序使用最大堆，每次和末尾元素交换，然后重新构建最大堆，整体数组减一；反之降序使用最小堆 堆构建从第一个非叶子节点开始，也就是len/2 - 1所在位置的元素 12345678910111213141516171819202122232425262728293031323334353637func maxHeap(nums []int, length int) []int &#123; if length &lt;= 1 &#123; return nums &#125; parent := length/2 + 1 // 第一个非叶子节点 for i := parent; i &gt;= 0; i-- &#123; // 比较三个节点的大小并将较大的节点上浮 max := i leftChild := 2*i + 1 rightChild := 2*i + 2 if leftChild &lt;= length-1 &amp;&amp; nums[leftChild] &gt; nums[max] &#123; max = leftChild &#125; if rightChild &lt;= length-1 &amp;&amp; nums[rightChild] &gt; nums[max] &#123; max = rightChild &#125; if max != i &#123; nums[i], nums[max] = nums[max], nums[i] &#125; &#125; return nums&#125;func sortHeap(nums []int) []int &#123; length := len(nums) for i := 0; i &lt; length; i++ &#123; lastLength := length - i // 剔除已经排完序的元素 nums = maxHeap(nums, lastLength) // 重新构建最大堆 nums[0], nums[lastLength-1] = nums[lastLength-1], nums[0] &#125; return nums&#125;func main() &#123; nums := []int&#123;8, 5, 11, 2, 7, 9&#125; fmt.Println(sortHeap(nums))&#125;","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"}],"tags":[]},{"title":"channel的底层实现","slug":"go/channel的底层实现","date":"2022-03-05T11:43:21.000Z","updated":"2022-05-23T09:46:25.833Z","comments":true,"path":"2022/03/05/go/channel的底层实现/","link":"","permalink":"https://cezz.github.io/2022/03/05/go/channel%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"本文基于go版本1.16 数据结构其底层数据结构为runtime包下的一个hchan的结构体，如下： 12345678910111213141516171819202122232425type hchan struct &#123; qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G&#x27;s status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex&#125;type waitq struct &#123; first *sudog last *sudog&#125; buf指向底层循环数组，只有缓冲型的channel才有 sendx, recvx均指向底层循环数组，表示当前可以发送和接收的元素位置索引值（相对于底层数组） sendq, recvq分别表示向channel读取或发送数据而阻塞的goroutine队列 waitq是sudog的一个双向链表（sudog实际上是对goroutine的封装） lock用来保证每个读channel或写channel的操作都是原子的 创建使用make能创建一个能收能发的channel： 12345// 无缓冲通道ch1 := make(chan int)// 有缓冲通道ch2 := make(chan int, 10) 通过汇编分析（go complie），找到最终创建chan的函数是位于runtime&#x2F;chan.go下的函数makechan： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455const ( maxAlign = 8 hchanSize = unsafe.Sizeof(hchan&#123;&#125;) + uintptr(-int(unsafe.Sizeof(hchan&#123;&#125;))&amp;(maxAlign-1)) debugChan = false)func makechan(t *chantype, size int) *hchan &#123; elem := t.elem // compiler checks this but be safe. if elem.size &gt;= 1&lt;&lt;16 &#123; throw(&quot;makechan: invalid channel element type&quot;) &#125; if hchanSize%maxAlign != 0 || elem.align &gt; maxAlign &#123; throw(&quot;makechan: bad alignment&quot;) &#125; mem, overflow := math.MulUintptr(elem.size, uintptr(size)) if overflow || mem &gt; maxAlloc-hchanSize || size &lt; 0 &#123; panic(plainError(&quot;makechan: size out of range&quot;)) &#125; // Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers. // buf points into the same allocation, elemtype is persistent. // SudoG&#x27;s are referenced from their owning thread so they can&#x27;t be collected. // TODO(dvyukov,rlh): Rethink when collector can move allocated objects. var c *hchan switch &#123; case mem == 0: // Queue or element size is zero. c = (*hchan)(mallocgc(hchanSize, nil, true)) // Race detector uses this location for synchronization. c.buf = c.raceaddr() case elem.ptrdata == 0: // Elements do not contain pointers. // Allocate hchan and buf in one call. c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: // Elements contain pointers. c = new(hchan) c.buf = mallocgc(mem, elem, true) &#125; c.elemsize = uint16(elem.size) c.elemtype = elem c.dataqsiz = uint(size) lockInit(&amp;c.lock, lockRankHchan) if debugChan &#123; print(&quot;makechan: chan=&quot;, c, &quot;; elemsize=&quot;, elem.size, &quot;; dataqsiz=&quot;, size, &quot;\\n&quot;) &#125; return c&#125; 发送123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool &#123; if c == nil &#123; // 当channel是nil if !block &#123; return false // 非阻塞直接返回false，表示发送失败 &#125; gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) // 挂起当前goroutine throw(&quot;unreachable&quot;) &#125; if debugChan &#123; print(&quot;chansend: chan=&quot;, c, &quot;\\n&quot;) &#125; if raceenabled &#123; racereadpc(c.raceaddr(), callerpc, funcPC(chansend)) &#125; // Fast path: check for failed non-blocking operation without acquiring the lock. // // After observing that the channel is not closed, we observe that the channel is // not ready for sending. Each of these observations is a single word-sized read // (first c.closed and second full()). // Because a closed channel cannot transition from &#x27;ready for sending&#x27; to // &#x27;not ready for sending&#x27;, even if the channel is closed between the two observations, // they imply a moment between the two when the channel was both not yet closed // and not ready for sending. We behave as if we observed the channel at that moment, // and report that the send cannot proceed. // // It is okay if the reads are reordered here: if we observe that the channel is not // ready for sending and then observe that it is not closed, that implies that the // channel wasn&#x27;t closed during the first observation. However, nothing here // guarantees forward progress. We rely on the side effects of lock release in // chanrecv() and closechan() to update this thread&#x27;s view of c.closed and full(). // 快速检测非阻塞且channel未关闭情况下的失败场景（详情看下述full函数）： // 1. 对于无缓冲channel，接收队列里没有goroutine则发送失败(非阻塞) // 2. 对于有缓冲channel，循环数组中已装满元素则发送失败(非阻塞) if !block &amp;&amp; c.closed == 0 &amp;&amp; full(c) &#123; return false &#125; var t0 int64 if blockprofilerate &gt; 0 &#123; t0 = cputicks() &#125; lock(&amp;c.lock) // 锁住channel，并发安全 if c.closed != 0 &#123; // 如果channel关闭了，则解锁并抛出异常 unlock(&amp;c.lock) panic(plainError(&quot;send on closed channel&quot;)) &#125; // 如果接收队列里有goroutine，则直接将要发送的数据拷贝到接收goroutine if sg := c.recvq.dequeue(); sg != nil &#123; // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). send(c, sg, ep, func() &#123; unlock(&amp;c.lock) &#125;, 3) return true &#125; // 对于有缓冲的channel，如果还有缓冲空间 if c.qcount &lt; c.dataqsiz &#123; // Space is available in the channel buffer. Enqueue the element to send. qp := chanbuf(c, c.sendx) // qp指向buf的sendx位置 if raceenabled &#123; racenotify(c, c.sendx, nil) &#125; typedmemmove(c.elemtype, qp, ep) // 将数据从ep处拷贝到qp c.sendx++ // 发送游标值加一 if c.sendx == c.dataqsiz &#123; // 如果发送游标值等于容量值，游标值归0 c.sendx = 0 &#125; c.qcount++ // 缓冲区的元素数量加一 unlock(&amp;c.lock) // 解锁 return true &#125; if !block &#123; // 如果是非阻塞的，直接返回错误 unlock(&amp;c.lock) return false &#125; // channel满了，发送方会被阻塞。接下来会构造一个sudog // Block on the channel. Some receiver will complete our operation for us. gp := getg() // 获取当前goroutine的指针 mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 &#123; mysg.releasetime = -1 &#125; // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil mysg.g = gp mysg.isSelect = false mysg.c = c gp.waiting = mysg gp.param = nil c.sendq.enqueue(mysg) // 当前goroutine进入发送等待队列 // Signal to anyone trying to shrink our stack that we&#x27;re about // to park on a channel. The window between when this G&#x27;s status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. atomic.Store8(&amp;gp.parkingOnChan, 1) // 挂起当前goroutine gopark(chanparkcommit, unsafe.Pointer(&amp;c.lock), waitReasonChanSend, traceEvGoBlockSend, 2) // Ensure the value being sent is kept alive until the // receiver copies it out. The sudog has a pointer to the // stack object, but sudogs aren&#x27;t considered as roots of the // stack tracer. KeepAlive(ep) // someone woke us up. if mysg != gp.waiting &#123; throw(&quot;G waiting list is corrupted&quot;) &#125; gp.waiting = nil gp.activeStackChans = false closed := !mysg.success gp.param = nil if mysg.releasetime &gt; 0 &#123; blockevent(mysg.releasetime-t0, 2) &#125; mysg.c = nil releaseSudog(mysg) if closed &#123; if c.closed == 0 &#123; throw(&quot;chansend: spurious wakeup&quot;) &#125; panic(plainError(&quot;send on closed channel&quot;)) &#125; return true&#125; 1234567891011121314func full(c *hchan) bool &#123; // c.dataqsiz is immutable (never written after the channel is created) // so it is safe to read at any time during channel operation. if c.dataqsiz == 0 &#123; // Assumes that a pointer read is relaxed-atomic. return c.recvq.first == nil &#125; // Assumes that a uint read is relaxed-atomic. return c.qcount == c.dataqsiz&#125;// if !block &amp;&amp; c.closed == 0 &amp;&amp; full(c) &#123;// return false// &#125; 这里有一个点需要注意，结合在chansend中调用full的地方上的英文注释进行分析，在得知channel未被关闭的情况下(c.closed==0)，去获取c.recvq.first和c.qcount的值时为什么不需要加锁(假设这个期间channe被关闭，则前后条件实际上是不一致的)？ 因为一个已经关闭的channel不能将channel状态从ready for sending变成not ready for sending，意味着在两个观测之间有一个时刻，通道既没有被关闭，也没有准备好发送，此时直接返回false也是没有问题的 然后其会依赖chanrecv()和closechan()中锁释放的副作用来更新这个线程的c.closed和full 如果从等待接收队列recvq里出队一个sudog(代表一个goroutine)，说明此时channel是空的，没有元素，所以才会有等待接收者。这时会调用send函数将元素直接从发送者的栈拷贝到接收者的栈，关键操作由sendDirect函数完成。 12345678910111213141516171819202122232425262728293031323334353637// send processes a send operation on an empty channel c.// The value ep sent by the sender is copied to the receiver sg.// The receiver is then woken up to go on its merry way.// Channel c must be empty and locked. send unlocks c with unlockf.// sg must already be dequeued from c.// ep must be non-nil and point to the heap or the caller&#x27;s stack.func send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) &#123; if raceenabled &#123; if c.dataqsiz == 0 &#123; racesync(c, sg) &#125; else &#123; // Pretend we go through the buffer, even though // we copy directly. Note that we need to increment // the head/tail locations only when raceenabled. racenotify(c, c.recvx, nil) racenotify(c, c.recvx, sg) c.recvx++ if c.recvx == c.dataqsiz &#123; c.recvx = 0 &#125; c.sendx = c.recvx // c.sendx = (c.sendx+1) % c.dataqsiz &#125; &#125; // sg.elem指向接收到的值存放的位置，如val &lt;-ch，指的就是&amp;val if sg.elem != nil &#123; sendDirect(c.elemtype, sg, ep) // 直接拷贝内存（从发送者到接收者） sg.elem = nil &#125; gp := sg.g // sudo上绑定的goroutine unlockf() gp.param = unsafe.Pointer(sg) sg.success = true if sg.releasetime != 0 &#123; sg.releasetime = cputicks() &#125; goready(gp, skip+1) // 唤醒接收的goroutine&#125; 继续看sendDirect函数： 12345678910111213141516171819202122// Sends and receives on unbuffered or empty-buffered channels are the// only operations where one running goroutine writes to the stack of// another running goroutine. The GC assumes that stack writes only// happen when the goroutine is running and are only done by that// goroutine. Using a write barrier is sufficient to make up for// violating that assumption, but the write barrier has to work.// typedmemmove will call bulkBarrierPreWrite, but the target bytes// are not in the heap, so that will not help. We arrange to call// memmove and typeBitsBulkBarrier instead.func sendDirect(t *_type, sg *sudog, src unsafe.Pointer) &#123; // src is on our stack, dst is a slot on another stack. // Once we read sg.elem out of sg, it will no longer // be updated if the destination&#x27;s stack gets copied (shrunk). // So make sure that no preemption points can happen between read &amp; use. dst := sg.elem typeBitsBulkBarrier(t, uintptr(dst), uintptr(src), t.size) // No need for cgo write barrier checks because dst is always // Go memory. memmove(dst, src, t.size)&#125; 这里涉及到一个goroutine直接写另一个goroutine栈的操作，一般而言，不同goroutine的栈是各自独有的。而这也违反了GC的一些假设。为了不出问题，写的过程中增加了写屏障，保证正确的完成写操作。这样做的好处是减少了一次内存拷贝，不用先拷贝到channel的buf，直接由发送者到接收者，减少了中间一层，效率得以提高。然后解锁，唤醒接收者，等待调度器的光临，接收者得以重见天日，可以继续执行接收操作后续代码了。 接收接收操作有两种写法，一种带”ok”，表示channel是否被关闭；一种不带”ok”，这种写法当接收到相应类型的零值时无法知道是真实的发送者发送者发送过来的值，还是channel被关闭后，返回给接收者默认类型的零值。经过编译器的处理后，这两种写法对应源码以下的两个函数： 1234567891011// entry points for &lt;- c from compiled code//go:nosplitfunc chanrecv1(c *hchan, elem unsafe.Pointer) &#123; chanrecv(c, elem, true)&#125;//go:nosplitfunc chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) &#123; _, received = chanrecv(c, elem, true) return&#125; 有上述源码可见，最终都会调用chanrecv这个函数： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146// chanrecv receives on channel c and writes the received data to ep.// ep may be nil, in which case received data is ignored.// If block == false and no elements are available, returns (false, false).// Otherwise, if c is closed, zeros *ep and returns (true, false).// Otherwise, fills in *ep with an element and returns (true, true).// A non-nil ep must point to the heap or the caller&#x27;s stack.func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) &#123; // raceenabled: don&#x27;t need to check ep, as it is always on the stack // or is new memory allocated by reflect. if debugChan &#123; print(&quot;chanrecv: chan=&quot;, c, &quot;\\n&quot;) &#125; if c == nil &#123; // 如果是nil的channel if !block &#123; return &#125; gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(&quot;unreachable&quot;) &#125; // Fast path: check for failed non-blocking operation without acquiring the lock. if !block &amp;&amp; empty(c) &#123; // After observing that the channel is not ready for receiving, we observe whether the // channel is closed. // // Reordering of these checks could lead to incorrect behavior when racing with a close. // For example, if the channel was open and not empty, was closed, and then drained, // reordered reads could incorrectly indicate &quot;open and empty&quot;. To prevent reordering, // we use atomic loads for both checks, and rely on emptying and closing to happen in // separate critical sections under the same lock. This assumption fails when closing // an unbuffered channel with a blocked send, but that is an error condition anyway. if atomic.Load(&amp;c.closed) == 0 &#123; // Because a channel cannot be reopened, the later observation of the channel // being not closed implies that it was also not closed at the moment of the // first observation. We behave as if we observed the channel at that moment // and report that the receive cannot proceed. return &#125; // The channel is irreversibly closed. Re-check whether the channel has any pending data // to receive, which could have arrived between the empty and closed checks above. // Sequential consistency is also required here, when racing with such a send. if empty(c) &#123; // The channel is irreversibly closed and empty. if raceenabled &#123; raceacquire(c.raceaddr()) &#125; if ep != nil &#123; typedmemclr(c.elemtype, ep) &#125; return true, false &#125; &#125; var t0 int64 if blockprofilerate &gt; 0 &#123; t0 = cputicks() &#125; lock(&amp;c.lock) if c.closed != 0 &amp;&amp; c.qcount == 0 &#123; if raceenabled &#123; raceacquire(c.raceaddr()) &#125; unlock(&amp;c.lock) if ep != nil &#123; typedmemclr(c.elemtype, ep) &#125; return true, false &#125; if sg := c.sendq.dequeue(); sg != nil &#123; // Found a waiting sender. If buffer is size 0, receive value // directly from sender. Otherwise, receive from head of queue // and add sender&#x27;s value to the tail of the queue (both map to // the same buffer slot because the queue is full). recv(c, sg, ep, func() &#123; unlock(&amp;c.lock) &#125;, 3) return true, true &#125; // 有缓冲channel，buf里面有元素，可以正常接收 if c.qcount &gt; 0 &#123; // Receive directly from queue qp := chanbuf(c, c.recvx) if raceenabled &#123; racenotify(c, c.recvx, nil) &#125; if ep != nil &#123; // 不忽略要接收的值，不是&quot;&lt;-ch&quot;，而是&quot;val &lt;-ch&quot;，ep指向val typedmemmove(c.elemtype, ep, qp) &#125; typedmemclr(c.elemtype, qp) // 清理掉循环数组里相应位置的值 c.recvx++ // 接收游标向前移动 if c.recvx == c.dataqsiz &#123; c.recvx = 0 // 接收游标归零 &#125; c.qcount-- unlock(&amp;c.lock) return true, true &#125; if !block &#123; unlock(&amp;c.lock) return false, false &#125; // no sender available: block on this channel. gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 &#123; mysg.releasetime = -1 &#125; // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil c.recvq.enqueue(mysg) // Signal to anyone trying to shrink our stack that we&#x27;re about // to park on a channel. The window between when this G&#x27;s status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. atomic.Store8(&amp;gp.parkingOnChan, 1) gopark(chanparkcommit, unsafe.Pointer(&amp;c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2) // someone woke us up if mysg != gp.waiting &#123; throw(&quot;G waiting list is corrupted&quot;) &#125; gp.waiting = nil gp.activeStackChans = false if mysg.releasetime &gt; 0 &#123; blockevent(mysg.releasetime-t0, 2) &#125; success := mysg.success gp.param = nil mysg.c = nil releaseSudog(mysg) return true, success&#125; 关闭1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071func closechan(c *hchan) &#123; if c == nil &#123; panic(plainError(&quot;close of nil channel&quot;)) // 关闭一个nil的channel直接panic &#125; lock(&amp;c.lock) if c.closed != 0 &#123; unlock(&amp;c.lock) panic(plainError(&quot;close of closed channel&quot;)) // 关闭一个已经关闭的channel，panic &#125; if raceenabled &#123; callerpc := getcallerpc() racewritepc(c.raceaddr(), callerpc, funcPC(closechan)) racerelease(c.raceaddr()) &#125; c.closed = 1 var glist gList // release all readers for &#123; sg := c.recvq.dequeue() if sg == nil &#123; break &#125; if sg.elem != nil &#123; typedmemclr(c.elemtype, sg.elem) sg.elem = nil &#125; if sg.releasetime != 0 &#123; sg.releasetime = cputicks() &#125; gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled &#123; raceacquireg(gp, c.raceaddr()) &#125; glist.push(gp) &#125; // release all writers (they will panic) for &#123; sg := c.sendq.dequeue() if sg == nil &#123; break &#125; sg.elem = nil if sg.releasetime != 0 &#123; sg.releasetime = cputicks() &#125; gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled &#123; raceacquireg(gp, c.raceaddr()) &#125; glist.push(gp) &#125; unlock(&amp;c.lock) // Ready all Gs now that we&#x27;ve dropped the channel lock. for !glist.empty() &#123; gp := glist.pop() gp.schedlink = 0 goready(gp, 3) &#125;&#125; close逻辑比较简单，对于一个channel，recvq和sendq中分别保存了阻塞的发送者和接收者。关闭channel后，对于等待接收者而言，会收到一个相应类型的零值。对于等待发送者，会直接panic。所以，在不了解channel还有没有接收者的情况下，不能贸然关闭channel。 close函数先上一把大锁，接着把所有挂在这个channel上的sender和receiver全都连成一个sudog链表，再解锁。最后再将所有的sudog全都唤醒。 唤醒之后，该干什么干什么。sender会继续执行chansend函数里goparkunlock函数之后的代码，当检测到channel已经关闭了则会panic。receiver则会进行后续的扫尾工作，然后返回，这里selected会返回true，received会根据channel是否关闭返回不同的值。","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"}],"tags":[]},{"title":"go语言变量逃逸分析","slug":"go/go语言变量逃逸分析","date":"2022-02-12T07:16:09.000Z","updated":"2022-06-28T16:22:59.830Z","comments":true,"path":"2022/02/12/go/go语言变量逃逸分析/","link":"","permalink":"https://cezz.github.io/2022/02/12/go/go%E8%AF%AD%E8%A8%80%E5%8F%98%E9%87%8F%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/","excerpt":"","text":"go实现了内存的自动管理，其主要包括两个动作：分配与释放。为了更好的理解逃逸分析，需要对堆和栈有一定的了解。 堆和栈应用程序的内存载体，可以简单分为堆和栈。 在go中，栈的内存是由编译器进行分配和释放，栈区往往存储着函数参数、局部变量和调用函数帧，它们随着函数的创建而分配，函数的退出而销毁。一个goroutine对应一个栈，栈是调用栈的简称。一个栈通常又包含了许多栈帧，它描述的函数之间的调用关系，每一帧对应一次尚未返回的函数调用，它本身也是以栈形式存放数据。 与栈不同的是，应用程序在运行时只会存在一个堆。狭隘的说，内存管理只是针对堆内存而言的。程序在运行期间可以主动从堆上申请内存，这些内存通过go的内存分配器分配，并由垃圾回收器回收。 另外，对于堆内存的回收，还需要通过标记清除阶段，如三色标记法。但是对于栈上的内存而言，其分配和释放非常廉价。简单的说，它只需要两个cpu指令，一个是分配入栈，一个是栈内释放，而这只需要借助栈相关的寄存器即可完成。 逃逸分析对于一个对象是被分配在堆上还是栈上，官网上也有这样的回答： 如果可以，go编译器会尽可能将变量分配到栈上。但是，当编译器无法证明函数返回后，该变量没有被引用，那么编译器就必须在堆上分配该变量，以此避免悬挂指针。另外如果局部变量非常大，也会将其分配在堆上。 而go编译器则是通过逃逸分析去选择堆或者是栈，逃逸分析的基本思想如下：检查变量的生命周期是否是完全可知的，如果通过检查，则可以在栈上分配。否则，就是逃逸，必须在堆上进行分配。 可以通过命令go build -gcflags &quot;-m -l&quot;来查看逃逸分析结果： -m：打印逃逸分析信息 -l：禁止内联优化 常见的逃逸情况如下所示： 情况一：变量类型不确定12345678910func main() &#123; a := 666 fmt.Println(a)&#125;// 输出如下// $ go build -gcflags &quot;-m -l&quot; main.go// # command-line-arguments// ./main.go:7:13: ... argument does not escape// ./main.go:7:13: a escapes to heap 变量a发生了逃逸是因为其被传入了fmt.Println中，这个方法参数自己发生了逃逸。 func Println(a ...interface&#123;&#125;) (n int, err error) 因为fmt.Println函数参数为interface类型，编译期无法确定参数的具体类型，故分配在堆上 情况二：暴露给外部指针123456789101112func foo() *int &#123; a := 666 return &amp;a&#125;func main() &#123; _ = foo()&#125;// # command-line-arguments// .\\main.go:4:2: moved to heap: a 变量存在外部引用则必定分配到堆上。 情况三：变量所占内存较大1234567891011121314func foo() &#123; s := make([]int, 10000, 10000) for i := 0; i &lt; len(s); i++ &#123; s[i] = i &#125;&#125;func main() &#123; foo()&#125;// # command-line-arguments// .\\main.go:4:11: make([]int, 10000, 10000) escapes to heap 这里需要注意，在go中执行用户代码的goroutine是一种用户态线程，其调用栈内存被称为用户栈，它其实也是从堆区分配的，但是我们仍然可以将其看作和系统栈一样的内存空间，它的分配和释放都是通过编译器完成的。与其对应的是系统栈，它的分配和释放是操作系统完成的。在GMP模型中，一个M对应一个系统栈(也称为M的g0栈)，M上的多个goroutine会共享该系统栈。 不同架构的系统栈最大限制不同，以x86_64为例，其系统栈最大为8mb 我们常说的goroutine初始大小为2kb，说的是用户栈，可在runtime/stack.go中找到 在go中大对象的范围为大于32kb，即上述代码中的n达到8192，就会逃逸 情况四：变量大小不确定123456789101112131415func foo() &#123; n := 1 s := make([]int, n) for i := 0; i &lt; len(s); i++ &#123; s[i] = i &#125;&#125;func main() &#123; foo()&#125;// # command-line-arguments// .\\main.go:5:11: make([]int, n) escapes to heap 这次，在make方法中，没有直接指定大小，而是填入了变量n，这时go逃逸分析也会将其分配到堆区去。可见，为了保证内存的绝对安全，go的编译器可能会将一些变量不合时宜地分配到堆上，但是因为这些对象最终也会被垃圾收集器处理，所以也能接受。 小结 发生逃逸的情况还有很多，理解其思想才是最为重要的。 理解逃逸分析可以帮助我们写出更好的程序，知道变量分配在堆栈上的差别，则尽可能写出分配在栈上的代码，堆上的变量变少了，可以减轻内存分配的开销，减小gc的压力，提高程序的运行速度。 你会发现有些go上线项目，它们在函数传参的时候，并没有传递结构体指针，而是直接传递的结构体。这个做法，虽然它需要值拷贝，但是这是在栈上完成的操作，开销远比变量逃逸后动态的在堆上分配内存少的多。当然这个做法不是绝对的，如果结构体较大，传递指针将更加合适。 从gc的角度来看，指针传递是个双刃剑，需要谨慎使用，否则线上调优解决gc延时会让人崩溃。","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"}],"tags":[]},{"title":"channel到底需不需要手动关闭","slug":"go/channel到底需不需要手动关闭？","date":"2021-12-25T16:31:29.000Z","updated":"2022-07-10T23:15:17.239Z","comments":true,"path":"2021/12/26/go/channel到底需不需要手动关闭？/","link":"","permalink":"https://cezz.github.io/2021/12/26/go/channel%E5%88%B0%E5%BA%95%E9%9C%80%E4%B8%8D%E9%9C%80%E8%A6%81%E6%89%8B%E5%8A%A8%E5%85%B3%E9%97%AD%EF%BC%9F/","excerpt":"","text":"前景提要下面的代码是《go语言圣经》这本书的其中一个案例，其中主协程和子协程兼具生产消费两种身份了，最终当没有新的消息时代码会阻塞住，而书中没有给出该案例的终止方式，自己也是思考了很久，看来还是对go的channel理解不够深，在使用channel的时候一定要有自己的思考，不然可能会引发很多问题，小到程序莫名其妙的panic，大到出现goroutine以及channel的泄露等等！ 123456789101112131415161718192021222324252627282930313233343536373839func crawl(url string) []string &#123; urls, err := links.Extract(url) // 书中其他章节, 具体逻辑是提取网页中所有a标签的链接 if err != nil &#123; log.Print(err) &#125; return urls&#125;func main() &#123; worklist := make(chan []string) // lists of URLs, may have duplicates unseenLinks := make(chan string) // de-duplicated URLs urls := []string&#123;&quot;http://xxxx.com&quot;&#125; // Add command-line arguments to worklist. go func() &#123; worklist &lt;- urls &#125;() // Create 20 crawler goroutines to fetch each unseen link. for i := 0; i &lt; 20; i++ &#123; go func() &#123; for link := range unseenLinks &#123; foundLinks := crawl(link) go func() &#123; worklist &lt;- foundLinks &#125;() &#125; &#125;() &#125; // The main goroutine de-duplicates worklist items // and sends the unseen ones to the crawlers. seen := make(map[string]bool) for list := range worklist &#123; for _, link := range list &#123; if !seen[link] &#123; seen[link] = true unseenLinks &lt;- link &#125; &#125; &#125;&#125; 虽然上述并发案例书中未提及如何终止的问题，不过书里也提供了另外一种并发方式且可自动终止，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041// tokens is a counting semaphore used to// enforce a limit of 20 concurrent requests.var tokens = make(chan struct&#123;&#125;, 20)func crawl(w work, mutex sync.Locker) []work &#123; fmt.Println(url) tokens &lt;- struct&#123;&#125;&#123;&#125; // acquire a token urls, err := links.Extract(w.url) &lt;-tokens // release the token if err != nil &#123; log.Print(err) &#125; return urls&#125;func main() &#123; worklist := make(chan []string) var n int // number of pending sends to worklist url := []string&#123;&quot;http://xxxx.com&quot;&#125; // start n++ go func() &#123; worklist &lt;- []work&#123;url&#125; &#125;() // crawl the web concurrently visited := make(map[string]bool) for ; n &gt; 0; n-- &#123; works := &lt;-worklist for _, w := range works &#123; if !visited[w.url] &#123; visited[w.url] = true n++ go func(w work) &#123; worklist &lt;- crawl(w, &amp;lock) &#125;(w) &#125; &#125; &#125;&#125; 这种实现方式很巧妙，使用了计数器n进行了限制，主协程在n减为0的时候会终止，子协程也会随之退出。这里的channel在没有被goroutine引用的时候也会被gc所销毁，结合第一个没有终止的案例，我们必须手动去关闭掉生产消费，让程序达到所有消息消费完后自动终止的目的。那么以下知识点就是必须要掌握的！ 什么情况下关闭channel会引发panic？示例如下： 1234567891011121314151617181920212223242526272829303132333435363738394041// 1. 关闭未初始化的chanfunc TestCloseNilChan(t *testing.T) &#123; var errCh chan error close(errCh) // Output: // panic: close of nil channel&#125;// 2. 关闭已经关闭的chanfunc TestRepeatClosingChan(t *testing.T) &#123; errCh := make(chan error) close(errCh) close(errCh) // Output: // panic: close of closed channel&#125;// 3. 关闭chan后发送数据func TestSendOnClosingChan(t *testing.T) &#123; errCh := make(chan error) close(errCh) errCh &lt;- errors.New(&quot;chan error&quot;) // Output: // panic: send on closed channel&#125;// 4. 发送数据时关闭chanfunc TestCloseOnSendingToChan(t *testing.T) &#123; errCh := make(chan error) go func() &#123; errCh &lt;- errors.New(&quot;chan error&quot;) &#125;() time.Sleep(1 * time.Second) close(errCh) // Output: // panic: send on closed channel&#125; 总结， 下述四种情况下关闭channel会引发panic： 关闭未初始化的channel 关闭已经关闭的channel 在关闭channel后发送数据 在发送数据时关闭channel 另外，可总结出以下规律： 只能让channel的唯一发送者关闭此channel 如果有多个发送者，应该使用专门的信号通知stop channel是否有必要关闭channel？不关闭又如何？当channel的发送次数等于接收次数12345678910111213141516171819202122232425262728// 1. 当channel的发送次数等于接收次数func TestIsCloseChannelNecessary_on_equal(t *testing.T) &#123; fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) ch := make(chan int) // sender go func() &#123; for i := 0; i &lt; 3; i++ &#123; ch &lt;- i &#125; &#125;() // receiver go func() &#123; for i := 0; i &lt; 3; i++ &#123; fmt.Println(&lt;-ch) &#125; &#125;() time.Sleep(time.Second * 1) fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) // Output: // NumGoroutine: 2 // 0 // 1 // 2 // NumGoroutine: 2&#125; channel的发送次数等于接收次数时，发送者的goroutine和接收者的goroutine分别会在发送和接收结束时结束自己的goroutine，用于传输数据的channel也会由于代码没有使用被垃圾收集器回收。所以该种情况下不需手动关闭chanel。当channel的发送次数大于&#x2F;小于接收次数12345678910111213141516171819202122232425262728293031// 2. 当channel的发送次数大于/小于接收次数func TestIsCloseChannelNecessary_on_more_equal(t *testing.T) &#123; fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) ch := make(chan int) // sender go func() &#123; defer fmt.Println(&quot;exit 1&quot;) for i := 0; i &lt; 4; i++ &#123; ch &lt;- i &#125; &#125;() // receiver go func() &#123; defer fmt.Println(&quot;exit 2&quot;) for i := 0; i &lt; 3; i++ &#123; fmt.Println(&lt;-ch) &#125; &#125;() time.Sleep(time.Second * 1) fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) // Output: // NumGoroutine: 2 // 0 // 1 // 2 // exit 2 // NumGoroutine: 3&#125; channel的发送次数大于接收次数时，发送者goroutine会等待接收者接收而一直阻塞。所以发送者goroutine一直未退出，channel也会由于一直被发送者使用而无法被垃圾回收。未退出的goroutine和channel会造成内存泄露等问题。 总结： 在只有一个发送者和一个接收者的情况下，只要确保发送者或接收者不会阻塞，不关闭channel是可行的。 在无法判断channel的发送次数和接收次数时，应当在合适的时机关闭channel。 另外使用for range从channel取值的时候，需要手动close掉channel，否则消费者会一直阻塞进而panic抛出错误，会被判定为死锁。 如何判断channel是否关闭？ channel关闭后继续读取该chennel不会阻塞，而是返回对应类型的零值。 使用channel的多重返回值(如err, ok :&#x3D; &lt;- errCh)12345678910111213141516171819202122// 1. 使用channel的返回值判断其是否关闭func TestReadFromClosedChan(t *testing.T) &#123; var errCh = make(chan error) go func() &#123; defer close(errCh) errCh &lt;- errors.New(&quot;chan error&quot;) &#125;() go func() &#123; for i := 0; i &lt; 3; i++ &#123; err, ok := &lt;-errCh; fmt.Println(i, err, ok) &#125; &#125;() time.Sleep(time.Second) // Output: // 0 chan error true // 1 &lt;nil&gt; false // 2 &lt;nil&gt; false&#125; err, ok :&#x3D; &lt;- errCh的第二个值ok返回false表示该channel已关闭。 使用for range简化语法123456789101112131415161718192021// 2. 使用for range简化语法func TestReadFromClosedChan2(t *testing.T) &#123; var errCh = make(chan error) go func() &#123; defer close(errCh) errCh &lt;- errors.New(&quot;chan error&quot;) &#125;() go func() &#123; i := 0 for err := range errCh &#123; fmt.Println(i, err) i++ &#125; &#125;() time.Sleep(time.Second) // Output: // 0 chan error&#125; 如何优雅的关闭channel?详细案例参考文章：https://gfw.go101.org/article/channel-closing.html 在使用单通道的函数中错误的关闭channel的话，编译的时候就会报错 参考上述文章，针对常规情况下需要关闭channel的四种场景，做了以下总结： 一个发送者，一个接收者：发送者关闭channel；接收者使用select或for range判断channel是否关闭 一个发送者，多个接收者：同上 多个发送者，一个接收者：接收者接收完后，使用专门的信号channel关闭；发送者使用select监听该信号channel是否关闭 多个发送者，多个接收者：任意一方或第三方使用专门的信号channel关闭；发送者，接收者都使用select监听该信号channel是否关闭总结回到开头例举的爬虫案例，个人进行了改写，主要是添加了超过递归深度时的退出以及超时退出和使用信号channel通知所用生产消费的goroutine关闭。具体代码如下，还有很多完善的点，以后理解更深后再进行修改：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475type work struct &#123; url string depth int&#125;func crawl(w work, quit chan struct&#123;&#125;) []work &#123; fmt.Printf(&quot;depth: %d, url: %s\\n&quot;, w.depth, w.url) if w.depth &gt; 3 &#123; quit &lt;- struct&#123;&#125;&#123;&#125; return nil &#125; urls, err := links.Extract(w.url) if err != nil &#123; log.Print(err) &#125; var works []work for _, url := range urls &#123; works = append(works, work&#123;url, w.depth + 1&#125;) &#125; return works&#125;//!+func main() &#123; worklist := make(chan []work) // lists of URLs, may have duplicates unseenLinks := make(chan work) // de-duplicated URLs stopCh := make(chan struct&#123;&#125;) // signal chan to stop all goroutine quit := make(chan struct&#123;&#125;) urls := work&#123;&quot;http://example.com/&quot;, 1&#125; // Add command-line arguments to worklist. go func() &#123; worklist &lt;- []work&#123;urls&#125; &#125;() // Create 20 crawler goroutines to fetch each unseen link. for i := 0; i &lt; 20; i++ &#123; go func() &#123; for &#123; select &#123; case &lt;-stopCh: return case link, _ := &lt;-unseenLinks: foundLinks := crawl(link, quit) go func() &#123;worklist &lt;- foundLinks&#125;() &#125; &#125; &#125;() &#125; // The main goroutine de-duplicates worklist items // and sends the unseen ones to the crawlers. seen := make(map[string]bool) for &#123; select &#123; case list := &lt;-worklist: for _, link := range list &#123; if !seen[link.url] &#123; seen[link.url] = true unseenLinks &lt;- link &#125; &#125; case &lt;-quit: fmt.Println(&quot;Exit, 111&quot;) close(stopCh) return case &lt;-time.After(3 * time.Second): // 如果上面的ch一直没数据会阻塞, 那么select也会检测其他case条件, 检测到后3s超时退出 fmt.Println(&quot;Exit, timeout&quot;) close(stopCh) return &#125; &#125;&#125;","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"}],"tags":[]},{"title":"关于channel和goroutine的内存泄漏问题","slug":"go/关于channel和goroutine的内存泄露问题","date":"2021-11-19T15:18:41.000Z","updated":"2022-06-28T16:12:40.717Z","comments":true,"path":"2021/11/19/go/关于channel和goroutine的内存泄露问题/","link":"","permalink":"https://cezz.github.io/2021/11/19/go/%E5%85%B3%E4%BA%8Echannel%E5%92%8Cgoroutine%E7%9A%84%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%E9%97%AE%E9%A2%98/","excerpt":"","text":"本文主要了解为关闭channel情况下所引发的内存泄露问题。 一个发送者导致的内存泄露主要原因是接收者提前退出了，导致发送者一直阻塞，最后导致了goroutine泄露，如下所示： 123456789101112131415161718192021222324252627func TestLeakOfMemory(t *testing.T) &#123; fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) chanLeakOfMemory() time.Sleep(time.Second * 3) // 等待 goroutine 执行，防止过早输出结果 fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine())&#125;func chanLeakOfMemory() &#123; errCh := make(chan error) // (1) go func() &#123; // (5) time.Sleep(2 * time.Second) errCh &lt;- errors.New(&quot;chan error&quot;) // (2) &#125;() var err error select &#123; case &lt;-time.After(time.Second): // (3) 大家也经常在这里使用 &lt;-ctx.Done() fmt.Println(&quot;超时&quot;) case err = &lt;-errCh: // (4) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Println(nil) &#125; &#125;&#125; 上述代码分析： 由于没有发送方想errCh发送数据，故代码在(4)处阻塞 当(3)处超时后，函数退出且(4)处代码并未接收成功 之后(2)开始执行，由于errCh没有接收者，故一直阻塞在(2)出 因为(2)出的代码所在协程一直没有退出，故发生了内存泄露 这种情况处理起来也较为简单，只需将channel设置为有缓冲的就行。例如将(1)处代码改为errCh := make(chan error, 1)即可。 多个发送者导致的内存泄露产生原因也和上述相同，当接收者提前退出了，那么至少有一个goroutine无法退出，进而造成内存泄露。 12345678910111213141516171819202122232425262728293031func TestLeakOfMemory2(t *testing.T) &#123; fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) chanLeakOfMemory2() time.Sleep(time.Second * 3) // 等待 goroutine 执行，防止过早输出结果 fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine())&#125;func chanLeakOfMemory2() &#123; ich := make(chan int, 100) // (3) // sender go func() &#123; defer close(ich) for i := 0; i &lt; 10000; i++ &#123; ich &lt;- i time.Sleep(time.Millisecond) // 控制一下，别发太快 &#125; &#125;() // receiver go func() &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() for i := range ich &#123; // (2) if ctx.Err() != nil &#123; // (1) fmt.Println(ctx.Err()) return &#125; fmt.Println(i) &#125; &#125;()&#125; 尽管上述代码使用了有缓冲的channel，依然可能会出现接收者提前退出，导致有缓冲channel的缓存队列被占满，阻塞在第101个位置。这种情况需要使用一个额外的stop channel来结束发送者所在的goroutine，如下： 12345678910111213141516171819202122232425262728293031323334353637func TestLeakOfMemory2(t *testing.T) &#123; fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) chanLeakOfMemory2() time.Sleep(time.Second * 3) // 等待 goroutine 执行，防止过早输出结果 fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine())&#125;func chanLeakOfMemory2() &#123; ich := make(chan int, 100) stopCh := make(chan struct&#123;&#125;) // sender go func() &#123; defer close(ich) for i := 0; i &lt; 10000; i++ &#123; select &#123; case &lt;-stopCh: case ich &lt;- i: return &#125; time.Sleep(time.Millisecond) // 控制一下，别发太快 &#125; &#125;() // receiver go func() &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() for i := range ich &#123; if ctx.Err() != nil &#123; fmt.Println(ctx.Err()) close(stopCh) return &#125; fmt.Println(i) &#125; &#125;()&#125; 总结不论发送者发送一次还是多次，如果接收者在接收完channel中的数据之前退出，那么就会造成内存泄露。如果接收者需要在channel关闭之前退出，为了防止内存泄露，在发送者与接收者一对一时，应设置channel缓冲队列为1；在发送者与接收者一对多或多对多时，应使用专门的stop channel通知发送者关闭相应channel。","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"}],"tags":[]},{"title":"关于channel发生死锁的情况总结","slug":"go/关于channel发生死锁的情况总结","date":"2021-11-03T13:09:18.000Z","updated":"2022-06-28T16:13:32.202Z","comments":true,"path":"2021/11/03/go/关于channel发生死锁的情况总结/","link":"","permalink":"https://cezz.github.io/2021/11/03/go/%E5%85%B3%E4%BA%8Echannel%E5%8F%91%E7%94%9F%E6%AD%BB%E9%94%81%E7%9A%84%E6%83%85%E5%86%B5%E6%80%BB%E7%BB%93/","excerpt":"","text":"时刻提醒自己必须深入理解channel的特性，有自己的思考，而不是死记硬背。之后可以阅读熟悉下channel的底层实现原理。 向无缓冲的channel发送&#x2F;接收数据无缓冲的channel必须有接收才能发送，下述代码在执行的时候会引发deadlock错误 12345func main() &#123; ch := make(chan int) ch &lt;- 1 // 这一行代码会引发死锁 // &lt;-ch // 直接取值也会引发死锁&#125; 解决方法是启用一个goroutine去接收值，如下： 12345678910func recv(c chan int) &#123; ret := &lt;-c fmt.Println(ret)&#125;func main() &#123; ch := make(chan int) go recv(ch) ch &lt;- 1&#125; 思考：下述情况会引发死锁吗？ 1234567func main() &#123; ch := make(chan int) go func() &#123; ch &lt;- 1 &#125;() time.Sleep(time.Second * 3)&#125; 答案是不会引发死锁，虽然子协程一直阻塞在传值语句，但是和主协程之间并无产生联系，当主协程退出的时候子协程也就跟着退出了。延伸：如果主协程和子协程之间建立了联系会产生死锁吗？ 123456789func main() &#123; ch1 := make(chan, int) ch2 := make(chan, int) go func() &#123; ch2 &lt;- 21 ch1 &lt;- 11 &#125;() &lt;-ch1&#125; 输出有缓冲的channel中所有的值当读取完channel中的数据后，继续读取的操作会造成阻塞，且阻塞发生在主协程中，故会引发阻塞。 12345678func main() &#123; ch := make(chan int, 2) ch &lt;- 1 ch &lt;- 2 for ch := range ch &#123; fmt.Println(ch) &#125;&#125; 解决方法是发送完所有数据后则关闭channel，或者通过select方法中的default进行处理，如下： 123456789101112131415161718func main() &#123; ch := make(chan int, 2) ch &lt;- 1 ch &lt;- 2 // solution 1: // close(ch) // solution 2: // select &#123; // case v := &lt;-ch: // fmt.Println(v) // default: // fmt.Println(&quot;nothing in channel&quot;) // &#125; for ch := range ch &#123; fmt.Println(ch) &#125;&#125; 过度向有缓冲的channel写入数据写入数据超过channel的容量的时候，也会引发死锁。 123456func main() &#123; ch := make(chan int, 2) ch &lt;- 1 ch &lt;- 2 ch &lt;- 3&#125; 解决方法是通过select方法中的default进行处理： 1234567891011func main() &#123; ch := make(chan int, 2) ch &lt;- 1 ch &lt;- 2 select &#123; case ch &lt;- 3: fmt.Println(&quot;ok&quot;) default: fmt.Println(&quot;wrong&quot;) &#125;&#125; 总结上述提到的死锁，是指在程序的主协程中发生的情况，如果上述情况是发生在非主协程中，读取或者写入的情况是发生阻塞的，而不是死锁(此时需要考虑是否需要主动关闭子协程)。实际上，阻塞情况省去了我们加锁的步骤，反而是更加有利于代码编写，要合理的运用阻塞。","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"}],"tags":[]},{"title":"如何主动关闭goroutine","slug":"go/如何主动关闭goroutine？","date":"2021-10-22T12:22:41.000Z","updated":"2022-06-28T16:08:48.495Z","comments":true,"path":"2021/10/22/go/如何主动关闭goroutine？/","link":"","permalink":"https://cezz.github.io/2021/10/22/go/%E5%A6%82%E4%BD%95%E4%B8%BB%E5%8A%A8%E5%85%B3%E9%97%ADgoroutine%EF%BC%9F/","excerpt":"","text":"在学习go语言channel中，读到最多的一句话便是通过通信共享内存，而不是通过共享内存来进行通信（Do not communicate by sharing memory；instead，share memory by communicating.）那么如何来理解这句话呢？个人理解通过共享内存来通信的话必须保证数据的安全及正确性，即需要通过加锁等手段进行控制，但是此种方式带来的性能开销以及可能造成的死锁问题处理起来较为繁琐。而go语言则通过channel来通信，通过通信来传递内存数据，个人认为更加优雅简洁与高效。很多情况下我们需要主动关闭goroutine，那么如何实现呢？ 使用channel进行控制for-range结构for-range从channel上获取值，直到channel关闭。该结构对于从单一通道上获取数据去执行某些任务是十分方便的，如下所示： 123456789101112131415161718192021func producer(out chan&lt;- int) &#123; for i := 0; i &lt; 10; i++ &#123; data := i * i fmt.Println(&quot;生产者生产数据：&quot;, data) out &lt;- data &#125; close(out)&#125;func consumer(in &lt;-chan int) &#123; for data := range in &#123; fmt.Println(&quot;消费者得到数据：&quot;, data) &#125;&#125;func main() &#123; ch := make(chan int) go producer(ch) consumer(ch)&#125; for-select结构当channel比较多时，for-range结构就不是很方便了。此时可以使用for-select，select能够让goroutine在多个通信操作上等待（可以理解为监听多个channel）。 指定一个退出的channel12345678910111213141516171819202122232425262728func producer(out chan&lt;- int, exit chan struct&#123;&#125;) &#123; for i := 0; i &lt; 10; i++ &#123; data := i * i fmt.Println(&quot;生产者生产数据：&quot;, data) out &lt;- data &#125; exit &lt;- struct&#123;&#125;&#123;&#125;&#125;func consumer(in &lt;-chan int, exit chan struct&#123;&#125;) &#123; for &#123; select &#123; case &lt;-exit: fmt.Println(&quot;收到退出信号&quot;) // 不建议使用goto语句 return // 必须return, 否则goroutine不会结束 case data := &lt;-in: fmt.Println(&quot;消费者得到数据：&quot;, data) &#125; &#125;&#125;func main() &#123; ch := make(chan int) exitCh := make(chan struct&#123;&#125;) go producer(ch, exitCh) consumer(ch, exitCh)&#125; 多个channel都关闭才能退出12345678910111213141516171819202122232425262728293031323334353637383940func producer(out1, out2 chan&lt;- int) &#123; for i := 0; i &lt; 10; i++ &#123; data := i * i fmt.Println(&quot;生产者生产数据：&quot;, data) out1 &lt;- data time.Sleep(1 * time.Second) out2 &lt;- data * 2 &#125; close(out1) close(out2)&#125;func consumer(in1, in2 &lt;-chan int) &#123; for &#123; select &#123; case data, ok := &lt;-in1: if !ok &#123; fmt.Println(&quot;收到ch1关闭信号&quot;) in1 = nil &#125; fmt.Println(&quot;消费者得到数据：&quot;, data) case data, ok := &lt;-in2: if !ok &#123; fmt.Println(&quot;收到ch2关闭信号&quot;) in2 = nil &#125; fmt.Println(&quot;消费者得到数据：&quot;, data) &#125; if in1 == nil &amp;&amp; in2 == nil &#123; return &#125; &#125;&#125;func main() &#123; ch1 := make(chan int) ch2 := make(chan int) go producer(ch1, ch2) consumer(ch1, ch2)&#125; 使用content包进行控制context是官方提供的用于控制多个goroutine协作的包。 1234567891011121314151617181920212223242526272829303132333435363738394041func producer(out chan&lt;- int, ctx context.Context, cancel context.CancelFunc) &#123; for i := 0; i &lt; 10; i++ &#123; data := i * i fmt.Println(&quot;生产者生产数据：&quot;, data) out &lt;- data &#125; subCtx, _ := context.WithCancel(ctx) go consumer2(subCtx) cancel()&#125;func consumer(in &lt;-chan int, ctx context.Context) &#123; for &#123; select &#123; case data := &lt;-in: fmt.Println(&quot;消费者得到数据：&quot;, data) case &lt;-ctx.Done(): fmt.Println(&quot;收到结束信号&quot;) return // 必须return, 防止goroutine泄露 &#125; &#125;&#125;func consumer2(ctx context.Context) &#123; for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;收到结束信号, consumer2&quot;) return // 必须return, 防止goroutine泄露 &#125; &#125;&#125;func main() &#123; ctx, cancel := context.WithCancel(context.Background()) ch := make(chan int) go producer(ch, ctx, cancel) consumer(ch, ctx) time.Sleep(1 * time.Second)&#125; 总结在实际开发过程中，不会简单的启动goroutine就结束了。往往是需要有效的管理多个goroutine之间的协作，此时掌握如何主动关闭goroutine就显得尤为重要了。不仅如此，还需要学会分析go语言运行性能，下一个目标就是学习go语言中的性能大杀器pprof。","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"}],"tags":[]},{"title":"如何控制并发速率","slug":"go/如何控制并发速率？","date":"2021-10-11T14:31:19.000Z","updated":"2022-06-28T16:09:56.259Z","comments":true,"path":"2021/10/11/go/如何控制并发速率？/","link":"","permalink":"https://cezz.github.io/2021/10/11/go/%E5%A6%82%E4%BD%95%E6%8E%A7%E5%88%B6%E5%B9%B6%E5%8F%91%E9%80%9F%E7%8E%87%EF%BC%9F/","excerpt":"","text":"为什么需要控制123456789101112func main() &#123; var wg sync.WaitGroup for i := 0; i &lt; math.MaxInt32; i++ &#123; wg.Add(1) go func(i int) &#123; defer wg.Done() fmt.Println(i) time.Sleep(time.Second) &#125;(i) &#125; wg.Wait()&#125; 过高的并发会将系统资源消耗殆尽，导致程序运行最终panic，关键的报错信息如下：panic: too many concurrent operations on a single file or socket (max 1048575) 导致出现上述错误的原因是源自fmt.Printf函数输出到标准输出，标准输出也可以视为文件，总之就是系统的资源被耗尽了。 就算注释掉fmt.Printf函数，也会因为内存不足而最终崩溃。 如何解决解决的主要方式就是限制并发的协程数量。 使用带缓冲的channel进行控制123456789101112131415func main() &#123; var wg sync.WaitGroup ch := make(chan struct&#123;&#125;, 3) for i := 0; i &lt; 10; i++ &#123; ch &lt;- struct&#123;&#125;&#123;&#125; wg.Add(1) go func(i int) &#123; defer wg.Done() log.Println(i) time.Sleep(time.Second) &lt;-ch &#125;(i) &#125; wg.Wait()&#125; 创建一个缓冲区大小为3的channel，在没有被接收的情况下，最多发送3个消息则被阻塞 开启协程前，调用ch &lt;- struct&#123;&#125;&#123;&#125;，若缓冲区满则阻塞 协程任务结束，调用&lt;-ch释放缓冲区 利用第三方库目前有很多第三方库实现了协程池，可以很方便的用来控制协程的并发数量，如Jeffail/tunny，panjf2000/ants，以tunny举例如下： 12345678910111213func main() &#123; pool := tunny.NewFunc(3, func(i interface&#123;&#125;) interface&#123;&#125; &#123; log.Println(i) time.Sleep(time.Second) return nil &#125;) defer pool.Close() for i := 0; i &lt; 10; i++ &#123; go pool.Process(i) &#125; time.Sleep(time.Second * 4)&#125; tunny.NewFunc(3, f)第一个参数是协程池的大小(poolSize)，第二个参数是协程运行的函数(worker) pool.Process(i)将参数i传递给协程池定义好的worker处理 pool.Close()关闭协程池 调整系统资源上限ulimit有些情况下，即使我们有效的限制了协程的并发数量，但是仍旧出现某一类资源不足的问题，例如： too many open files out of memory 操作系统通常会限制同时打开文件数量，栈空间大小等，ulimit -a可以看到系统的当前设置： 1234567891011121314151617[root@master ~]# ulimit -acore file size (blocks, -c) unlimiteddata seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 14997max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 100001pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 14997virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited 进而进行按需调整即可。 虚拟内存virtual memory虚拟内存是一项非常常见的技术，当内存不足时，将磁盘映射为内存使用，比如linux下的交换分区(swap space)。在linux上创建并使用交换分区是一件非常简单的事情： 12345sudo fallocate -l 20G /mnt/.swapfile # 创建 20G 空文件sudo mkswap /mnt/.swapfile # 转换为交换分区文件sudo chmod 600 /mnt/.swapfile # 修改权限为 600sudo swapon /mnt/.swapfile # 激活交换分区free -m # 查看当前内存使用情况(包括交换分区) 关闭交换分区也非常简单： 12sudo swapoff /mnt/.swapfilerm -rf /mnt/.swapfile 磁盘的 I&#x2F;O 读写性能和内存条相差是非常大的，例如 DDR3 的内存条读写速率很容易达到 20GB&#x2F;s，但是 SSD 固态硬盘的读写性能通常只能达到 0.5GB&#x2F;s，相差 40倍之多。因此，使用虚拟内存技术将硬盘映射为内存使用，显然会对性能产生一定的影响。如果应用程序只是在较短的时间内需要较大的内存，那么虚拟内存能够有效避免 out of memory 的问题。如果应用程序长期高频度读写大量内存，那么虚拟内存对性能的影响就比较明显了。","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"}],"tags":[]},{"title":"go语言实现爬虫(三)","slug":"go/个人项目实战：go语言实现爬虫(三)","date":"2021-09-15T16:12:23.000Z","updated":"2022-06-28T16:18:26.065Z","comments":true,"path":"2021/09/16/go/个人项目实战：go语言实现爬虫(三)/","link":"","permalink":"https://cezz.github.io/2021/09/16/go/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%EF%BC%9Ago%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E7%88%AC%E8%99%AB(%E4%B8%89)/","excerpt":"","text":"添加grpc简单编写proto文件： 1234567891011121314151617181920212223242526272829syntax = &quot;proto3&quot;;option go_package = &quot;./;proto&quot;;service Crawler &#123; rpc Start (StartReq) returns (TaskInfoResp) &#123;&#125; rpc Stop (TaskInfoReq) returns (TaskInfoResp) &#123;&#125; rpc Status (TaskInfoReq) returns (TaskInfoResp) &#123;&#125; rpc Pause (TaskInfoReq) returns (TaskInfoResp) &#123;&#125; rpc Resume (TaskInfoReq) returns (TaskInfoResp) &#123;&#125; rpc Result (TaskInfoReq) returns (TaskInfoResp) &#123;&#125;&#125;message StartReq &#123; string taskID = 1; repeated string urls = 2; int32 threads = 3; int32 timeout = 4; int32 depth = 5;&#125;message TaskInfoReq &#123; string taskID = 1;&#125;message TaskInfoResp &#123; int32 code = 1; string msg = 2; repeated string data = 3;&#125; 运行测试","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"}],"tags":[]},{"title":"go语言实现爬虫(二)","slug":"go/个人项目实战：go语言实现爬虫(二)","date":"2021-09-13T13:05:57.000Z","updated":"2022-06-28T16:21:25.740Z","comments":true,"path":"2021/09/13/go/个人项目实战：go语言实现爬虫(二)/","link":"","permalink":"https://cezz.github.io/2021/09/13/go/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%EF%BC%9Ago%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E7%88%AC%E8%99%AB(%E4%BA%8C)/","excerpt":"","text":"使用gin封装项目目录结构如下： api：主要业务逻辑实现，结合gin的上下文进行封装 config：项目主要配置文件 global：全局变量管理 model：结构体定义的地方 proto：定义proto文件，存放其生成的go文件 router：路由控制 storage：运行日志存储及临时结果存放 util：常用的工具类封装 1234567891011121314151617181920212223242526272829303132333435363738├─api│ │ base.go│ ││ └─crawler│ │ crawl.go│ ││ └─links│ links.go│├─config│ settings.go│├─global│ global.go│├─model│ ├─request│ │ request.go│ ││ └─response│ response.go│├─proto│ crawler.proto│├─router│ router.go│├─storage│ ├─logs│ └─tasks│─utils│ └─writer│ write_data.go│ go.mod│ go.sum│ main.go│ readme.md 完善各控制流程任务定义及初始化如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445type work struct &#123; url string // 网页链接 currDepth int // 当前深度&#125;type WlcTask struct &#123; taskID string // 任务ID workList chan []work // 存放每一个链接下一层的所有链接 workListBak chan []work // workList的备份, 用于任务的暂停与恢复 unVisitedLinks chan work // 存放未访问过的链接 stopSignalCh chan struct&#123;&#125; // 用于通知所有生产消费的goroutine退出, 防止内存泄露 quitCh chan struct&#123;&#125; // 用于主动停止任务, 通过递归深度判断 statusCh chan string // 用于记录任务状态变化 visited map[string]bool // 标记已访问过的链接 startUrl []work // 开始链接 concurrency int // 并发数量 timeOut int // 超时时间设置 depth int // 递归深度 currDepth int // 当前递归深度 status string // 任务状态 created running stopped finished pausing resuming&#125;func NewWclTask(wlcReq *request.WlcTaskReq) *WlcTask &#123; var startUrl []work for _, url := range wlcReq.Urls &#123; startUrl = append(startUrl, work&#123;url: url, currDepth: 1&#125;) &#125; workListCh := make(chan []work) return &amp;WlcTask&#123; taskID: wlcReq.TaskID, workList: workListCh, workListBak: workListCh, unVisitedLinks: make(chan work), stopSignalCh: make(chan struct&#123;&#125;), quitCh: make(chan struct&#123;&#125;), statusCh: make(chan string), visited: make(map[string]bool), startUrl: startUrl, concurrency: wlcReq.Concurrency, timeOut: wlcReq.Timeout, depth: wlcReq.Depth, currDepth: 1, status: config.TaskStatus.Created, &#125;&#125; 另外，还针对WlcTask封装了一个改变任务状态的方法： 1234567891011121314151617181920212223242526func (w *WlcTask) ChangeTaskStatus() &#123; for &#123; select &#123; case &lt;-w.stopSignalCh: log.Printf(&quot;[Start] record task(%s) status goroutine exit...&quot;, w.taskID) return case taskStr, ok := &lt;-w.statusCh: if ok &#123; arr := strings.Split(taskStr, &quot;,&quot;) w.status = arr[0] currDepth, err := strconv.Atoi(arr[1]) if err != nil &#123; log.Println(err) &#125; log.Printf(&quot;[Start] change task(%s) status to %s, depth is, %d&quot;, w.taskID, w.status, currDepth) // recode the task info to a json file task := request.TaskInfo&#123; Status: arr[0], CurrDepth: currDepth, &#125; writer.TaskInfoWriter(w.taskID, &amp;task) &#125; &#125; &#125;&#125; 启动12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061func (w *WlcTask) StartHandler(globalTask map[string]*WlcTask) &#123; // record the task status change go w.ChangeTaskStatus() go func() &#123; w.workList &lt;- w.startUrl &#125;() w.statusCh &lt;- fmt.Sprintf(&quot;%s,%d&quot;, config.TaskStatus.Running, w.currDepth) for i := 0; i &lt; w.concurrency; i++ &#123; go func(num int) &#123; for &#123; select &#123; case &lt;-w.stopSignalCh: log.Printf(&quot;[Start] task(%s) goroutine %d exit...&quot;, w.taskID, num) return case link, _ := &lt;-w.unVisitedLinks: foundLinks := crawl(link, w.depth, w.quitCh) go func() &#123; w.workList &lt;- foundLinks &#125;() &#125; &#125; &#125;(i) &#125; for &#123; select &#123; case list := &lt;-w.workList: // change taskStatus from resuming to running if w.status != config.TaskStatus.Running &#123; w.status = config.TaskStatus.Running &#125; for _, link := range list &#123; if !w.visited[link.url] &#123; w.visited[link.url] = true w.unVisitedLinks &lt;- link // write crawl result to file and update currDepth writer.TaskResultWriter(fmt.Sprintf(&quot;%s.txt&quot;, w.taskID), fmt.Sprintln(link.url)) if link.currDepth != w.currDepth &#123; w.currDepth = link.currDepth &#125; &#125; &#125; case &lt;-w.quitCh: log.Printf(&quot;[Start] task(%s) over than crawl depth, get quit signal and exit&quot;, w.taskID) w.statusCh &lt;- fmt.Sprintf(&quot;%s,%d&quot;, config.TaskStatus.Stopped, w.currDepth) close(w.stopSignalCh) delete(globalTask, w.taskID) return case &lt;-time.After(time.Duration(w.timeOut) * time.Second): if w.status == config.TaskStatus.Pausing || w.status == config.TaskStatus.Resuming &#123; continue &#125; else &#123; log.Printf(&quot;[Start] task(%s) execute timeout, get timeout signal and exit&quot;, w.taskID) w.statusCh &lt;- fmt.Sprintf(&quot;%s,%d&quot;, config.TaskStatus.Finished, w.currDepth) close(w.stopSignalCh) delete(globalTask, w.taskID) return &#125; &#125; &#125;&#125; 停止停止较为简单，直接向退出信号channel发送消息即可： 123func (w *WlcTask) StopHandler() &#123; w.quitCh &lt;- struct&#123;&#125;&#123;&#125;&#125; 暂停暂停的思路是将数据传输的channel赋值为nil，则相关的goroutine会阻塞进而整个执行暂停。 12345678910111213func (w *WlcTask) PauseHandler() &#123; if w.status == config.TaskStatus.Pausing &#123; log.Printf(&quot;[Pause] task(%s) is already pause, can&#x27;t pause again&quot;, w.taskID) return &#125; if w.status == config.TaskStatus.Stopped || w.status == config.TaskStatus.Finished &#123; log.Printf(&quot;[Pause] task(%s) is closed, can&#x27;t pause&quot;, w.taskID) return &#125; w.statusCh &lt;- fmt.Sprintf(&quot;%s,%d&quot;, config.TaskStatus.Pausing, w.currDepth) w.workList = nil log.Printf(&quot;[Pause] task(%s) is pausing&quot;, w.taskID)&#125; 恢复将之前备份好的数据channel重新赋值给当前使用的channel，则相关goroutine会接着运行。 123456789func (w *WlcTask) ResumingHandler() &#123; if w.status != config.TaskStatus.Pausing &#123; log.Printf(&quot;[Resume] task(%s) is not pausing, can&#x27;t resume&quot;, w.taskID) return &#125; w.workList = w.workListBak w.statusCh &lt;- fmt.Sprintf(&quot;%s,%d&quot;, config.TaskStatus.Resuming, w.currDepth) log.Printf(&quot;[Resume] task(%s) is resuming&quot;, w.taskID)&#125; 状态及结果获取状态获取： 123func (w *WlcTask) StatusHandler() (status string, currDepth int) &#123; return w.status, w.currDepth&#125; 结果获取： 12345678func ResultHandler(taskID string) (links []string, err error) &#123; f, err := ioutil.ReadFile(taskID + &quot;.txt&quot;) if err != nil &#123; return nil, err &#125; links = strings.Split(string(f), &quot;\\n&quot;) return links[:len(links)-1], nil&#125; 思考 本文使用的是channel控制整个流程，当换成标准库context时如何编写？ 路由的地方有重复性的地方，考虑如何优化？ 当前项目未自定义错误，如何完善整个项目的异常处理？","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"}],"tags":[]},{"title":"go语言实现爬虫(一)","slug":"go/个人项目实战：go语言实现爬虫(一)","date":"2021-09-06T11:47:11.000Z","updated":"2022-06-28T16:17:38.631Z","comments":true,"path":"2021/09/06/go/个人项目实战：go语言实现爬虫(一)/","link":"","permalink":"https://cezz.github.io/2021/09/06/go/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%EF%BC%9Ago%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E7%88%AC%E8%99%AB(%E4%B8%80)/","excerpt":"","text":"本项目适合在快速学习完go语言后的一个简单练手，主要达成以下功能： 能够递归的抓取网页链接，通过递归深度进行控制停止 支持爬取的并发控制，超时处理，以及其执行过程的暂停与恢复 基于gin提供restful的api接口，包括启动，停止，暂停，恢复，查看状态，获取结果等 提供grpc远程调用功能，并调研grpc-gateway，简单做一个学习案例 注：本文仅总结了重要的部分，还需不断进行完善，具体项目点击链接查看。 页面解析依赖模块golang.org/x/net/html，Extract函数向给定URL发起HTTP GET请求，解析HTML并返回HTML文档中存在的链接，如果要在此部分添加或删除规则，那么可以修改此函数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263func Extract(url string) ([]string, error) &#123; resp, err := http.Get(url) if err != nil &#123; return nil, err &#125; if resp.StatusCode != http.StatusOK &#123; return nil, fmt.Errorf(&quot;getting %s: %s&quot;, url, resp.Status) &#125; doc, err := html.Parse(resp.Body) defer resp.Body.Close() if err != nil &#123; return nil, fmt.Errorf(&quot;parsing %s as HTML: %v&quot;, url, err) &#125; var links []string visitNode := func(n *html.Node) &#123; if n.Type == html.ElementNode &amp;&amp; n.Data == &quot;a&quot; &#123; for _, a := range n.Attr &#123; if a.Key != &quot;href&quot; &#123; continue &#125; link, err := resp.Request.URL.Parse(a.Val) if err != nil &#123; continue // ignore bad URLs &#125; links = append(links, link.String()) &#125; &#125; &#125; forEachNode(doc, visitNode, nil) //forEachNode(doc, startElement, endElement) return links, nil&#125;func forEachNode(n *html.Node, pre, post func(n *html.Node)) &#123; if pre != nil &#123; pre(n) &#125; for c := n.FirstChild; c != nil; c = c.NextSibling &#123; forEachNode(c, pre, post) &#125; if post != nil &#123; post(n) &#125;&#125;var depth intfunc startElement(n *html.Node) &#123; if n.Type == html.ElementNode &#123; fmt.Printf(&quot;%*s&lt;%s&gt;\\n&quot;, depth*2, &quot;&quot;, n.Data) depth++ &#125;&#125;func endElement(n *html.Node) &#123; if n.Type == html.ElementNode &#123; depth-- fmt.Printf(&quot;%*s&lt;/%s&gt;\\n&quot;, depth*2, &quot;&quot;, n.Data) &#125;&#125; 然后再根据广度优先遍历的思想新建一个函数breadthFirst，breadthFirst对每个worklist元素调用f，并将返回的内容添加到worklist中，对每一个元素，最多调用一次f。 123456789101112131415161718192021222324252627282930313233343536373839func breadthFirst(f func(item string) []string, worklist []string) &#123; seen := make(map[string]bool) for len(worklist) &gt; 0 &#123; items := worklist worklist = nil for _, item := range items &#123; if !seen[item] &#123; seen[item] = true worklist = append(worklist, f(item)...) &#125; &#125; &#125;&#125;func crawl(urlStr string) []string &#123; fmt.Println(urlStr) list, err := links.Extract(urlStr) if err != nil &#123; log.Print(err) &#125; //// extract same domain //var filterList []string //u, _ := url.Parse(urlStr) //for _, link := range list &#123; // l, _ := url.Parse(link) // if u.Hostname() == l.Hostname() &#123; // filterList = append(filterList, link) // &#125; //&#125; return list&#125;func main() &#123; urls := []string&#123;&quot;http://www.xxxx.com&quot;&#125; breadthFirst(crawl, urls)&#125; 并发控制在go语言中实现并发较为简单，只需要在函数定义前加上关键字go即可。对于爬虫而言，过高的并行度也不是一个好的做法，如何合理的控制并发速率也成为了当前需要控制的重点，下面介绍两种并发控制方式。 方式一利用有缓冲的channel控制并发，并灵活的通过一个计数器n来控制程序自动结束。 12345678910111213141516171819202122232425262728293031323334353637383940// tokens is a counting semaphore used to// enforce a limit of 20 concurrent requests.var tokens = make(chan struct&#123;&#125;, 20)func crawl(url string) []string &#123; fmt.Println(url) tokens &lt;- struct&#123;&#125;&#123;&#125; // acquire a token list, err := links.Extract(url) &lt;-tokens // release the token if err != nil &#123; log.Print(err) &#125; return list&#125;func main() &#123; worklist := make(chan []string) var n int url := &quot;http://www.xxxx.com&quot; // start n++ go func() &#123; worklist &lt;- []string&#123;url&#125; &#125;() // crawl the web concurrently visited := make(map[string]bool) for ; n &gt; 0; n-- &#123; list := &lt;-worklist for _, link := range list &#123; if !visited[link] &#123; visited[link] = true n++ go func(link string) &#123; worklist &lt;- crawl(link) &#125;(link) &#125; &#125; &#125;&#125; 方式二使用一定数量常驻goroutine控制并发，并在channel中没有数据后一定时间内超时退出。 123456789101112131415161718192021222324252627282930313233func main() &#123; worklist := make(chan []string) // lists of URLs, may have duplicates unseenLinks := make(chan string) // de-duplicated URLs // Add command-line arguments to worklist. go func() &#123; worklist &lt;- os.Args[1:] &#125;() // Create 20 crawler goroutines to fetch each unseen link. for i := 0; i &lt; 20; i++ &#123; go func() &#123; for link := range unseenLinks &#123; foundLinks := crawl(link) go func() &#123; worklist &lt;- foundLinks &#125;() &#125; &#125;() &#125; // The main goroutine de-duplicates worklist items // and sends the unseen ones to the crawlers. seen := make(map[string]bool) for &#123; select &#123; case list := &lt;-worklist &#123; for _, link := range list &#123; if !seen[link] &#123; seen[link] = true unseenLinks &lt;- link &#125; &#125; case &lt;- time.After(3 * time.Second) fmt.Println(&quot;Exit, timeout&quot;) return &#125; &#125;&#125; 递归深度要控制抓取的递归深度可以从crawl函数入手，将url进行封装，添加一个depth属性，当获取这个url的下一层链接时则对depth进行加一。另外还需添加一个信号控制channel，当递归层数满足要求时，发送信号控制程序退出。 123456789101112131415161718192021222324type work struct &#123; url string depth int&#125;func crawl(w work, quit chan struct&#123;&#125;) []work &#123; fmt.Printf(&quot;depth: %d, url: %s\\n&quot;, w.depth, w.url) if w.depth &gt; 3 &#123; quit &lt;- struct&#123;&#125;&#123;&#125; return nil &#125; urls, err := links.Extract(w.url) if err != nil &#123; log.Print(err) &#125; var works []work for _, url := range urls &#123; works = append(works, work&#123;url, w.depth + 1&#125;) &#125; return works&#125;","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"}],"tags":[]},{"title":"go语言中string和[]byte之间的转换","slug":"go/go语言中string和[]byte之间的转换","date":"2021-08-29T14:52:38.000Z","updated":"2022-06-28T16:22:22.880Z","comments":true,"path":"2021/08/29/go/go语言中string和[]byte之间的转换/","link":"","permalink":"https://cezz.github.io/2021/08/29/go/go%E8%AF%AD%E8%A8%80%E4%B8%ADstring%E5%92%8C[]byte%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BD%AC%E6%8D%A2/","excerpt":"","text":"在项目实际运用中发现数据量较大时，通过pprof进行性能分析发现string到byte的标准转换内存消耗十分大，后使用了unsafe包进行强转后性能有了很大的提升，在此记录下。 转换方式标准转换123456// string to []bytes1 := &quot;hello&quot;b := []byte(s1)// []byte to strings2 := string(b) 强转换1234567func string2bytes(s string) []byte &#123; return *(*[]byte)(unsafe.Pointer(&amp;s))&#125;func bytes2string(b []byte) string &#123; return *(*string)(unsafe.Pointer(&amp;b))&#125; 性能对比123456789101112131415161718192021222324252627func Benchmark_NormalString2Bytes(b *testing.B) &#123; x := &quot;Test Normal String 2 Bytes With Go!&quot; for i := 0; i &lt; b.N; i++ &#123; _ = []byte(x) &#125;&#125;func Benchmark_Bytes2String(b *testing.B) &#123; x := []byte(&quot;Test Unsafe Bytes 2 String With Go!&quot;) for i := 0; i &lt; b.N; i++ &#123; _ = bytes2string(x) &#125;&#125;func Benchmark_NormalString2Bytes(b *testing.B) &#123; x := &quot;Test Normal String 2 Bytes With Go!&quot; for i := 0; i &lt; b.N; i++ &#123; _ = []byte(x) &#125;&#125;func Benchmark_String2Bytes(b *testing.B) &#123; x := &quot;Test Normal String 2 Bytes With Go!&quot; for i := 0; i &lt; b.N; i++ &#123; _ = string2bytes(x) &#125;&#125; 测试结果如下： 123456789101112D:\\goproject\\study_go\\study_unsafe\\test_byte_string&gt;go test -bench=&quot;.&quot; -benchmemgoos: windowsgoarch: amd64pkg: study_go/study_unsafe/test_byte_stringcpu: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHzBenchmark_NormalBytes2String-12 43473496 28.20 ns/op 48 B/op 1 allocs/opBenchmark_Bytes2String-12 1000000000 0.2593 ns/op 0 B/op 0 allocs/opBenchmark_NormalString2Bytes-12 31570804 35.06 ns/op 48 B/op 1 allocs/opBenchmark_String2Bytes-12 1000000000 0.2626 ns/op 0 B/op 0 allocs/opPASSok study_go/study_unsafe/test_byte_string 4.436s 由上述可见，强转换性能明显优于标准转换 原理分析首先需要了解string和slice的底层数据结构： 12345678910type StringHeader struct &#123; Data uintptr Len int&#125;type SliceHeader struct &#123; Data uintptr Len int Cap int&#125; 在go中，任何类型的指针*T都可以转化为unsafe.Pointer类型的指针，它可以存储任何变量的地址 unsafe.Pointer类型的指针也可以转换回普通指针，而且不必和之前的类型*T相同 unsafe.Pointer类型还可以转换为uintptr类型，该类型保存了指针所指向地址的数值，从而可以对地址进行数值计算。 思考总结为什么强转换性能比标准转换好？ 对于标准转换，无论是从[]byte转string还是从string转[]byte都会涉及到底层数组的拷贝。而强转换是直接替换指针的指向，从而使得string和[]byte指向同一个底层数组。故后者的性能会更好 在上述测试中，当数据较大时，标准转换会有一次分配内存的操作，从而导致其性能更差，而为什么强转换不受影响？ 标准转换时，当数据长度大于32个字节时，需要通过mallocgc申请新的内存，之后再进行数据拷贝工作。而强转换只是更改指针的指向。故当数据较大时，两者性能差距越明显。","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"}],"tags":[]},{"title":"go语言中的数据结构","slug":"go/go语言中的数据结构","date":"2021-08-21T15:01:04.000Z","updated":"2022-06-28T16:21:51.794Z","comments":true,"path":"2021/08/21/go/go语言中的数据结构/","link":"","permalink":"https://cezz.github.io/2021/08/21/go/go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","excerpt":"","text":"数组初始化12arr1 := [3]int&#123;1, 2, 3&#125; // 显示指定数组大小arr2 := [...]int&#123;1, 2 ,3&#125; // 使用[...]T声明数组 [...]T初始化数组的方式是go语言提供的一种语法糖，最终也会转化为具体元素数量 在不考虑逃逸分析的情况下，如果数组中元素个数小于等于4个，则所有的变量会直接在栈上初始化；反之如果数组元素大于4个，变量就会在静态存储去初始化然后拷贝到栈上。 访问和赋值 无论是在栈上还是静态存储区，数组在内存中都是一连串的内存空间。我们通过指向数组开头的指针、元素的数量以及元素类型占的空间大小表示数组。 数组和字符串的一些简单的越界错误都会在编译期间发现。如使用整数或常量访问数组，但是如果使用变量去访问数组或字符串时，编译器就无法提前发现错误，此时会在运行时阻止不合法的访问。小结对数组的访问和赋值同时需要依赖编译器和运行时支持，其大多数操作在编译期间都会转换成直接读写内存，在中间代码生成期间，编译器还会插入运行时方法runtime.panicIndex防止发生越界错误。切片数据结构切片在运行时由reflect.SliceHeader结构体表示，如下：12345type SliceHeader struct &#123; Data uintptr // 指向数组的指针 Len int // 当前切片的长度 Cap int // 当前切片的容量, 即Data数组的大小&#125; 初始化有以下三种初始化切片的方式：12345678// 1. 通过下标的方式获得数组或切片的一部分arr[0:3] or slice[0:3]// 2. 使用字面量初始化新的切片slice := []int&#123;1, 2, 3&#125;// 3. 使用make关键字slice := make([]int, 10) 使用下标：使用下标初始化切片不会拷贝原数组或原切片中的数据，它只会创建一个指向原数组的切片结构体，所以修改新切片的数据也会修改原切片。 使用字面量：根据切片中的元素数量对底层数组的大小进行推断并创建一个数组，将字面量元素存储到初始化的数组中，创建一个同样指向相同类型的数组指针，将初始化的数组赋值给指针所在的地址，通过[:]操作获取一个底层使用该地址的切片。 访问元素切片的操作基本都是在编译期间完成的，除了访问切片的长度、容量或者其中的元素之外，编译期间也会将包含range关键字的遍历转换成形式更简单的循环。 追加和扩容当切片容量不足时，会调用runtime.growslice进行切片扩容。扩容是为切片分配新的内存空间并拷贝原切片中元素的过程，那么新切片的容量如何确定呢？ 如果期望容量大于当前容量的两倍就会使用当前容量 如果当前切片的长度小于1024就会将容量翻倍 如果当前切片的长度大于1024就会每次增加25%的容量，直到新容量大于期望容量 另外上述调用仅会确定切片的大致容量，还需要根据切片中的元素大小进行内存对齐。 拷贝切片无论是编译期间拷贝还是运行时拷贝，两种拷贝方式都会通过runtime.memmove将整块内存的内容拷贝到目标的内存区域中，相比于依次拷贝元素，runtime.memmove能提供更好的性能。 小结切片的很多功能都是由运行时实现的，无论是初始化切片，还是对切片进行追加或扩容都需要运行时的支持，需要注意的是在遇到大切片扩容或者复制时可能会发生大规模的内存拷贝，一定要减少类似的操作避免影响程序的性能。 字典哈希冲突开放寻址法拉链法 数据结构go语言运行时使用了多个数据结构组合表示哈希表，最核心的结构体runtime.hmap如下所示： 12345678910111213141516171819type hmap struct &#123; count int // 表示当前哈希表中的元素数量 flags uint8 B uint8 // 表示当前哈希表持有的buckets数量(都是2的倍数) noverflow uint16 hash0 uint32 // 哈希种子，为哈希函数的结果引入随机性 buckets unsafe.Pointer oldbuckets unsafe.Pointer // 扩容时用于保存之前buckets字段 nevacuate uintptr extra *mapextra&#125;type mapextra struct &#123; overflow *[]*bmap oldoverflow *[]*bmap nextOverflow *bmap&#125; 如上所示哈希表runtime.hmap的桶是runtime.bmap，每一个runtime.bmap都能存储8个键值对。当哈希表中存储的数据过多，单个桶已经装满时就会使用extra.nextOverflow中桶存储溢出的数据。这两种不同的桶在内存中都是连续的，分别称之为正常桶和溢出桶 初始化字面量 12345hash := map[string]int&#123; &quot;1&quot;: 2, &quot;2&quot;: 4, &quot;5&quot;: 6,&#125; 使用字面量初始化的过程都会使用go语言中的关键字make来创建新的哈希并通过最原始的[]语法向哈希追加元素，另外最终都是调用runtime.makemap。 读写操作扩容在以下两种情况下会进行扩容： 装载因子已经超过6.5 哈希使用了太多溢出桶 小结 go语言使用了拉链法来解决哈希碰撞的问题实现了哈希表，它的读写等操作都是在编译期间转换成了运行时的函数或方法。哈希在每一个桶中存储键对应哈希的前8位，当对哈希进行操作时，这些tophash就成为可以帮助哈希快速遍历桶中元素的缓存。 哈希表的每个桶都只能存储8个键值对，一旦当前哈希的某个桶超出8个，新的键值对就会存储到哈希的溢出桶中。随着键值对数量的增加，溢出桶的数量和哈希的装载因子也会逐渐升高，超过一定范围就会触发扩容，扩容会将桶的数量翻倍，元素再分配的过程也是在调用写操作时增量进行的，不会造成性能的瞬时巨大抖动。字符串数据结构字符串在运行时会使用如下的reflect.StringHeader表示：1234type StringHeader struct &#123; Data uintptr // 指向字节数组的指针 Len int // 数组的大小&#125; 字符串是只读的类型，我们并不会直接向字符串追加元素改变其本身的内存空间，所有字符串上的写入操作都是通过拷贝实现的。 解析过程1234str1 := &quot;this is a string&quot;str2 := `this is anotherstring` 类型转换 当解析和序列化json等数据格式时，经常需要将数据在string和[]byte之间来回转换，而类型转换的开销并没有想象的那么小。 字符串和[]byte中的内容虽然一样，但是字符串的内容是只读的，我们不能通过下标或者其他形式改变其中的数据，而跑[]byte中的内容是可读写的。不过无论从哪种类型转换到另一种都需要拷贝数据，而内存拷贝的性能损耗会随着字符串和[]byte长度的增长而增长。小结字符串作为只读的数据类型，我们无法改变其本身的结构，但是在做拼接和类型转换等操作时一定要注意性能的损耗，遇到需要极致性能的场景一定要尽量减少类型转换的次数。","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"}],"tags":[]},{"title":"go语言中make和new的区别","slug":"go/go语言中make和new的区别","date":"2021-08-03T13:11:27.000Z","updated":"2022-05-23T01:08:55.098Z","comments":true,"path":"2021/08/03/go/go语言中make和new的区别/","link":"","permalink":"https://cezz.github.io/2021/08/03/go/go%E8%AF%AD%E8%A8%80%E4%B8%ADmake%E5%92%8Cnew%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"make用于初始化内置的数据结构，如slice，map，channel new的作用是根据传入的类型分配一片内存空间并返回指向这片内存空间的指针123slice := make([]int, 0, 100)hash := make(map[int]bool, 10)ch := make(chan int, 5) slice是一个包含data，cap和len的结构体reflect.SliceHeader hash是一个指向runtime.hmap结构体的指针 ch是一个指向runtime.hchan结构体的指针 1234i := new(int)var v inti := &amp;v 上述代码片段两种初始化方法是等价的，它们都会创建一个指向int零值的指针 make在编译期间的类型检查阶段，go语言会将代表make关键字的OMAKE节点根据参数类型的不同转换成了OMAKESLICE、OMAKEMAP和OMAKECHAN三种不同类型的节点，这些节点会调用不同的运行时函数来初始化相应的数据结构。 new编译器会在中间代码生成阶段通过以下两个函数处理该关键字： cmd/compile/internal/gc.callnew会将关键字转换成ONEWOBJ类型的节点 cmd/complie/internal/gc.state.expr会根据申请空间的大小分两种情况处理 如果申请的空间为0，就会返回一个表示空指针的zerobase变量 在遇到其他情况时会将关键字转换成runtime.newobject函数小结简单总结一下go语言中make和new关键字的实现原理，make关键字的作用是创建切片、哈希表和Channel等内置的数据结构，而new的作用是为类型申请一片内存空间，并返回指向这片内存的指针。","categories":[{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"}],"tags":[]},{"title":"在Django中使用缓存","slug":"django/在Django中使用缓存","date":"2020-08-16T04:19:21.000Z","updated":"2022-06-28T16:26:28.416Z","comments":true,"path":"2020/08/16/django/在Django中使用缓存/","link":"","permalink":"https://cezz.github.io/2020/08/16/django/%E5%9C%A8Django%E4%B8%AD%E4%BD%BF%E7%94%A8%E7%BC%93%E5%AD%98/","excerpt":"","text":"快速开始缓存是什么(What?) 缓存就是数据交换的缓冲区(称作Cache)，是存储数据的临时地方。当用户查询数据，首先在缓存中寻找，如果找到了则直接执行。如果找不到，则去数据库查找。 缓存的本质就是用空间换时间，牺牲数据的实时性，以服务器内存中的数据暂时代替从数据库读取的数据，减少数据库IO，减轻服务器压力，减少网络延迟，加快页面打开速度。 存储介质访问速度比较 来自Google工程师Jeff Dean的分享，仅供参考： 存储介质 速度 L1 cache reference 读取CPU的一级缓存 0.5 ns Branch mispredict(转移、分支预测) 5 ns L2 cache reference 读取CPU的二级缓存 7 ns Mutex lock&#x2F;unlock 互斥锁\\解锁 100 ns Main memory reference 读取内存数据 100 ns Compress 1K bytes with Zippy 1k字节压缩 10,000 ns Send 2K bytes over 1 Gbps network 在1Gbps的网络上发送2k字节 20,000 ns Read 1 MB sequentially from memory 从内存顺序读取1MB 250,000 ns Round trip within same datacenter 从一个数据中心往返一次，ping一下 500,000 ns Disk seek 磁盘搜索 10,000,000 ns Read 1 MB sequentially from network从网络上顺序读取1兆的数据 10,000,000 ns Read 1 MB sequentially from disk 从磁盘里面读出1MB 30,000,000 ns Send packet CA-&gt;Netherlands-&gt;CA 一个包的一次远程访问 150,000,000 ns 访问流程： 1234567graph TBA(读操作_) --&gt; B&#123;查询缓存_&#125;B --&gt; |有缓存_| C[返回_]B --&gt; |无缓存_| D[查询数据库_]D --&gt; E[放入缓存_] 缓存的优点: 减少了磁盘和网络IO来提高吞吐量，减少计算量(CPU计算)释放CPU，提高系统的响应速度。 面向切面的处理发出，可以在各层进行插拔，是所有性能优化的最简单有效的解决方案。 缓存应用场景(Where?) 对于数据实时性要求不高对于一些经常访问但是很少改变的数据，读明显多于写，使用缓存就很有必要。比如一些网站配置项。 对于性能要求高比如一些秒杀活动场景。 基于DRF快速开始(How?)pip install drf-extensions key值计算: {“view_instance”: “”, “view_method”: “”, “request”:””, “args”:””, “kwargs”: “”} –&gt; json –&gt; md5\\rest_framework_extensions\\key_constructor\\constructors.py 123456789101112131415161718192021222324252627282930313233343536373839404142# settings.py REST_FRAMEWORK_EXTENSIONS = &#123; &#x27;DEFAULT_OBJECT_CACHE_KEY_FUNC&#x27;: &#x27;rest_framework_extensions.utils.default_object_cache_key_func&#x27;, &#x27;DEFAULT_LIST_CACHE_KEY_FUNC&#x27;: &#x27;rest_framework_extensions.utils.default_list_cache_key_func&#x27;, &#x27;DEFAULT_CACHE_RESPONSE_TIMEOUT&#x27;: 60 * 15, &#x27;DEFAULT_CACHE_ERRORS&#x27;: False &#125; # views.py # usage 1: don&#x27;t overwirte list, retrieve method from rest_framework_extensions.cache.mixins import CacheResponseMixin class StudentViewSet(CacheResponseMixin, viewsets.ModelViewSet): pass # usage: 2 from rest_framework_extensions.cache.decorators import cache_response from rest_framework_extensions.utils import default_object_cache_key_func class StudentViewSet(CacheResponseMixin, viewsets.ModelViewSet): @cache_response(key_func=default_object_cache_key_func, cache_errors=False) def retrieve(self, request, *args, **kwargs): pass ``` &gt; python自带的缓存机制```pythonimport timeitfrom functools import lru_cache# @lru_cache(None)def fib(n): if n &lt; 2: return n return fib(n - 2) + fib(n - 1) print(timeit.timeit(lambda: fib(35), number=1)) 一、缓存类型1. 数据库缓存 常用的缓存方案有memcached、redis等 。把经常要从数据库查询的数据，或经常更新的数据放入到缓存中。这样下次查询时，直接从缓存直接返回，减轻数据库压力，提升数据库性能。 2. 服务器端缓存2.1 代理服务器缓存 代理服务器是浏览器和源服务器之间的中间服务器，浏览器先向这个中间服务器发起Web请求，经过处理后(比如权限验证，缓存匹配等)，再将请求转发到源服务器。 代理服务器缓存的运作原理跟浏览器的运作原理差不多，只是规模更大。可以把它理解为一个共享缓存，不只为一个用户服务，一般为大量用户提供服务，因此在减少响应时间和带宽使用方面很有效，同一个副本会被重用多次。 2.2 CDN缓存 也叫网关缓存、反向代理缓存。CDN缓存一般是由网站管理员自己部署，为了让他们的网站更容易扩展并获得更好的性能。 浏览器先向CDN网关发起Web请求，网关服务器后面对应着一台或多台负载均衡源服务器，会根据它们的负载请求，动态将请求转发到合适的源服务器上。 虽然这种架构负载均衡源服务器之间的缓存没法共享，但却拥有更好的处扩展性。从浏览器角度来看，整个CDN就是一个源服务器。 2.3 DNS缓存 万维网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。DNS协议运行在UDP协议之上，使用端口号53。 有dns的地方,就有缓存。浏览器、操作系统、Local DNS、根域名服务器，它们都会对DNS结果做一定程度的缓存。 DNS查询过程如下: 首先搜索浏览器自身的DNS缓存,如果存在，则域名解析到此完成。 如果浏览器自身的缓存里面没有找到对应的条目，那么会尝试读取操作系统的hosts文件看是否存在对应的映射关系,如果存在，则域名解析到此完成。 如果本地hosts文件不存在映射关系，则查找本地DNS服务器(ISP服务器,或者自己手动设置的DNS服务器),如果存在,域名到此解析完成。 如果本地DNS服务器还没找到的话,它就会向根服务器发出请求,进行递归查询。 3. 浏览器缓存 浏览器缓存根据一套与服务器约定的规则进行工作，在同一个会话过程中会检查一次并确定缓存的副本足够新。如果在浏览过程中前进或后退时访问到同一个图片，这些图片可以从浏览器缓存中调出而即时显示。 4. web应用层缓存 应用层缓存指的是从代码层面上，通过代码逻辑和缓存策略，实现对数据、页面、图片等资源的缓存，可以根据实际情况选择将数据存在文件系统或者内存中，减少数据库查询或者读写瓶颈，提高响应效率。 二、缓存淘汰策略1. FIFOFIFO (First in First out)， 先进先出。核心原则就是: 如果一个数据最先进入缓存中，则应最早淘汰掉。 2. LFULFU (Least Frequently Used)，最不频繁使用，以使用次数作为参考。 核心思想：如果数据过去被访问多次，那么将来被访问的几率也更高。 3. LRULRU(Least Recently Used)，最近最少使用，以时间作为参考。 核心思想：如果数据最近被访问过，那么将来被访问的频率也更高 三、Django缓存系统伪代码解释动态网站生成页面时，缓存是怎么工作的 123456789101112131415161718192021222324given a URL, try finding that page in the cache if the page is in the cache: return the cached page else: generate the page save the generated page in the cache (for next time) return the generated page ``` ## 设置缓存 ### django-redis - 更多详细配置参阅[官方文档](https://github.com/jazzband/django-redis)- `pip install django-redis` ```pythonCACHES = &#123; &quot;default&quot;: &#123; &quot;BACKEND&quot;: &quot;django_redis.cache.RedisCache&quot;, &quot;LOCATION&quot;: &quot;redis://127.0.0.1:6379/1&quot;, # &quot;LOCATION&quot;: &quot;redis://username:password@localhost:6379/0&quot; &quot;OPTIONS&quot;: &#123; &quot;CLIENT_CLASS&quot;: &quot;django_redis.client.DefaultClient&quot;, &#125; &#125;&#125; memcached 完全基于内存的缓存服务器： 是Django支持的最快，最高效的缓存类型。—&gt; Facebook，Wikipedia都有使用其来减少数据库访问并显著提高网站性能缓存的数据存储在内存中，如果服务器崩溃，那么数据将会丢失。 pip install python-memached pip install pylibmc 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115# use python-memcached CACHES = &#123; &#x27;default&#x27;: &#123; &#x27;BACKEND&#x27;: &#x27;django.core.cache.backends.memcached.MemcachedCache&#x27;, &#x27;LOCATION&#x27;: &#x27;127.0.0.1:11211&#x27;, # &#x27;LOCATION&#x27;: &#x27;unix:/tmp/memcached.sock&#x27;, # 能在多个服务器上共享缓存，即无需再每台机器上复制缓存值 # &#x27;LOCATION&#x27;: [ # &#x27;172.19.26.240:11211&#x27;, # &#x27;172.19.26.242:11211&#x27;, # ] &#125; &#125; # use pylibmc CACHES = &#123; &#x27;default&#x27;: &#123; &#x27;BACKEND&#x27;: &#x27;django.core.cache.backends.memcached.PyLibMCCache&#x27;, &#x27;LOCATION&#x27;: &#x27;/tmp/memcached.sock&#x27;, &#125; &#125; ``` ### 数据库缓存 - 适用于有一个快速，索引正常的数据库服务器。 - `python manage.py createcachetable` ```python CACHES = &#123; &#x27;default&#x27;: &#123; &#x27;BACKEND&#x27;: &#x27;django.core.cache.backends.db.DatabaseCache&#x27;, &#x27;LOCATION&#x27;: &#x27;my_cache_table&#x27;, &#125; &#125; ``` ### 文件系统缓存 - 一个缓存值为一个单独的文件 - 注意指定目的写权限问题。 ```python CACHES = &#123; &#x27;default&#x27;: &#123; &#x27;BACKEND&#x27;: &#x27;django.core.cache.backends.filebased.FileBasedCache&#x27;, &#x27;LOCATION&#x27;: &#x27;/var/tmp/django_cache&#x27;, # &#x27;LOCATION&#x27;: &#x27;c:/foo/bar&#x27;, &#125; &#125; ``` ### 本地内存缓存 - 是默认的缓存方式 - 使用LRU淘汰策略 &gt; 每个进程都有其自己的私有缓存实例，意味着不存在跨进程的缓存。 &gt; 也意味着本地缓存不是特别节省内存，不是生产环境的好选择，但在开发环境表现很好。 ```python CACHES = &#123; &#x27;default&#x27;: &#123; &#x27;BACKEND&#x27;: &#x27;django.core.cache.backends.locmem.LocMemCache&#x27;, &#x27;LOCATION&#x27;: &#x27;unique-snowflake&#x27;, &#125; &#125; ``` ### 虚拟缓存(用于开发模式) - 只是实现了缓存接口，并不做其他操作 - 如果你有一个正式网站在不同地方使用了重型缓存，但你不想在开发环境使用缓存时非常有用。 ```python CACHES = &#123; &#x27;default&#x27;: &#123; &#x27;BACKEND&#x27;: &#x27;django.core.cache.backends.dummy.DummyCache&#x27;, &#125; &#125; ``` ### 缓存参数 - **`TIMEOUT`**: 超时时间，默认为300秒。设置为`None`表示永不过时。 - **`OPTIONS`**: 实现自有的淘汰策略的缓存后端（比如 `locmem`, `filesystem` 和 `database` 后端）将遵循以下选项 -- **`MAX_ENTRIES`**: 允许缓存的最大条目， 默认为300。 -- **`CULL_FREQUENCY`**: 当达到最大条目时淘汰的条目数量，默认为3。比率为1 / CULL_FREQUENCY，为0是清空整个缓存。 - **`KEY_PREFIX`**: Django 服务器使用的所有缓存键的字符串。 - **`VERSION`**: 通过 Django 服务器生成的缓存键的默认版本号。 - **`KEY_FUNCTION`**: 一个包含指向函数的路径的字符串，该函数定义将如何前缀、版本和键组成最终的缓存键。 ## 站点缓存 ```python MIDDLEWARE = [ &#x27;django.middleware.cache.UpdateCacheMiddleware&#x27;, &#x27;django.middleware.common.CommonMiddleware&#x27;, &#x27;django.middleware.cache.FetchFromCacheMiddleware&#x27;, ] ``` ## 视图缓存 &gt; **cache_page**设置的缓存超时优先于Cache-Control头中的&quot;max_age&quot;&gt; 和缓存站点一样，对试图缓存以URL为键。如果多个URL指向相同的试图，每个URL将被单独缓存。```python from django.views.decorators.cache import cache_page @cache_page(60 * 15, cache=&quot;default&quot;, key_frefix=&quot;site1&quot;) def my_view(request): pass ``` ## 底层缓存API &gt; 以任意级别粒度在缓存中存储对象，如：模型对象的字符串、字典、列表，或者其他(pickle)。### 访问缓存&gt; 可通过`django.core.cache.caches`对象访问在CACHES配置的缓存。&gt; 重复请求同一个线程里的同一个别名将返回同一个对象。```pythonfrom django.core.cache import cachescache1 = caches[&#x27;myalias&#x27;]cache2 = caches[&#x27;myalias&#x27;]cache1 is cache2 # True 作为快捷方式，默认缓存可以通过django.core.cache.cache引用。等价于caches[&#39;default&#39;] 基本用法 cache.set(key, value, timeout&#x3D;DEFAULT_TIMEOUT, version&#x3D;None) cache.get(key, default&#x3D;None, version&#x3D;None) cache.add(key, value, timeout&#x3D;DEFAULT_TIMEOUT, version&#x3D;None) cache.get_or_set(key, default, timeout&#x3D;DEFAULT_TIMEOUT, version&#x3D;None) cache.get_many(keys, version&#x3D;None) cache.set_many(dict, timeout) cache.delete(key, version&#x3D;None) cache.delete_many(keys, version&#x3D;None) cache.clear() cache.touch(key, timeout&#x3D;DEFAULT_TIMEOUT, version&#x3D;None) 12345678# delete cachefrom django.core.cache import cachefrom django.utils.cache import get_cache_keyclass StudentViewSet(CacheResponseMixin, BaseModelViewSet): def update(self, request, *args, **kwargs): cache.delete(get_cache_key(request)) 下游缓存略 使用Vary标头略 四、常用的缓存组件1. Memcache详见另一篇笔记。 启动命令：memcached -d -m 10m -p 11211 -u root缓存过期策略：当内存容量达到指定值之后，就会基于LRU算法自动删除不使用的缓存。 2. Redis详见另一篇笔记。缓存过期策略： # MAXMEMORY POLICY: how Redis will select what to remove when maxmemory # is reached. You can select one from the following behaviors: # volatile-lru -&gt; Evict using approximated LRU, only keys with an expire set. # allkeys-lru -&gt; Evict any key using approximated LRU. # volatile-lfu -&gt; Evict using approximated LFU, only keys with an expire set. # allkeys-lfu -&gt; Evict any key using approximated LFU. # volatile-random -&gt; Remove a random key having an expire set. # allkeys-random -&gt; Remove a random key, any key. # volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL) # noeviction -&gt; Don&#39;t evict anything, just return an error on write operations. # # LRU means Least Recently Used # LFU means Least Frequently Used # # Both LRU, LFU and volatile-ttl are implemented using approximated # randomized algorithms. # # Note: with any of the above policies, Redis will return an error on write # operations, when there are no suitable keys for eviction. # # At the date of writing these commands are: set setnx setex append # incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd # sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby # zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby # getset mset msetnx exec sort # # The default is: # # maxmemory-policy noeviction Redis过期机制参考 五、缓存带来的问题1. 数据一致性 产生原因： ①先删除缓存：在写数据库之前，如果有读请求发生，可能导致旧数据入缓存， 引发数据不一致。②先修改数据库： a.在有缓存的情况下，两个并发的读写操作。写操作在删除缓存的时候，缓存删除失败，读操作此时读到的数据是老数据，引发数据不一致。(此处考虑是删除缓存还是更新缓存)b.在没有缓存的情况下，两个并发的读写操作。读操作没有及时的把数据放入缓存，写操作进来修改了数据库，删除了缓存，然后读操作恢复，把老数据写进了缓存。 解决方案： 延迟双删–&gt;改进–&gt;内存队列删除缓存(如果删除缓存失败，可以多次尝试)考虑到系统复杂度，一般情况下先修改数据库，后删除缓存就行。 2. 缓存击穿 产生原因： 针对某一key，该缓存在某一时间点过期的时候，刚好有对应这个key的大量并发请求过来，此时请求会直接走到数据库，可能回导致数据库崩溃。 解决方案： **①使用互斥锁(mutex key)**：使用zookeeper或者Redis实现互斥锁，等待第一个请求创建完缓存之后才允许后续请求继续访问。**②”数据永不过期”**：在value的内部设置一个超时值(timeout1)，timeout1比实际的超时时间小。当从缓存读取到timeout1发现其已经过期时，马上延迟timeout1并重新设置到缓存。然后再从数据库加载数据并这是到缓存中。 3. 缓存穿透 产生原因： 由于缓存是不命中时被动写的，且出于容错考虑，如果从数据库查不到数据就不写入缓存，当数据库中本来就不存在的数据一直被请求，在流量大时，数据库可能就会崩溃。 解决方案: ①请求校验：对请求url进行校验，有可能是恶意攻击。②使用布隆过滤器：将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层数据库的查询压力。③对空结果进行缓存：如果查询一个数据返回为空(不管是数据不存在还是系统故障)，仍然将这个空结果进行缓存，但需要设置过期时间。 4. 缓存雪崩 产生原因： 由于设置缓存时采用了相同的过期时间(或者服务器宕机)，导致缓存在某一时刻同时失效，请求全部转发到数据库，数据库瞬间压力过重而导致崩溃。 解决方案： ①将过期时间分散：在过期时间后面加上一个随机数，让key均匀的失效。②使用队列或锁控制：用队列或者锁让程序执行在压力范围之内，当然这种方案可能会影响并发量。③配置redis高可用，服务降级，缓存数据持久化","categories":[{"name":"django","slug":"django","permalink":"https://cezz.github.io/categories/django/"}],"tags":[]},{"title":"pyenv的使用","slug":"python/pyenv的使用","date":"2020-07-29T10:02:49.000Z","updated":"2022-05-23T08:42:48.553Z","comments":true,"path":"2020/07/29/python/pyenv的使用/","link":"","permalink":"https://cezz.github.io/2020/07/29/python/pyenv%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"pyenv安装(ubuntu)1. 拉取源代码git clone https://github.com/pyenv/pyenv.git ~/.pyenv 2. 定义环境变量1234echo &#x27;export PYENV_ROOT=&quot;$HOME/.pyenv&quot;&#x27; &gt;&gt; ~/.bashrcecho &#x27;export PATH=&quot;PYENV_ROOT/bin:$PATH&quot;&#x27; &gt;&gt; ~/.bashrcecho -e &#x27;if command -v pyenv 1&gt;/dev/null 2&gt;&amp;1;then\\n eval &quot;$(pyenv init -)&quot;\\nfi&#x27; &gt;&gt; ~/.bashrcsource /root/.bashrc 3. 安装python编译依赖1234sudo apt-get install -y build-essential libbz2-dev libssl-dev libreadline-dev libsqlite3-dev tk-dev libffi-dev# for Numpy,Matplotlibb,Scipy,etc.sudo apt-get install -y libpng-dev libfreetype6-dev python安装1. 修改镜像源export PYTHON_BUILD_MIRROR_URL=&quot;https://mirrors.huaweicloud.com&quot; 2. 安装指定版本123# 镜像源没用的话，提前下载好tar.xz包pyenv install 3.9.0 插件pyenv-virtualenv安装1. 下载插件到指定文件夹git clone https://github.com/pyenv/pyenv-virtualenv.git /root/.pyenv/plugins/pyenv-virtualenv 2. 添加到环境变量echo &#39;eval &quot;$(pyenv virtualenv-init-)&quot;&#39; &gt;&gt; ~/.bash_profile 3. 创建虚拟环境pyenv virtualenv 3.9.0 venvFirmadyne 4. 重启shell使其生效exec &quot;$SHELL&quot; 5. 激活及退出虚拟环境12pyenv activate venvFirmadynepyenv deactivate 6. 删除虚拟环境rm -rf /root/.pyenv/version/3.9.0/envs/venvFirmadyne pip源更换123456vim /root/.pip/pip.conf[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple[install]trusted-host = pypi.tuna.tsinghua.edu.cn 图片插入示例","categories":[{"name":"python","slug":"python","permalink":"https://cezz.github.io/categories/python/"}],"tags":[]},{"title":"python协程的相关总结","slug":"python/python协程的相关总结","date":"2020-07-26T11:35:21.000Z","updated":"2022-06-28T16:27:09.611Z","comments":true,"path":"2020/07/26/python/python协程的相关总结/","link":"","permalink":"https://cezz.github.io/2020/07/26/python/python%E5%8D%8F%E7%A8%8B%E7%9A%84%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93/","excerpt":"","text":"生成器可迭代对象、迭代器、生成器 可迭代对象：实现了方法__iter__或__getitem__就是可迭代的。 迭代器：在可迭代对象的基础上实现了__next__方法，__iter__方法需返回一个迭代器，如果自身是迭代器则返回self。 生成器：可以理解为在迭代器的基础上再实现了yield，yield返回新的值后，会在当前位置阻塞，等待下一次的调用。 如何激活生成器 next() generator.send(None) 生成器的执行状态 GEN_CREATED GEN_RUNNING GEN_SUSPENDED GEN_CLOSED 生成器的异常处理当生成器不满足生成元素的条件时，就应该抛出异常StopIteration 从生成器过度到协程 协程是为非抢占式多任务产生子程序的计算机程序组件，协程允许不同入口点在不同位置暂停或开始执行程序。 如何向生成器中发送消息： 12345678910111213141516def jumping_range(N): index = 0 while index &lt; N: # 通过send()发送的消息将赋值给jump jump = yield index if jump is None: jump += 1 index += jumpif __name__ == &#x27;__main__&#x27;: itr = jumping_range(5) print(next(itr)) # 0 print(itr.send(2)) # 2 print(next(itr)) # 3 print(itr.send(-1)) # 2 重点在于jump = yield index yield index 是将index return给外部调用程序 jump = yield 是可以接收外部程序通过send()发送的信息，并赋值给jump yield from 语法为什么要使用协程如果没有协程，要去实现一个并发程序，可能会有以下问题 使用最常规的同步编程要实现异步并发效果并不理想，或者难度极高 由于GIL锁的存在，多线程的运行需要频繁的加锁解锁，切换线程，这极大的降低了并发性能 而协程的出现，刚好可以解决以上的问题，它的特点有 协程是在单线程里实现任务的切换的 利用同步的方式去实现异步 不再需要锁，提高了并发性能 yield from用法详解yield from 是在python3.3才出现的语法。这个特性是在python2中没有的。yield from 后面是需要加可迭代对象，它可以普通的可迭代对象，也可以是迭代器，甚至是生成器。 1234567891011121314151617# usage: yielddef gen_1(*args, **kwargs): for item in args: for i in item: yield idef gen_2(*args, **kwargs): for item in args: yield from itemstr_1 = &quot;test&quot;list_1 = [1, 2, 3]ret_1 = gen_1(str_1, list_1)ret_2 = gen_2(str_1, list_1)# [&#x27;t&#x27;, &#x27;e&#x27;, &#x27;s&#x27;, &#x27;t&#x27;, 1, 2, 3] 生成器嵌套 调用方：调用委托生成器的客户端代码 委托生成器：包含yield from的表达式生成器函数 子生成器：yield from 后面加的生成器函数","categories":[{"name":"python","slug":"python","permalink":"https://cezz.github.io/categories/python/"}],"tags":[]}],"categories":[{"name":"python","slug":"python","permalink":"https://cezz.github.io/categories/python/"},{"name":"go","slug":"go","permalink":"https://cezz.github.io/categories/go/"},{"name":"数据库","slug":"数据库","permalink":"https://cezz.github.io/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"其他","slug":"其他","permalink":"https://cezz.github.io/categories/%E5%85%B6%E4%BB%96/"},{"name":"docker","slug":"docker","permalink":"https://cezz.github.io/categories/docker/"},{"name":"django","slug":"django","permalink":"https://cezz.github.io/categories/django/"},{"name":"grpc","slug":"grpc","permalink":"https://cezz.github.io/categories/grpc/"},{"name":"爬虫","slug":"python/爬虫","permalink":"https://cezz.github.io/categories/python/%E7%88%AC%E8%99%AB/"},{"name":"项目实战","slug":"go/项目实战","permalink":"https://cezz.github.io/categories/go/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"}],"tags":[]}