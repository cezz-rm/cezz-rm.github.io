{"meta":{"title":"Hexo","subtitle":"","description":"","author":"CeJ","url":"https://zcej.github.io","root":"/"},"pages":[{"title":"关于","date":"2022-05-23T01:27:43.000Z","updated":"2022-05-23T03:29:43.790Z","comments":false,"path":"about/index.html","permalink":"https://zcej.github.io/about/index.html","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637&#123; &quot;name&quot;: &quot;CeJ&quot;, &quot;age&quot;: 27, &quot;gender&quot;: &quot;man&quot;, &quot;profression&quot;: &quot;python &amp; go Developer&quot;, &quot;experience&quot;: &quot;4 years&quot;, &quot;address&quot;: &quot;BeiJing&quot;, &quot;education&quot;: &quot;Southwest Jiaotong University&quot;, &quot;major&quot;: &quot;mechanical design, manufacturing and automation&quot;, &quot;github&quot;: &quot;https://github.com/zcej&quot;, &quot;description&quot;: &quot;faithful to your heart, fruitful to your result&quot;, &quot;skills&quot;: [ [&quot;HTML5&quot;, &quot;javascript&quot;, &quot;jquery&quot;, &quot;css&quot;], [&quot;python&quot;, &quot;go&quot;], [&quot;django&quot;, &quot;flask&quot;, &quot;gin&quot;, &quot;grpc&quot;, &quot;vue&quot;], [&quot;mysql&quot;, &quot;redis&quot;, &quot;mongodb&quot;], [&quot;linux&quot;, &quot;shell&quot;], [&quot;rabbitmq&quot;], [&quot;git&quot;, &quot;svn&quot;], [&quot;docker&quot;, &quot;kubernetes&quot;], ], &quot;devTools&quot;: [ [&quot;pycharm&quot;, &quot;goland&quot;, &quot;webstorm&quot;], [&quot;sublime&quot;, &quot;nptepad++&quot;], [&quot;chrome&quot;, &quot;fiddler&quot;], [&quot;navicat&quot;], [&quot;mobaxterm&quot;], [&quot;snipaste&quot;, &quot;faststone&quot;, &quot;processon&quot;], ], &quot;hobby&quot;: &#123; &quot;sports&quot;: [&quot;ping-pong&quot;, &quot;badminton&quot;], &quot;animation&quot;: [&quot;one piece&quot;, &quot;naruto&quot;, &quot;black&quot;] &#125;&#125;"},{"title":"书单","date":"2022-05-23T01:25:50.000Z","updated":"2022-05-23T01:26:28.458Z","comments":false,"path":"books/index.html","permalink":"https://zcej.github.io/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2022-04-10T06:46:53.000Z","updated":"2022-04-10T06:49:32.991Z","comments":false,"path":"categories/index.html","permalink":"https://zcej.github.io/categories/index.html","excerpt":"","text":""},{"title":"友链","date":"2022-05-23T01:26:49.000Z","updated":"2022-05-23T01:27:19.285Z","comments":false,"path":"links/index.html","permalink":"https://zcej.github.io/links/index.html","excerpt":"","text":""},{"title":"tags","date":"2022-05-23T01:21:14.000Z","updated":"2022-05-23T01:22:32.583Z","comments":false,"path":"tags/index.html","permalink":"https://zcej.github.io/tags/index.html","excerpt":"","text":""},{"title":"项目","date":"2022-05-23T01:24:19.000Z","updated":"2022-05-23T01:25:24.126Z","comments":false,"path":"repository/index.html","permalink":"https://zcej.github.io/repository/index.html","excerpt":"","text":""}],"posts":[{"title":"快速上手BeautifulSoup4","slug":"爬虫/BeautifulSoup4解析","date":"2022-06-08T13:03:11.000Z","updated":"2022-07-03T13:18:10.759Z","comments":true,"path":"2022/06/08/爬虫/BeautifulSoup4解析/","link":"","permalink":"https://zcej.github.io/2022/06/08/%E7%88%AC%E8%99%AB/BeautifulSoup4%E8%A7%A3%E6%9E%90/","excerpt":"","text":"安装安装BeautifulSoup可通过系统的包管理工具安装： 1apt-get install Python-bs4 或者通过python的包管理工具pip进行安装： 1pip install beautifulsoup4 -i http://mirrors.aliyun.com/pypi/simple/ 安装解析器python内置了HTML解析器，若要使用第三方的解析器，如lxml，则需根据操作系统和python的版本选择对应的包进行安装，若要离线安装，windows下可点击该链接下载。 123apt-get install Python-lxmlpip install lxml 或纯python实现的html5lib，其解析方式与浏览器相同。 123apt-get install Python-html5libpip install html5lib 解析器 使用方法 优势 劣势 python标准库 BeautifulSoup(html, ‘html.parser’) python的内置标准库执行速度适中文档容错能力强 Python2.7.3或3.2.2前的版本中文容错能力差 lxml HTML解析器 BeautifulSoup(html, ‘lxml’) 速度快文档容错能力强 需要安装c语言库 lxml XML解析器 BeautifulSoup(html, [‘lxml’, ‘xml’]) 速度快唯一支持XML的解析器 需要安装c语言库 html5lib BeautifulSoup(html, ‘html5lib’) 最好的容错性以浏览器的方式解析文档生成HTML5格式的文档 速度慢不依赖外部扩展 使用技巧假设有一个网页html，创建一个BeautifulSoup对象，并指定解析器。 123456789from bs4 import BeautifulSoupsoup = BeautifulSoup(html, &quot;lxml)soup.prettify() # 缩进打印soup.title # 获取title标签的内容soup.div # 获取第一个div标签的内容soup.find(id=&quot;uq&quot;) # 获取id=&quot;u1&quot;的标签soup.find_all(class_=&quot;item&quot;) # 查找所有class属性有item的标签 注：灵活利用IDE的打断点进行debug可以快速调试，拿到自己需要的元素 对象种类~将复杂HTML文档转换成一个复杂的树形结构，每个节点都是python对象，所有对象可以归为以下四类： TagTag通俗点讲就是HTML中的一个个标签，它的类型是bs4.element.Tag，对于Tag有两个重要的属性，是name和attrs。 123456# 每个tag都有自己的名字，通过.name来获取tag.name# 一个tag可能有多个属性，其操作方式与字典相同，也可以通过点的方式获取tag[&quot;class&quot;]tag.attrs 注：如果标签中某个属性有多值，则解析后返回的类型是list，但是转换的文档是xml时除外。 NavigableString用于获取标签内部的文字，如下： 123soup.title.stringprint(type(bs.title.string)) BeautifulSoup表示的是一个文档的全部内容，大部分时候可以将其看作为一个特殊的Tag，可通过以下方式获取其名称和属性： 1234soup.namesoup.attrsprint(type(soup)) Comment是一个特殊类型的NavigableString对象，其输出的内容不包括注释符号 12345soup.a # &lt;a class=&quot;mnav&quot;&gt;&lt;!--新闻--&gt;&lt;/a&gt;soup.a.string # 新闻print(type(soup.a.string)) # &lt;class &#x27;bs4.element.Comment&#x27;&gt; 遍历文档树子节点.contents和.children contents：获取Tag的所有子节点，返回一个list 123soup.contentssoup.contents[0].name children：获取Tag的所有子节点，返回一个生成器 12for child in soup.body.children: print(child) .descendants .contents和.children属性仅包含tag的直接子节点，.descendants可以对所有tag的子孙节点进行递归循环。 .string 如果tag只有一个子节点，这个tag可以使用.string方法获取，如果有多个子节点，则返回为None .strings和.stripped_strings 若果tag中包含多个字符串，可以使用.strings循环获取 如果字符串包含很多空格或空行，可以使用.stripped_strings去除 父节点.parent 通过.parent获取某个元素的父节点 顶层节点的父节点是BeautifulSoup对象 BeautifulSoup对象的.parent是None .parents 通过.parents可以递归获取元素的所有父节点 兄弟节点.next_sibling和.previous_sibling 使用 .next_sibling 和 .previous_sibling 属性来查询兄弟节点 .next_siblings和.previous_siblings 通过 .next_siblings 和 .previous_siblings 属性可以对当前节点的兄弟节点迭代输出 搜索文档树这里主要列举find_all和find方法以及CSS选择器，其他方法可参考官方文档。 find_allfind_all(name, attrs, recursive, text, **kwargs) name参数 字符串过滤：会查找与字符串完全匹配的内容 12a_list = soup.find_all(&quot;a&quot;)print(a_list) 正则表达式过滤：如果传入的是正则表达式，那么BeautifulSoup4会通过search()来匹配内容 123a_list = soup.find_all(re.compile(&quot;a&quot;))for item in a_list: print(item) 列表：如果传入一个列表，BeautifulSoup4将会与列表中的任一元素匹配到的节点返回 123a_list = soup.find_all([&quot;meta&quot;, &quot;link&quot;])for item in a_list: print(item) 方法：传入一个方法，根据方法来匹配 123456def name_is_exists(tag): return tag.has_attr(&quot;name&quot;)a_list = soup.find_all(name_is_exists)for item in a_list: print(item) kwargs如果一个指定名字的参数不是搜索内置的参数名,搜索时会把该参数当作指定名字tag的属性来搜索 123456789101112# 查询id=head的Tagt_list = soup.find_all(id=&quot;head&quot;)print(t_list)# 查询href属性包含ss1.bdstatic.com的Tagt_list = soup.find_all(href=re.compile(&quot;http://news.baidu.com&quot;))print(t_list)# 查询所有包含class的Tag(注：class要加上_进行区分)t_list = soup.find_all(class_=True)for item in t_list: print(item) attrs不是所有的属性都可以使用上面的方式进行搜索，比如HTML的data-*属性，这时可以使用attrs参数，定义一个字典来搜索包含特殊属性的tag。 123t_list = soup.find_all(attrs=&#123;&quot;data-foo&quot;:&quot;value&quot;&#125;)for item in t_list: print(item) string通过string参数可以搜索文档中的字符串内容，与name参数的可选值一样，string参数接收字符串，正则表达式，列表，True。 12345t_list = soup.find_all(string=&quot;Elsie&quot;) t_list = soup.find_all(string=[&quot;Tillie&quot;, &quot;Elsie&quot;, &quot;Lacie&quot;])t_list = soup.find_all(string=re.compile(&quot;Dormouse&quot;)) limit传入一个limit参数来限制返回的数量。 123t_list = soup.find_all(&quot;a&quot;, limit=2)for item in t_list: print(item) recursive默认会检索当前tag的所有子孙节点，如果只想搜索直接子节点，可以使用该参数。 1soup.html.find_all(recursive=False) findfind( name , attrs , recursive , string , **kwargs )返回符合条件的第一个Tag，即当我们要取一个值的时候就可以用该方法 1soup.find(&quot;head&quot;).find(&quot;title&quot;) CSS选择器 通过tag标签名查找 123soup.select(&quot;title&quot;)soup.select(&quot;a&quot;) 通过tag标签逐层查找： 123soup.select(&quot;body a&quot;)soup.select(&quot;html head title&quot;) 找到某个tag标签下的直接子标签： 123soup.select(&quot;head &gt; title&quot;)soup.select(&quot;p &gt; #link1&quot;) 找到兄弟节点标签： 123soup.select(&quot;#link1 ~ .sister&quot;)soup.select(&quot;#link1 + .sister&quot;) 通过class属性查找： 123soup.select(&quot;.sister&quot;)soup.select(&quot;[class~=sister]&quot;) 通过tag的id查找： 123soup.select(&#x27;#link1&#x27;)soup.select(&quot;a#link2&quot;) 同时用多种css选择器查询： 1soup.select(&quot;#link1,#link2&quot;) 通过是否存在某个属性来查找： 1soup.select(&quot;a[href]&quot;) 通过属性的值来查找： 1234567soup.select(&#x27;a[href=&quot;http://example.com/elsie&quot;]&#x27;)soup.select&#x27;a[href^=&quot;http://example.com&quot;]&#x27;)soup.select(&#x27;a[href$=&quot;tillie&quot;]&#x27;)soup.select(&#x27;a[href*=&quot;.com/el&quot;]&#x27;) 通过语言设置来查找： 1234567891011multilingual_markup = &quot;&quot;&quot; &lt;p lang=&quot;en&quot;&gt;Hello&lt;/p&gt; &lt;p lang=&quot;en-us&quot;&gt;Howdy, y&#x27;all&lt;/p&gt; &lt;p lang=&quot;en-gb&quot;&gt;Pip-pip, old fruit&lt;/p&gt; &lt;p lang=&quot;fr&quot;&gt;Bonjour mes amis&lt;/p&gt;&quot;&quot;&quot;multilingual_soup = BeautifulSoup(multilingual_markup)multilingual_soup.select(&#x27;p[lang|=en]&#x27;)# [&lt;p lang=&quot;en&quot;&gt;Hello&lt;/p&gt;,# &lt;p lang=&quot;en-us&quot;&gt;Howdy, y&#x27;all&lt;/p&gt;,# &lt;p lang=&quot;en-gb&quot;&gt;Pip-pip, old fruit&lt;/p&gt;] 返回查找到的元素的第一个 1soup.select_one(&quot;.sister&quot;) 修改文档树BeautifulSoup的强项是文档树的搜索，但同时也可以方便的修改文档树，这部分可详细参考官方文档。","categories":[{"name":"python","slug":"python","permalink":"https://zcej.github.io/categories/python/"},{"name":"爬虫","slug":"python/爬虫","permalink":"https://zcej.github.io/categories/python/%E7%88%AC%E8%99%AB/"}],"tags":[]},{"title":"项目实战：go语言实现redis(四)","slug":"go/项目实战：go语言实现redis(四)","date":"2022-05-27T12:51:46.000Z","updated":"2022-06-28T15:48:16.023Z","comments":true,"path":"2022/05/27/go/项目实战：go语言实现redis(四)/","link":"","permalink":"https://zcej.github.io/2022/05/27/go/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%EF%BC%9Ago%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0redis(%E5%9B%9B)/","excerpt":"","text":"背景本系列文章记录如何基于go语言实现Redis，从整体设计到具体细节实现，不仅可以有效的锻炼自己的编码能力，又能加深对redis的认识。文章主要从整体设计思路入手，记录关键的设计步骤，详细的实现可以参考github上的相关代码。主体上有下面几个部分： TCP服务器(一)：支持同时监听多个TCP连接，并进行相关处理 Redis协议解析器(一)：实现相关Handler，命令解析及响应处理 内存数据库(二)：实现数据库，注册相关命令，完成支持对数据库的增删改查 Redis持久化(三)：实现redis中的持久化功能aof **Redis集群(四)**：本文将通过一致性哈希的方式实现cluster集群 本章的项目目录结构如下，在前一篇的基础上新增了cluster相关文件： 1234567891011121314151617181920212223242526272829303132333435363738394041424344├─aof│├─cluster│ client_pool.go│ cluster_database.go│ com.go│ del.go│ keys.go│ ping.go│ rename.go│ router.go│├─config│├─database│├─datastruct│ └─dict│├─interface│ ├─database│ ││ ├─dict│ ││ ├─resp│ ││ └─tcp│├─lib│├─resp│ ├─connection│ ││ ├─handler│ ││ ├─parser│ ││ └─reply│├─tcp││ go.mod│ main.go│ redis.conf 实现一致性hash结构体定义在文件lib/comsistenthash/comsistenthash.go中定义结构体NodeMap，包含下面几个属性，并进行初始化，此处设置了一个默认的哈希函数crc32.ChecksumIEEE。 hashFunc：类型为func，需要指定一个hash函数 nodeHashs：类型为int类型的切片，存储节点哈希后的值，且该切片有序的 nodehashMap：类型为map，key为哈希值，value是节点的地址 123456789101112131415161718192021// HashFunc defines function to generate hash codetype HashFunc func(data []byte) uint32// NodeMap stores nodes and you can pick node from NodeMaptype NodeMap struct &#123; hashFunc HashFunc nodeHashs []int // sorted nodehashMap map[int]string&#125;// NewNodeMap creates a new NodeMapfunc NewNodeMap(fn HashFunc) *NodeMap &#123; m := &amp;NodeMap&#123; hashFunc: fn, nodehashMap: make(map[int]string), &#125; if m.hashFunc == nil &#123; m.hashFunc = crc32.ChecksumIEEE &#125; return m&#125; 方法实现需要实现添加节点到哈希环中和从哈希环取出节点的方法： 12345678// IsEmpty returns if there is no node in NodeMapfunc (m *NodeMap) IsEmpty() bool &#123;&#125;// AddNode add the given nodes into consistent hash circlefunc (m *NodeMap) AddNode(keys ...string) &#123;&#125;// PickNode gets the closest item in the hash to the provided key.func (m *NodeMap) PickNode(key string) string &#123;&#125; 集群核心架构连接池为了支持高并发的连接及能够对连接进行复用，此处引进了一个第三方连接池，通过命令go get &quot;github.com/jolestar/go-commons-pool/v2&quot;进行下载。另外，在cluster/client_pool.go中定义结构体connectionFactory实现其接口PooledObjectFactory。 12345678910111213type connectionFactory struct &#123; Peer string&#125;func (f *connectionFactory) MakeObject(ctx context.Context) (*pool.PooledObject, error) &#123;&#125;func (f *connectionFactory) DestroyObject(ctx context.Context, object *pool.PooledObject) error &#123;&#125;func (f *connectionFactory) ValidateObject(ctx context.Context, object *pool.PooledObject) bool &#123;&#125;func (f *connectionFactory) ActivateObject(ctx context.Context, object *pool.PooledObject) error &#123;&#125;func (f *connectionFactory) PassivateObject(ctx context.Context, object *pool.PooledObject) error &#123;&#125; 实现ClusterDatabase需要对原来单体的Database进行进一步封装，新建文件cluster/cluster_database.go。 1234567891011121314151617181920212223242526272829303132333435// ClusterDatabase represents a node of godis cluster// it holds part of data and coordinates other nodes to finish transactionstype ClusterDatabase struct &#123; self string nodes []string peerPicker *consistenthash.NodeMap peerConnection map[string]*pool.ObjectPool db databaseface.Database&#125;// MakeClusterDatabase creates and starts a node of clusterfunc MakeClusterDatabase() *ClusterDatabase &#123; cluster := &amp;ClusterDatabase&#123; self: config.Properties.Self, db: database.NewStandaloneDatabase(), peerPicker: consistenthash.NewNodeMap(nil), peerConnection: make(map[string]*pool.ObjectPool), &#125; nodes := make([]string, 0, len(config.Properties.Peers)+1) for _, peer := range config.Properties.Peers &#123; nodes = append(nodes, peer) &#125; nodes = append(nodes, config.Properties.Self) cluster.peerPicker.AddNode(nodes...) ctx := context.Background() for _, peer := range config.Properties.Peers &#123; cluster.peerConnection[peer] = pool.NewObjectPoolWithDefaultConfig(ctx, &amp;connectionFactory&#123; Peer: peer, &#125;) &#125; cluster.nodes = nodes return cluster&#125; 另外还需实现以下几个方法。 12345678// Close stops current node of clusterfunc (cluster *ClusterDatabase) Close() &#123;&#125;// Exec executes command on clusterfunc (cluster *ClusterDatabase) Exec(c resp.Connection, cmdLine [][]byte) (result resp.Reply) &#123;&#125;// AfterClientClose does some clean after client close connectionfunc (cluster *ClusterDatabase) AfterClientClose(c resp.Connection) &#123;&#125; 操作连接池cluster/com.go 1234567891011func (cluster *ClusterDatabase) getPeerClient(peer string) (*client.Client, error) &#123;&#125;func (cluster *ClusterDatabase) returnPeerClient(peer string, peerClient *client.Client) error &#123;&#125;// relay relays command to peer// select db by c.GetDBIndex()// cannot call Prepare, Commit, execRollback of self nodefunc (cluster *ClusterDatabase) relay(peer string, c resp.Connection, args [][]byte) resp.Reply &#123;&#125;// broadcast broadcasts command to all node in clusterfunc (cluster *ClusterDatabase) broadcast(c resp.Connection, args [][]byte) map[string]resp.Reply &#123;&#125; 指令路由需要根据不同的指令，操作对应的节点，这里需要有一个全局的方式，找到执行指令的相关函数，新建文件cluster/router.go。 123456789101112131415161718192021222324252627func makeRouter() map[string]CmdFunc &#123; routerMap := make(map[string]CmdFunc) routerMap[&quot;ping&quot;] = ping routerMap[&quot;del&quot;] = Del routerMap[&quot;exists&quot;] = defaultFunc routerMap[&quot;type&quot;] = defaultFunc routerMap[&quot;rename&quot;] = Rename routerMap[&quot;renamenx&quot;] = Rename routerMap[&quot;set&quot;] = defaultFunc routerMap[&quot;setnx&quot;] = defaultFunc routerMap[&quot;get&quot;] = defaultFunc routerMap[&quot;getset&quot;] = defaultFunc routerMap[&quot;flushdb&quot;] = FlushDB return routerMap&#125;// relay command to responsible peer, and return its reply to clientfunc defaultFunc(cluster *ClusterDatabase, c resp.Connection, args [][]byte) resp.Reply &#123; key := string(args[1]) peer := cluster.peerPicker.PickNode(key) return cluster.relay(peer, c, args)&#125; 修改特殊的指令操作，分别在下述文件中添加对应的函数。 cluster/ping.go：直接执行即可 cluster/del.go：需要广播至集群的所有节点 cluster/rename.go：需要找到键所在的节点执行，并处理重命名后更换节点的情况 cluster/keys.go：需要广播至集群的所有节点 1234567891011func ping(cluster *ClusterDatabase, c resp.Connection, cmdAndArgs [][]byte) resp.Reply &#123;&#125;// Del atomically removes given writeKeys from cluster, writeKeys can be distributed on any node// if the given writeKeys are distributed on different node, Del will use try-commit-catch to remove themfunc Del(cluster *ClusterDatabase, c resp.Connection, args [][]byte) resp.Reply &#123;&#125;// Rename renames a key, the origin and the destination must within the same nodefunc Rename(cluster *ClusterDatabase, c resp.Connection, args [][]byte) resp.Reply &#123;&#125;// FlushDB removes all data in current databasefunc FlushDB(cluster *ClusterDatabase, c resp.Connection, args [][]byte) resp.Reply &#123;&#125; 启用集群模式要使用集群需要修改resp/handler/handler.go中初始化Database的逻辑。 1234567891011121314// MakeHandler creates a RespHandler instancefunc MakeHandler() *RespHandler &#123; var db databaseface.Database if config.Properties.Self != &quot;&quot; &amp;&amp; len(config.Properties.Peers) &gt; 0 &#123; db = cluster.MakeClusterDatabase() &#125; else &#123; db = database.NewStandaloneDatabase() &#125; return &amp;RespHandler&#123; db: db, &#125;&#125; 总结至此，基于go语言实现redis的项目已基本完成了。项目中有许多值得学习的地方，例如整个架构的设计，整体功能的切分及具体实现。每一步的过程都需要有自己的思考，而不是按部就班，随便记录以下就完了，记录下这个系列的文章，也是为了以后的回顾，温故而知新才能不断的加深影响提高自己。不过项目也依然有很多需要优化的地方，这个可以参考开源的项目godis。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"},{"name":"项目实战","slug":"go/项目实战","permalink":"https://zcej.github.io/categories/go/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"}],"tags":[]},{"title":"项目实战：go语言实现redis(三)","slug":"go/项目实战：go语言实现redis(三)","date":"2022-05-21T02:14:09.000Z","updated":"2022-06-28T15:53:39.796Z","comments":true,"path":"2022/05/21/go/项目实战：go语言实现redis(三)/","link":"","permalink":"https://zcej.github.io/2022/05/21/go/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%EF%BC%9Ago%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0redis(%E4%B8%89)/","excerpt":"","text":"背景本系列文章记录如何基于go语言实现Redis，从整体设计到具体细节实现，不仅可以有效的锻炼自己的编码能力，又能加深对redis的认识。文章主要从整体设计思路入手，记录关键的设计步骤，详细的实现可以参考github上的相关代码。主体上有下面几个部分： TCP服务器(一)：支持同时监听多个TCP连接，并进行相关处理 Redis协议解析器(一)：实现相关Handler，命令解析及响应处理 内存数据库(二)：实现数据库，注册相关命令，完成支持对数据库的增删改查 **Redis持久化(三)**：实现redis中的持久化功能aof Redis集群(四) 本章的项目目录结构如下，主要是在前一篇文章新增了aof相关文件： 1234567891011121314151617181920212223242526272829303132333435├─aof│ aof.go│├─config│├─database│├─datastruct│ └─dict│├─interface│ ├─database│ ││ ├─dict│ ││ ├─resp│ ││ └─tcp│├─lib│├─resp│ ├─connection│ ││ ├─handler│ ││ ├─parser│ ││ └─reply│├─tcp│ │ go.mod│ main.go│ redis.conf 命令记录与恢复需要实现一个AofHandler结构体，由它封装命令保存及数据恢复的相关方法，然后在初始化Database的时候将AofHandler进行注册。在文件aof/aof.go中的实现如下。 12345678910111213141516// CmdLine is alias for [][]byte, represents a command linetype CmdLine = [][]bytetype payload struct &#123; cmdLine CmdLine dbIndex int&#125;// AofHandler receive msgs from channel and write to AOF filetype AofHandler struct &#123; db databaseface.Database aofChan chan *payload aofFile *os.File aofFilename string currentDB int&#125; 另外初始化AofHandler的时候还需要考虑根据已有的Aof文件进行恢复，以及启用一个协程不断的记录执行过的命令。 1234567891011121314151617// NewAOFHandler creates a new aof.AofHandlerfunc NewAOFHandler(db databaseface.Database) (*AofHandler, error) &#123; handler := &amp;AofHandler&#123;&#125; handler.aofFilename = config.Properties.AppendFilename handler.db = db handler.LoadAof() aofFile, err := os.OpenFile(handler.aofFilename, os.O_APPEND|os.O_CREATE|os.O_RDWR, 0600) if err != nil &#123; return nil, err &#125; handler.aofFile = aofFile handler.aofChan = make(chan *payload, aofQueueSize) go func() &#123; handler.handleAof() &#125;() return handler, nil&#125; 另外还需实现下述方法： AddAof：如果配置中开启Aof的话，将执行的命令发送到channel中 handleAof：从channel中读取数据，并写入到文件当中 LoadAof：从文件中读取命令，然后执行123456789// AddAof send command to aof goroutine through channelfunc (handler *AofHandler) AddAof(dbIndex int, cmdLine CmdLine) &#123;&#125;// handleAof listen aof channel and write into filefunc (handler *AofHandler) handleAof() &#123;&#125;// LoadAof read aof filefunc (handler *AofHandler) LoadAof() &#123;&#125; 底层指令集修改首先修改database/db.go中的结构体DB，新增属性addAof，以便指令集中的方法能够调用到addAof，需要修改的地方如下，另外初始化该方法的工作将在后续完成。123456789101112131415// DB stores data and execute user&#x27;s commandstype DB struct &#123; index int data iDict.Dict // key -&gt; DataEntity addAof func(CmdLine)&#125;// makeDB create DB instancefunc makeDB() *DB &#123; db := &amp;DB&#123; data: dict.MakeSyncDict(), addAof: func(line CmdLine) &#123;&#125;, &#125; return db&#125; 在database/string.go中对应的需要记录该指令的方法中添加Addof：123456789101112131415// execSet sets string value and time to live to the given keyfunc execSet(db *DB, args [][]byte) resp.Reply &#123; ... db.addAof(utils.ToCmdLine2(&quot;set&quot;, args...)) ...&#125;// execSetNX sets string if not existsfunc execSetNX(db *DB, args [][]byte) resp.Reply &#123; ... db.addAof(utils.ToCmdLine2(&quot;setnx&quot;, args...)) ...&#125;... 注：同样的database/keys.go中的相关方法也许调用Addof方法。 调用AofHandler初始化database时将AofHandler注册到Database结构体中，然后把方法Addof赋值给DB结构体，这样上述指令集就能调用到该方法了。文件database/databse.go中需要修改的地方如下。 12345678910111213141516171819202122232425// Database is a set of multiple database settype Database struct &#123; dbSet []*DB aofHandler *aof.AofHandler // handle aof persistence&#125;// NewDatabase creates a redis database,func NewDatabase() *Database &#123; ... if config.Properties.AppendOnly &#123; aofHandler, err := aof.NewAOFHandler(mdb) if err != nil &#123; panic(err) &#125; mdb.aofHandler = aofHandler for _, db := range mdb.dbSet &#123; // avoid closure singleDB := db singleDB.addAof = func(line CmdLine) &#123; mdb.aofHandler.AddAof(singleDB.index, line) &#125; &#125; &#125; return mdb&#125; 注：上述for循环遍历数据库的切片时，需要暂时把db赋值给一个临时变量，不然拿到的db都是最后一个值，这是go语言中循环变量的作用域导致的，需要注意。 在go语言的for循环中，循环内部创建的函数变量都是共享同一内存地址，for循环总是使用同一块内存去接收循环中的变量的值。不管循环多少次，变量的内存地址都是相同的。 此处使用的解决方法就是用一个临时变量进行赋值保存记录。 总结redis支持两种持久化的方式，一种是aof，它对数据有修改的相关指令记录到文件中，重新执行这些命令达到数据恢复的效果。另一种是rdb，这种方式是记录了内存快照，在指定的时间间隔内，将内存中的数据写入到磁盘中，就是在指定目录下生产一个dump.rdb文件，通过加载该文件进行恢复数据。本文基于go语言实现了aof持久化功能，通过可插拔的方式集成到之前已基本实现的单体redis当中。接下来将实现redis的集群模式。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"},{"name":"项目实战","slug":"go/项目实战","permalink":"https://zcej.github.io/categories/go/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"}],"tags":[]},{"title":"项目实战：go语言实现redis(二)","slug":"go/项目实战：go语言实现redis(二)","date":"2022-05-12T15:06:31.000Z","updated":"2022-06-28T15:56:20.131Z","comments":true,"path":"2022/05/12/go/项目实战：go语言实现redis(二)/","link":"","permalink":"https://zcej.github.io/2022/05/12/go/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%EF%BC%9Ago%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0redis(%E4%BA%8C)/","excerpt":"","text":"背景本系列文章记录如何基于go语言实现Redis，从整体设计到具体细节实现，不仅可以有效的锻炼自己的编码能力，又能加深对redis的认识。文章主要从整体设计思路入手，记录关键的设计步骤，详细的实现可以参考github上的相关代码。主体上有下面几个部分： TCP服务器(一)：支持同时监听多个TCP连接，并进行相关处理 Redis协议解析器(一)：实现相关Handler，命令解析及响应处理 **内存数据库(二)**：实现数据库，注册相关命令，完成支持对数据库的增删改查 Redis持久化(三) Redis集群(四) 本章的项目目录结构如下： 123456789101112131415161718192021222324252627282930313233343536373839404142├─config│├─database│ command.go│ database.go│ db.go│ echo_database.go│ keys.go│ ping.go│ string.go│├─datastruct│ └─dict│ simple_dict.go│ sync_dict.go│├─interface│ ├─database│ ││ ├─dict│ │ dict.go│ ││ ├─resp│ ││ └─tcp│├─lib│├─resp│ ├─connection│ ││ ├─handler│ ││ ├─parser│ ││ └─reply│├─tcp│ │ go.mod│ main.go│ redis.conf 数据底层存储定义及实现Dict接口在interface/dict/dict.go中定义Dict接口，包含下述方法： 1234567891011121314151617// Consumer is used to traversal dict, if it returns false the traversal will be breaktype Consumer func(key string, val interface&#123;&#125;) bool// Dict is interface of a key-value data structuretype Dict interface &#123; Get(key string) (val interface&#123;&#125;, exists bool) Len() int Put(key string, val interface&#123;&#125;) (result int) PutIfAbsent(key string, val interface&#123;&#125;) (result int) PutIfExists(key string, val interface&#123;&#125;) (result int) Remove(key string) (result int) ForEach(consumer Consumer) Keys() []string RandomKeys(limit int) []string RandomDistinctKeys(limit int) []string Clear()&#125; 然后在datastruct/dict/sync_dict.go中实现一个并发安全的dict。 123456789101112131415161718192021222324252627282930313233343536373839404142// SyncDict wraps a map, it is not thread safetype SyncDict struct &#123; m sync.Map&#125;// MakeSyncDict makes a new mapfunc MakeSyncDict() *SyncDict &#123; return &amp;SyncDict&#123;&#125;&#125;// Get returns the binding value and whether the key is existfunc (dict *SyncDict) Get(key string) (val interface&#123;&#125;, exists bool) &#123;&#125;// Len returns the number of dictfunc (dict *SyncDict) Len() int &#123;&#125;// Put puts key value into dict and returns the number of new inserted key-valuefunc (dict *SyncDict) Put(key string, val interface&#123;&#125;) (result int) &#123;&#125;// PutIfAbsent puts value if the key is not exists and returns the number of updated key-valuefunc (dict *SyncDict) PutIfAbsent(key string, val interface&#123;&#125;) (result int) &#123;&#125;// PutIfExists puts value if the key is exist and returns the number of inserted key-valuefunc (dict *SyncDict) PutIfExists(key string, val interface&#123;&#125;) (result int) &#123;&#125;// Remove removes the key and return the number of deleted key-valuefunc (dict *SyncDict) Remove(key string) (result int) &#123;&#125;// Keys returns all keys in dictfunc (dict *SyncDict) Keys() []string &#123;&#125;// ForEach traversal the dictfunc (dict *SyncDict) ForEach(consumer iDict.Consumer) &#123;&#125;// RandomKeys randomly returns keys of the given number, may contain duplicated keyfunc (dict *SyncDict) RandomKeys(limit int) []string &#123;&#125;// RandomDistinctKeys randomly returns keys of the given number, won&#x27;t contain duplicated keyfunc (dict *SyncDict) RandomDistinctKeys(limit int) []string &#123;&#125;// Clear removes all keys in dictfunc (dict *SyncDict) Clear() &#123;&#125; 注：非并发安全的实现可参考datastruct/dict/simple_dict.go 定义DB结构体在database/db.go定义DB结构体，它是对底层Dict相关操作的进一步封装，根据接收到的实际命令找到对应的方法并执行，其核心是Exec方法。 12345678910111213141516171819202122232425262728293031323334// DB stores data and execute user&#x27;s commandstype DB struct &#123; index int data dict.Dict // key -&gt; DataEntity&#125;// makeDB create DB instancefunc makeDB() *DB &#123; db := &amp;DB&#123;data: dict.MakeSyncDict()&#125; return db&#125;// Exec executes command within one databasefunc (db *DB) Exec(c resp.Connection, cmdLine [][]byte) resp.Reply &#123;&#125;// GetEntity returns DataEntity bind to given keyfunc (db *DB) GetEntity(key string) (*database.DataEntity, bool) &#123;&#125;// PutEntity a DataEntity into DBfunc (db *DB) PutEntity(key string, entity *database.DataEntity) int &#123;&#125;// PutIfExists edit an existing DataEntityfunc (db *DB) PutIfExists(key string, entity *database.DataEntity) int &#123;&#125;// Remove the given key from dbfunc (db *DB) Remove(key string) &#123;&#125;// Removes the given keys from dbfunc (db *DB) Removes(keys ...string) (deleted int) &#123;&#125;// Flush clean databasefunc (db *DB) Flush() &#123;&#125;func validateArity(arity int, cmdArgs [][]byte) bool &#123;&#125; 命令注册及实现命令的注册database/command.go主要包含以下三个部分： cmdTable：类型为字典，功能为存储命令及对应命令的结构体 command：类型为结构体，包含命令对应的实际方法以及参数数量 RegisterCommand：类型为一个函数，用于实现命令注册全局表中1234567891011121314151617var cmdTable = make(map[string]*command)type command struct &#123; executor ExecFunc arity int // allow number of args, arity &lt; 0 means len(args) &gt;= -arity&#125;// RegisterCommand registers a new command// arity means allowed number of cmdArgs, arity &lt; 0 means len(args) &gt;= -arity.// for example: the arity of `get` is 2, `mget` is -2func RegisterCommand(name string, executor ExecFunc, arity int) &#123; name = strings.ToLower(name) cmdTable[name] = &amp;command&#123; executor: executor, arity: arity, &#125;&#125; 命令的实现ping的实现与注册在文件database/ping.go中的init()方法下将命令及其对应的处理函数注册到全局表中：123456func init() &#123; RegisterCommand(&quot;ping&quot;, Ping, -1)&#125;// Ping the serverfunc Ping(db *DB, args [][]byte) resp.Reply &#123;&#125; keys指令集的实现与注册在文件database/keys.go中的init()方法下将命令及其对应的处理函数注册到全局表中：123456789func init() &#123; RegisterCommand(&quot;Del&quot;, execDel, -2) RegisterCommand(&quot;Exists&quot;, execExists, -2) RegisterCommand(&quot;Keys&quot;, execKeys, 2) RegisterCommand(&quot;FlushDB&quot;, execFlushDB, -1) RegisterCommand(&quot;Type&quot;, execType, 2) RegisterCommand(&quot;Rename&quot;, execRename, 3) RegisterCommand(&quot;RenameNx&quot;, execRenameNx, 3)&#125; 并实现相关函数：1234567891011121314151617181920// execDel removes a key from dbfunc execDel(db *DB, args [][]byte) resp.Reply &#123;&#125;// execExists checks if a is existed in dbfunc execExists(db *DB, args [][]byte) resp.Reply &#123;&#125;// execFlushDB removes all data in current dbfunc execFlushDB(db *DB, args [][]byte) resp.Reply &#123;&#125;// execType returns the type of entity, including: string, list, hash, set and zsetfunc execType(db *DB, args [][]byte) resp.Reply &#123;&#125;// execRename a keyfunc execRename(db *DB, args [][]byte) resp.Reply &#123;&#125;// execRenameNx a key, only if the new key does not existfunc execRenameNx(db *DB, args [][]byte) resp.Reply &#123;&#125;// execKeys returns all keys matching the given patternfunc execKeys(db *DB, args [][]byte) resp.Reply &#123;&#125; string指令集的实现与注册在文件database/string.go中的init()方法下将命令及其对应的处理函数注册到全局表中：1234567func init() &#123; RegisterCommand(&quot;Get&quot;, execGet, 2) RegisterCommand(&quot;Set&quot;, execSet, -3) RegisterCommand(&quot;SetNx&quot;, execSetNX, 3) RegisterCommand(&quot;GetSet&quot;, execGetSet, 3) RegisterCommand(&quot;StrLen&quot;, execStrLen, 2)&#125; 并实现相关函数：12345678910111213141516func (db *DB) getAsString(key string) ([]byte, reply.ErrorReply) &#123;&#125;// execGet returns string value bound to the given keyfunc execGet(db *DB, args [][]byte) resp.Reply &#123;&#125;// execSet sets string value and time to live to the given keyfunc execSet(db *DB, args [][]byte) resp.Reply &#123;&#125;// execSetNX sets string if not existsfunc execSetNX(db *DB, args [][]byte) resp.Reply &#123;&#125;// execGetSet sets value of a string-type key and returns its old valuefunc execGetSet(db *DB, args [][]byte) resp.Reply &#123;&#125;// execStrLen returns len of string value bound to the given keyfunc execStrLen(db *DB, args [][]byte) resp.Reply &#123;&#125; 实现数据库核心在database/database.go中定义结构体Database，需实现第一篇文章中定义的Database接口，并进行初始化，创建16个数据库表，另外还需要注意执行命令时所在db的选择，这里封装了一个选择db的函数execSelect。123456789101112131415161718192021222324252627282930// Database is a set of multiple database settype Database struct &#123; dbSet []*DB&#125;// NewDatabase creates a redis database,func NewDatabase() *Database &#123; mdb := &amp;Database&#123;&#125; if config.Properties.Databases == 0 &#123; config.Properties.Databases = 16 &#125; mdb.dbSet = make([]*DB, config.Properties.Databases) for i := range mdb.dbSet &#123; singleDB := makeDB() singleDB.index = i mdb.dbSet[i] = singleDB &#125; return mdb&#125;// Exec executes command// parameter `cmdLine` contains command and its arguments, for example: &quot;set key value&quot;func (mdb *Database) Exec(c resp.Connection, cmdLine [][]byte) (result resp.Reply) &#123;&#125;// Close graceful shutdown databasefunc (mdb *Database) Close() &#123;&#125;func (mdb *Database) AfterClientClose(c resp.Connection) &#123;&#125;func execSelect(c resp.Connection, mdb *Database, args [][]byte) resp.Reply &#123;&#125; 然后将resp/handler/handler.go中的初始化数据库改为上述实现的数据库即可。总结到目前为止一个单体的redis应用已基本完成，可以暂不关注每个方法的具体实现，但是一定要理解整个调用逻辑，做到融会贯通。首先处理TCP连接，选择对应的handler，由handler初始化database，同时对conn封装，选择对应的数据库执行命令，在项目一开始运行的时候会将代码中已实现的命令注册到全局表中。接下来将实现redis的持久化与集群的相关功能。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"},{"name":"项目实战","slug":"go/项目实战","permalink":"https://zcej.github.io/categories/go/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"}],"tags":[]},{"title":"项目实战：go语言实现redis(一)","slug":"go/项目实战：go语言实现redis(一)","date":"2022-05-08T14:41:18.000Z","updated":"2022-06-28T16:06:11.479Z","comments":true,"path":"2022/05/08/go/项目实战：go语言实现redis(一)/","link":"","permalink":"https://zcej.github.io/2022/05/08/go/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%EF%BC%9Ago%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0redis(%E4%B8%80)/","excerpt":"","text":"背景本系列文章记录如何基于go语言实现Redis，从整体设计到具体细节实现，不仅可以有效的锻炼自己的编码能力，又能加深对redis的认识。文章主要从整体设计思路入手，记录关键的设计步骤，详细的实现可以参考github上的相关代码。主体上有下面几个部分： **TCP服务器(一)**：支持同时监听多个TCP连接，并进行相关处理 **Redis协议解析器(一)**：实现相关Handler，命令解析及响应处理 内存数据库(二) Redis持久化(三) Redis集群(四) 实现TCP服务器项目初始化，主要包括相关配置，日志处理，以及定义相关接口或结构体。当前目录结构如下： 12345678910111213141516├─config│ config.go│├─interface│ └─tcp│ handler.go│├─lib│├─tcp│ echo.go│ server.go│ | go.mod| main.go| redis.conf 项目初始化配置文件解析在config/config.go文件中定义Redis相关服务端属性如下： 123456789101112131415161718package config// ServerProperties defines global config propertiestype ServerProperties struct &#123; Bind string `cfg:&quot;bind&quot;` Port int `cfg:&quot;port&quot;` AppendOnly bool `cfg:&quot;appendOnly&quot;` AppendFilename string `cfg:&quot;appendFilename&quot;` MaxClients int `cfg:&quot;maxclients&quot;` RequirePass string `cfg:&quot;requirepass&quot;` Databases int `cfg:&quot;databases&quot;` Peers []string `cfg:&quot;peers&quot;` Self string `cfg:&quot;self&quot;`&#125;// Properties holds global config propertiesvar Properties *ServerProperties 另外，还需要实现配置文件解析的相关方法： 1234567891011121314151617// SetupConfig read config file and store properties into Propertiesfunc SetupConfig(configFilename string) &#123; file, err := os.Open(configFilename) if err != nil &#123; panic(err) &#125; defer file.Close() Properties = parse(file)&#125;func parse(src io.Reader) *ServerProperties &#123; config := &amp;ServerProperties&#123;&#125; ... ... ... return config&#125; 为了防止没有配置文件的情况下也能正常初始化，可以添加如下代码： 12345678func init() &#123; // default config Properties = &amp;ServerProperties&#123; Bind: &quot;127.0.0.1&quot;, Port: 6379, AppendOnly: false, &#125;&#125; 接口定义在interface/tcp/handler.go中需要定义相关接口，以规范化处理tcp的连接： 12345// Handler represents application server over tcptype Handler interface &#123; Handle(ctx context.Context, conn net.Conn) Close() error&#125; TCP服务实现并发处理tcp连接在tcp/server.go中实现以下两个函数，用于处理tcp连接，此处主要依赖标准库net： 12345678910111213141516171819202122232425262728293031323334// Config stores tcp handler propertiestype Config struct &#123; Address string `yaml:&quot;address&quot;` MaxConnect uint32 `yaml:&quot;max-connect&quot;` Timeout time.Duration `yaml:&quot;timeout&quot;`&#125;// ListenAndServeWithSignal binds port and handle requests, blocking until receive stop signalfunc ListenAndServeWithSignal(cfg *Config, handler tcp.Handler) error &#123; closeChan := make(chan struct&#123;&#125;) ... listener, err := net.Listen(&quot;tcp&quot;, cfg.Address) ... ListenAndServe(listener, handler, closeChan) return nil&#125;// ListenAndServe binds port and handle requests, blocking until closefunc ListenAndServe(listener net.Listener, handler tcp.Handler, closeChan &lt;-chan struct&#123;&#125;) &#123; go func()&#123; &lt;-closeChan listener.Close() handler.Close() &#125; ... for &#123; conn, err := listener.Accept() ... go func() &#123; handler.Handle(ctx, conn) &#125;() &#125; ....&#125; main函数入口实现此时main.go中需要调用的函数已基本实现，后续修改只需传入对应的Handler即可： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package mainimport ( &quot;fmt&quot; &quot;go-redis/config&quot; &quot;go-redis/lib/logger&quot; &quot;go-redis/tcp&quot; EchoHandler &quot;go-redis/tcp&quot; &quot;os&quot;)const configFile string = &quot;redis.conf&quot;var defaultProperties = &amp;config.ServerProperties&#123; Bind: &quot;0.0.0.0&quot;, Port: 6379,&#125;func fileExists(filename string) bool &#123; info, err := os.Stat(filename) return err == nil &amp;&amp; !info.IsDir()&#125;func main() &#123; logger.Setup(&amp;logger.Settings&#123; Path: &quot;logs&quot;, Name: &quot;godis&quot;, Ext: &quot;log&quot;, TimeFormat: &quot;2006-01-02&quot;, &#125;) if fileExists(configFile) &#123; config.SetupConfig(configFile) &#125; else &#123; config.Properties = defaultProperties &#125; err := tcp.ListenAndServeWithSignal( &amp;tcp.Config&#123; Address: fmt.Sprintf(&quot;%s:%d&quot;, config.Properties.Bind, config.Properties.Port), &#125;, EchoHandler.MakeHandler()) if err != nil &#123; logger.Error(err) &#125;&#125; echoHandler示例新建文件tcp/echo.go，定义结构体EchoHandler与EchoClient： 1234567891011121314151617181920212223// EchoHandler echos received line to client, using for testtype EchoHandler struct &#123; activeConn sync.Map closing atomic.Boolean&#125;// MakeHandler creates EchoHandlerfunc MakeHandler() *EchoHandler &#123; return &amp;EchoHandler&#123;&#125;&#125;// EchoClient is client for EchoHandler, using for testtype EchoClient struct &#123; Conn net.Conn Waiting wait.Wait&#125;// Close close connectionfunc (c *EchoClient) Close() error &#123; c.Waiting.WaitWithTimeout(10 * time.Second) c.Conn.Close() return nil&#125; EchoHandler实现了接口Handler，主要是将接收到的数据原样返回，详情如下： 123456789101112131415161718192021222324// Handle echos received line to clientfunc (h *EchoHandler) Handle(ctx context.Context, conn net.Conn) &#123; ... reader := bufio.NewReader(conn) for &#123; // may occurs: client EOF, client timeout, server early close msg, err := reader.ReadString(&#x27;\\n&#x27;) .... b := []byte(msg) _, _ = conn.Write(b) .... &#125;&#125;// Close stops echo handlerfunc (h *EchoHandler) Close() error &#123; h.closing.Set(true) h.activeConn.Range(func(key interface&#123;&#125;, val interface&#123;&#125;) bool &#123; client := key.(*EchoClient) _ = client.Close() return true &#125;) return nil&#125; 实现Redis协议解析器本章节主要新增了redis相关命令的解析，具体执行，以及响应处理等，相关目录结构如下： 1234567891011121314151617181920212223242526272829303132333435363738394041├─config│ config.go│├─database│ echo_database.go│├─interface│ ├─database│ │ database.go│ ││ ├─resp│ │ conn.go│ │ reply.go│ ││ └─tcp│ handler.go│├─lib│├─resp│ ├─connection│ │ conn.go│ ││ ├─handler│ │ handler.go│ ││ ├─parser│ │ parser.go│ ││ └─reply│ consts.go│ errors.go│ reply.go│└─tcp│ echo.go│ server.go│ | go.mod| main.go| redis.conf redis网络协议认识 正常回复：以”+”开头，以”\\r\\n”结尾的字符串形式 错误回复：以”-“开头，以”\\r\\n”结尾的字符串形式 整数：以”:”开头，以”\\r\\n”结尾的字符串形式 多行字符串：以”$”开头，后面跟实际发送的字节数，以”\\r\\n”结尾 数组：以”*”开头，后面跟成员个数 接口定义及实现Connection在interface/resp/conn.go中定义连接，主要包含三个方法，写数据、获取当前所在数据库的索引，以及选择数据库： 123456// Connection represents a connection with redis clienttype Connection interface &#123; Write([]byte) error GetDBIndex() int // used for multi database SelectDB(int)&#125; 在resp/connection/conn.go中创建Connection结构体并实现Connection接口 1234567891011121314151617181920212223242526// Connection represents a connection with a redis-clitype Connection struct &#123; conn net.Conn waitingReply wait.Wait // waiting until reply finished mu sync.Mutex // lock while handler sending response selectedDB int // selected db&#125;func NewConn(conn net.Conn) *Connection &#123; return &amp;Connection&#123;conn: conn,&#125;&#125;// RemoteAddr returns the remote network addressfunc (c *Connection) RemoteAddr() net.Addr &#123;&#125;// Close disconnect with the clientfunc (c *Connection) Close() error &#123;&#125;// Write sends response to client over tcp connectionfunc (c *Connection) Write(b []byte) error &#123;&#125;// GetDBIndex returns selected dbfunc (c *Connection) GetDBIndex() int &#123;&#125;// SelectDB selects a databasefunc (c *Connection) SelectDB(dbNum int) &#123;&#125; Reply在interface/resp/reply.go中定义接口Reply，用于处理基于resp协议的响应，主要包含ToBytes方法： 12345678910// Reply is the interface of redis serialization protocol messagetype Reply interface &#123; ToBytes() []byte&#125;// ErrorReply is an error and redis.Replytype ErrorReply interface &#123; Error() string ToBytes() []byte&#125; 在resp/reply下创建以下三个文件，分别用于实现具体的相关处理： consts.go：定义一些固定不变的响应 reply.go：定义正常执行命令时的响应 errors.go：定义发生错误时的响应 consts.go中的文件内容如下，其中的结构体都需要实现Reply接口： 1234567891011121314// PongReply is +PONGtype PongReply struct&#123;&#125;// OkReply is +OKtype OkReply struct&#123;&#125;// NullBulkReply is empty stringtype NullBulkReply struct&#123;&#125;// EmptyMultiBulkReply is a empty listtype EmptyMultiBulkReply struct&#123;&#125;// NoReply respond nothing, for commands like subscribetype NoReply struct&#123;&#125; reply.go中的文件内容如下，其中的结构体都需要实现Reply接口： 123456789101112131415161718192021222324// BulkReply stores a binary-safe stringtype BulkReply struct &#123; Arg []byte&#125;// MultiBulkReply stores a list of stringtype MultiBulkReply struct &#123; Args [][]byte&#125;// StatusReply stores a simple status stringtype StatusReply struct &#123; Status string&#125;// IntReply stores an int64 numbertype IntReply struct &#123; Code int64&#125;// StandardErrReply represents handler errortype StandardErrReply struct &#123; Status string&#125; errors.go中的文件内容如下，其中的结构体都需要实现Reply接口： 123456789101112131415161718// UnknownErrReply represents UnknownErrtype UnknownErrReply struct&#123;&#125;// ArgNumErrReply represents wrong number of arguments for commandtype ArgNumErrReply struct &#123; Cmd string&#125;// SyntaxErrReply represents meeting unexpected argumentstype SyntaxErrReply struct&#123;&#125;// WrongTypeErrReply represents operation against a key holding the wrong kind of valuetype WrongTypeErrReply struct&#123;&#125;// ProtocolErrReply represents meeting unexpected byte during parse requeststype ProtocolErrReply struct &#123; Msg string&#125; Database在interface/database/database.go定义接口Database，规范不同的数据库实现： 123456// Database is the interface for redis style storage enginetype Database interface &#123; Exec(client resp.Connection, args [][]byte) resp.Reply AfterClientClose(c resp.Connection) Close()&#125; 命令解析实现在文件resp/parser/parser.go实现下面的功能： 响应流式处理 Payload：包含正常响应或错误 readState：解析器状态 ParseStream：返回数据类型为Payload的channel 123456789101112131415161718192021222324// Payload stores redis.Reply or errortype Payload struct &#123; Data resp.Reply Err error&#125;type readState struct &#123; readingMultiLine bool expectedArgsCount int msgType byte args [][]byte bulkLen int64&#125;func (s *readState) finished() bool &#123; return s.expectedArgsCount &gt; 0 &amp;&amp; len(s.args) == s.expectedArgsCount&#125;// ParseStream reads data from io.Reader and send payloads through channelfunc ParseStream(reader io.Reader) &lt;-chan *Payload &#123; ch := make(chan *Payload) go parse0(reader, ch) return ch&#125; 命令读取及具体解析 readLine：精确读取一行数据 parseMultiBulkHeader：处理多行数据(“*”号开始)，改变解析器状态 parseBulkHeader：处理单个数据(“$”号开始)，改变解析器状态 parseSingleLineReply：处理客户端发送+ok -err :5的情况 1234567func readLine(bufReader *bufio.Reader, state *readState) ([]byte, bool, error) &#123;&#125;func parseMultiBulkHeader(msg []byte, state *readState) error &#123;&#125;func parseBulkHeader(msg []byte, state *readState) error &#123;&#125;func parseSingleLineReply(msg []byte) (resp.Reply, error) &#123;&#125; 解析实现 readBody：去除其他字符，解析命令内容 parse0：根据读取到的数据调用不同的解析方法，并将结果返回Payload的channel 1234// read the non-first lines of multi bulk reply or bulk replyfunc readBody(msg []byte, state *readState) error &#123;&#125;func parse0(reader io.Reader, ch chan&lt;- *Payload) &#123;&#125; 实现RespHandler在TCP层面处理用户发过来的数据，并调用resp协议解析器进行解析，然后根据对应的db去实际执行相关的命令，主要在Handle方法中实现。 1234567891011121314151617181920212223// RespHandler implements tcp.Handler and serves as a redis handlertype RespHandler struct &#123; activeConn sync.Map // *client -&gt; placeholder db databaseface.Database closing atomic.Boolean // refusing new client and new request&#125;// MakeHandler creates a RespHandler instancefunc MakeHandler() *RespHandler &#123; var db databaseface.Database db = database.NewEchoDatabase() return &amp;RespHandler&#123; db: db, &#125;&#125;func (h *RespHandler) closeClient(client *connection.Connection) &#123;&#125;// Handle receives and executes redis commandsfunc (h *RespHandler) Handle(ctx context.Context, conn net.Conn) &#123;&#125;// Close stops handlerfunc (h *RespHandler) Close() error &#123;&#125; EchoDatabase示例在database/echo_database.go中简单实现一个数据库，其实现了Database接口。这里只是方便做简单测试，下一篇文章将记录如何实现redis的内存数据库： 123456789101112131415161718type EchoDatabase struct &#123;&#125;func NewEchoDatabase() *EchoDatabase &#123; return &amp;EchoDatabase&#123;&#125;&#125;func (e EchoDatabase) Exec(client resp.Connection, args [][]byte) resp.Reply &#123; return reply.MakeMultiBulkReply(args)&#125;func (e EchoDatabase) AfterClientClose(c resp.Connection) &#123; logger.Info(&quot;EchoDatabase AfterClientClose&quot;)&#125;func (e EchoDatabase) Close() &#123; logger.Info(&quot;EchoDatabase Close&quot;)&#125;","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"},{"name":"项目实战","slug":"go/项目实战","permalink":"https://zcej.github.io/categories/go/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"}],"tags":[]},{"title":"go语言实现大根堆、小根堆及堆排序","slug":"go/go实现大根堆、小根堆及堆排序","date":"2022-03-18T13:07:38.000Z","updated":"2022-06-28T16:24:38.505Z","comments":true,"path":"2022/03/18/go/go实现大根堆、小根堆及堆排序/","link":"","permalink":"https://zcej.github.io/2022/03/18/go/go%E5%AE%9E%E7%8E%B0%E5%A4%A7%E6%A0%B9%E5%A0%86%E3%80%81%E5%B0%8F%E6%A0%B9%E5%A0%86%E5%8F%8A%E5%A0%86%E6%8E%92%E5%BA%8F/","excerpt":"","text":"二叉堆是一种特殊的堆，它满足两个性质：结构性和堆序性 结构性：二叉堆是一棵完全二叉树，完全二叉树可以用一个数组表示，不需要指针，所以效率更高。当用数组表示时，数组中任一位置i上的元素，其左子树在位置2i上，右子树在位置2i+1上，其父节点在位置i&#x2F;2上。 堆序性质：堆的最小值或最大值在根节点上，所以可以快速找到最大值或最小值。 最大堆和最小堆是二叉堆的两种形式： 最大堆：根节点的键值是所有堆节点键值中最大者的堆。 最小堆：根节点的键值是所有堆节点键值中最小者的堆。 最小堆实现插入和删除当向最小堆插入元素时： 将元素插入末尾 判断该元素是否需要上移(与父节点比较，如果比父节点小则上移) 重复上述步骤，直到满足最小堆特性 当向最小堆删除元素时： 删除堆顶元素 判断目前的堆顶元素是否需要下调(与子节点比较，和其中较小的节点交换位置) 重复上述步骤，直到满足最小堆特性 具体实现下面以求数据流中第k大的元素为问题实现一个最小堆，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253type minHeap struct &#123; k int // 容量 heap []int // heap数组&#125;func createMinHeap(k int, nums []int) *minHeap &#123; heap := &amp;minHeap&#123;k: k, heap: []int&#123;&#125;&#125; for _, n := range nums &#123; heap.add(n) &#125; return heap&#125;func (m *minHeap) add(num int) &#123; if len(m.heap) &lt; m.k &#123; m.heap = append(m.heap, num) m.up(len(m.heap) - 1) &#125; else if num &gt; m.heap[0] &#123; m.heap[0] = num m.down(0) &#125;&#125;// 元素上浮func (m *minHeap) up(i int) &#123; for i &gt; 0 &#123; parent := (i - 1) &gt;&gt; 1 // 找到父节点在heap数组中的位置 // 如果比父节点元素小，则交换位置并更新索引 if m.heap[parent] &gt; m.heap[i] &#123; m.heap[parent], m.heap[i] = m.heap[i], m.heap[parent] i = parent &#125; else &#123; break // 当前节点比父节点小，满足最小堆性质，退出 &#125; &#125;&#125;// 元素下沉(包括切片中第一个元素，索引为0)func (m *minHeap) down(i int) &#123; for 2*i+1 &lt; len(m.heap) &#123; // 左子节点越界，则退出循环 child := 2*i + 1 // 左子节点在heap切片中的位置 if child+1 &lt; len(m.heap) &amp;&amp; m.heap[child+1] &lt; m.heap[child] &#123; child++ // 如果右子节点没有越界，且值比左子节点更小，则选择下沉右子节点 &#125; // 将当前元素与子节点最大元素对比，然后交换并更新索引 if m.heap[i] &gt; m.heap[child] &#123; m.heap[child], m.heap[i] = m.heap[i], m.heap[child] i = child &#125; else &#123; break // 子节点都比自己大，满足最小堆属性，退出 &#125; &#125;&#125; 应用如果要求输出数据流中的第k大元素，正好可以使用最小堆实现： 123456789101112type KthLargest struct &#123; heap *minHeap&#125;func Constructor(k int, nums []int) KthLargest &#123; return KthLargest&#123;heap: createMinHeap(k, nums)&#125;&#125;func (k *KthLargest) Add(val int) int &#123; k.heap.add(val) return k.heap.heap[0]&#125; 使用heap包实现heap源码中定义了一个Interface接口，该接口一共包含5个方法，定义一个实现了该接口的结构体就实现了一个二叉堆。container/heap/heap.go 12345678// Note that Push and Pop in this interface are for package heap&#x27;s// implementation to call. To add and remove things from the heap,// use heap.Push and heap.Pop.type Interface interface &#123; sort.Interface Push(x interface&#123;&#125;) // add x as element Len() Pop() interface&#123;&#125; // remove and return element Len() - 1.&#125; sort/sort.go 1234567891011121314151617181920212223242526// An implementation of Interface can be sorted by the routines in this package.// The methods refer to elements of the underlying collection by integer index.type Interface interface &#123; // Len is the number of elements in the collection. Len() int // Less reports whether the element with index i // must sort before the element with index j. // // If both Less(i, j) and Less(j, i) are false, // then the elements at index i and j are considered equal. // Sort may place equal elements in any order in the final result, // while Stable preserves the original input order of equal elements. // // Less must describe a transitive ordering: // - if both Less(i, j) and Less(j, k) are true, then Less(i, k) must be true as well. // - if both Less(i, j) and Less(j, k) are false, then Less(i, k) must be false as well. // // Note that floating-point comparison (the &lt; operator on float32 or float64 values) // is not a transitive ordering when not-a-number (NaN) values are involved. // See Float64Slice.Less for a correct implementation for floating-point values. Less(i, j int) bool // Swap swaps the elements with indexes i and j. Swap(i, j int)&#125; 定义一个最大堆，实现上述接口如下： 12345678910111213141516171819202122232425262728293031323334type MaxHeap []intfunc (h MaxHeap) Len() int &#123; return len(h)&#125;func (h MaxHeap) Less(i, j int) bool &#123; return h[i] &gt; h[j] // 因为实现最大堆，所以使用大于号&#125;func (h *MaxHeap) Swap(i, j int) &#123; (*h)[i], (*h)[j] = (*h)[j], (*h)[i]&#125;func (h *MaxHeap) Push(x interface&#123;&#125;) &#123; *h = append(*h, x.(int))&#125;// Pop 弹出堆顶元素func (h *MaxHeap) Pop() interface&#123;&#125; &#123; res := (*h)[len(*h)-1] *h = (*h)[:len(*h)-1] return res&#125;func main() &#123; h := &amp;MaxHeap&#123;3, 1, 2, 5&#125; heap.Init(h) heap.Push(h, 8) for h.Len() &gt; 0 &#123; fmt.Printf(&quot;%d &quot;, heap.Pop(h)) &#125;&#125; 堆排序堆排序是一种选择排序，它的最坏、最好、平均时间复杂度均为O(nlogn)，它也是不稳定排序。 排序的过程主要由构建初始堆，交换堆顶元素和末尾元素并重建堆两部分组成 升序使用最大堆，每次和末尾元素交换，然后重新构建最大堆，整体数组减一；反之降序使用最小堆 堆构建从第一个非叶子节点开始，也就是len/2 - 1所在位置的元素 12345678910111213141516171819202122232425262728293031323334353637func maxHeap(nums []int, length int) []int &#123; if length &lt;= 1 &#123; return nums &#125; parent := length/2 + 1 // 第一个非叶子节点 for i := parent; i &gt;= 0; i-- &#123; // 比较三个节点的大小并将较大的节点上浮 max := i leftChild := 2*i + 1 rightChild := 2*i + 2 if leftChild &lt;= length-1 &amp;&amp; nums[leftChild] &gt; nums[max] &#123; max = leftChild &#125; if rightChild &lt;= length-1 &amp;&amp; nums[rightChild] &gt; nums[max] &#123; max = rightChild &#125; if max != i &#123; nums[i], nums[max] = nums[max], nums[i] &#125; &#125; return nums&#125;func sortHeap(nums []int) []int &#123; length := len(nums) for i := 0; i &lt; length; i++ &#123; lastLength := length - i // 剔除已经排完序的元素 nums = maxHeap(nums, lastLength) // 重新构建最大堆 nums[0], nums[lastLength-1] = nums[lastLength-1], nums[0] &#125; return nums&#125;func main() &#123; nums := []int&#123;8, 5, 11, 2, 7, 9&#125; fmt.Println(sortHeap(nums))&#125;","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"channel的底层实现","slug":"go/channel的底层实现","date":"2022-03-05T11:43:21.000Z","updated":"2022-05-23T09:46:25.833Z","comments":true,"path":"2022/03/05/go/channel的底层实现/","link":"","permalink":"https://zcej.github.io/2022/03/05/go/channel%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"本文基于go版本1.16 数据结构其底层数据结构为runtime包下的一个hchan的结构体，如下： 12345678910111213141516171819202122232425type hchan struct &#123; qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G&#x27;s status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex&#125;type waitq struct &#123; first *sudog last *sudog&#125; buf指向底层循环数组，只有缓冲型的channel才有 sendx, recvx均指向底层循环数组，表示当前可以发送和接收的元素位置索引值（相对于底层数组） sendq, recvq分别表示向channel读取或发送数据而阻塞的goroutine队列 waitq是sudog的一个双向链表（sudog实际上是对goroutine的封装） lock用来保证每个读channel或写channel的操作都是原子的 创建使用make能创建一个能收能发的channel： 12345// 无缓冲通道ch1 := make(chan int)// 有缓冲通道ch2 := make(chan int, 10) 通过汇编分析（go complie），找到最终创建chan的函数是位于runtime&#x2F;chan.go下的函数makechan： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455const ( maxAlign = 8 hchanSize = unsafe.Sizeof(hchan&#123;&#125;) + uintptr(-int(unsafe.Sizeof(hchan&#123;&#125;))&amp;(maxAlign-1)) debugChan = false)func makechan(t *chantype, size int) *hchan &#123; elem := t.elem // compiler checks this but be safe. if elem.size &gt;= 1&lt;&lt;16 &#123; throw(&quot;makechan: invalid channel element type&quot;) &#125; if hchanSize%maxAlign != 0 || elem.align &gt; maxAlign &#123; throw(&quot;makechan: bad alignment&quot;) &#125; mem, overflow := math.MulUintptr(elem.size, uintptr(size)) if overflow || mem &gt; maxAlloc-hchanSize || size &lt; 0 &#123; panic(plainError(&quot;makechan: size out of range&quot;)) &#125; // Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers. // buf points into the same allocation, elemtype is persistent. // SudoG&#x27;s are referenced from their owning thread so they can&#x27;t be collected. // TODO(dvyukov,rlh): Rethink when collector can move allocated objects. var c *hchan switch &#123; case mem == 0: // Queue or element size is zero. c = (*hchan)(mallocgc(hchanSize, nil, true)) // Race detector uses this location for synchronization. c.buf = c.raceaddr() case elem.ptrdata == 0: // Elements do not contain pointers. // Allocate hchan and buf in one call. c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: // Elements contain pointers. c = new(hchan) c.buf = mallocgc(mem, elem, true) &#125; c.elemsize = uint16(elem.size) c.elemtype = elem c.dataqsiz = uint(size) lockInit(&amp;c.lock, lockRankHchan) if debugChan &#123; print(&quot;makechan: chan=&quot;, c, &quot;; elemsize=&quot;, elem.size, &quot;; dataqsiz=&quot;, size, &quot;\\n&quot;) &#125; return c&#125; 发送123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool &#123; if c == nil &#123; // 当channel是nil if !block &#123; return false // 非阻塞直接返回false，表示发送失败 &#125; gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) // 挂起当前goroutine throw(&quot;unreachable&quot;) &#125; if debugChan &#123; print(&quot;chansend: chan=&quot;, c, &quot;\\n&quot;) &#125; if raceenabled &#123; racereadpc(c.raceaddr(), callerpc, funcPC(chansend)) &#125; // Fast path: check for failed non-blocking operation without acquiring the lock. // // After observing that the channel is not closed, we observe that the channel is // not ready for sending. Each of these observations is a single word-sized read // (first c.closed and second full()). // Because a closed channel cannot transition from &#x27;ready for sending&#x27; to // &#x27;not ready for sending&#x27;, even if the channel is closed between the two observations, // they imply a moment between the two when the channel was both not yet closed // and not ready for sending. We behave as if we observed the channel at that moment, // and report that the send cannot proceed. // // It is okay if the reads are reordered here: if we observe that the channel is not // ready for sending and then observe that it is not closed, that implies that the // channel wasn&#x27;t closed during the first observation. However, nothing here // guarantees forward progress. We rely on the side effects of lock release in // chanrecv() and closechan() to update this thread&#x27;s view of c.closed and full(). // 快速检测非阻塞且channel未关闭情况下的失败场景（详情看下述full函数）： // 1. 对于无缓冲channel，接收队列里没有goroutine则发送失败(非阻塞) // 2. 对于有缓冲channel，循环数组中已装满元素则发送失败(非阻塞) if !block &amp;&amp; c.closed == 0 &amp;&amp; full(c) &#123; return false &#125; var t0 int64 if blockprofilerate &gt; 0 &#123; t0 = cputicks() &#125; lock(&amp;c.lock) // 锁住channel，并发安全 if c.closed != 0 &#123; // 如果channel关闭了，则解锁并抛出异常 unlock(&amp;c.lock) panic(plainError(&quot;send on closed channel&quot;)) &#125; // 如果接收队列里有goroutine，则直接将要发送的数据拷贝到接收goroutine if sg := c.recvq.dequeue(); sg != nil &#123; // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). send(c, sg, ep, func() &#123; unlock(&amp;c.lock) &#125;, 3) return true &#125; // 对于有缓冲的channel，如果还有缓冲空间 if c.qcount &lt; c.dataqsiz &#123; // Space is available in the channel buffer. Enqueue the element to send. qp := chanbuf(c, c.sendx) // qp指向buf的sendx位置 if raceenabled &#123; racenotify(c, c.sendx, nil) &#125; typedmemmove(c.elemtype, qp, ep) // 将数据从ep处拷贝到qp c.sendx++ // 发送游标值加一 if c.sendx == c.dataqsiz &#123; // 如果发送游标值等于容量值，游标值归0 c.sendx = 0 &#125; c.qcount++ // 缓冲区的元素数量加一 unlock(&amp;c.lock) // 解锁 return true &#125; if !block &#123; // 如果是非阻塞的，直接返回错误 unlock(&amp;c.lock) return false &#125; // channel满了，发送方会被阻塞。接下来会构造一个sudog // Block on the channel. Some receiver will complete our operation for us. gp := getg() // 获取当前goroutine的指针 mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 &#123; mysg.releasetime = -1 &#125; // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil mysg.g = gp mysg.isSelect = false mysg.c = c gp.waiting = mysg gp.param = nil c.sendq.enqueue(mysg) // 当前goroutine进入发送等待队列 // Signal to anyone trying to shrink our stack that we&#x27;re about // to park on a channel. The window between when this G&#x27;s status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. atomic.Store8(&amp;gp.parkingOnChan, 1) // 挂起当前goroutine gopark(chanparkcommit, unsafe.Pointer(&amp;c.lock), waitReasonChanSend, traceEvGoBlockSend, 2) // Ensure the value being sent is kept alive until the // receiver copies it out. The sudog has a pointer to the // stack object, but sudogs aren&#x27;t considered as roots of the // stack tracer. KeepAlive(ep) // someone woke us up. if mysg != gp.waiting &#123; throw(&quot;G waiting list is corrupted&quot;) &#125; gp.waiting = nil gp.activeStackChans = false closed := !mysg.success gp.param = nil if mysg.releasetime &gt; 0 &#123; blockevent(mysg.releasetime-t0, 2) &#125; mysg.c = nil releaseSudog(mysg) if closed &#123; if c.closed == 0 &#123; throw(&quot;chansend: spurious wakeup&quot;) &#125; panic(plainError(&quot;send on closed channel&quot;)) &#125; return true&#125; 1234567891011121314func full(c *hchan) bool &#123; // c.dataqsiz is immutable (never written after the channel is created) // so it is safe to read at any time during channel operation. if c.dataqsiz == 0 &#123; // Assumes that a pointer read is relaxed-atomic. return c.recvq.first == nil &#125; // Assumes that a uint read is relaxed-atomic. return c.qcount == c.dataqsiz&#125;// if !block &amp;&amp; c.closed == 0 &amp;&amp; full(c) &#123;// return false// &#125; 这里有一个点需要注意，结合在chansend中调用full的地方上的英文注释进行分析，在得知channel未被关闭的情况下(c.closed==0)，去获取c.recvq.first和c.qcount的值时为什么不需要加锁(假设这个期间channe被关闭，则前后条件实际上是不一致的)？ 因为一个已经关闭的channel不能将channel状态从ready for sending变成not ready for sending，意味着在两个观测之间有一个时刻，通道既没有被关闭，也没有准备好发送，此时直接返回false也是没有问题的 然后其会依赖chanrecv()和closechan()中锁释放的副作用来更新这个线程的c.closed和full 如果从等待接收队列recvq里出队一个sudog(代表一个goroutine)，说明此时channel是空的，没有元素，所以才会有等待接收者。这时会调用send函数将元素直接从发送者的栈拷贝到接收者的栈，关键操作由sendDirect函数完成。 12345678910111213141516171819202122232425262728293031323334353637// send processes a send operation on an empty channel c.// The value ep sent by the sender is copied to the receiver sg.// The receiver is then woken up to go on its merry way.// Channel c must be empty and locked. send unlocks c with unlockf.// sg must already be dequeued from c.// ep must be non-nil and point to the heap or the caller&#x27;s stack.func send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) &#123; if raceenabled &#123; if c.dataqsiz == 0 &#123; racesync(c, sg) &#125; else &#123; // Pretend we go through the buffer, even though // we copy directly. Note that we need to increment // the head/tail locations only when raceenabled. racenotify(c, c.recvx, nil) racenotify(c, c.recvx, sg) c.recvx++ if c.recvx == c.dataqsiz &#123; c.recvx = 0 &#125; c.sendx = c.recvx // c.sendx = (c.sendx+1) % c.dataqsiz &#125; &#125; // sg.elem指向接收到的值存放的位置，如val &lt;-ch，指的就是&amp;val if sg.elem != nil &#123; sendDirect(c.elemtype, sg, ep) // 直接拷贝内存（从发送者到接收者） sg.elem = nil &#125; gp := sg.g // sudo上绑定的goroutine unlockf() gp.param = unsafe.Pointer(sg) sg.success = true if sg.releasetime != 0 &#123; sg.releasetime = cputicks() &#125; goready(gp, skip+1) // 唤醒接收的goroutine&#125; 继续看sendDirect函数： 12345678910111213141516171819202122// Sends and receives on unbuffered or empty-buffered channels are the// only operations where one running goroutine writes to the stack of// another running goroutine. The GC assumes that stack writes only// happen when the goroutine is running and are only done by that// goroutine. Using a write barrier is sufficient to make up for// violating that assumption, but the write barrier has to work.// typedmemmove will call bulkBarrierPreWrite, but the target bytes// are not in the heap, so that will not help. We arrange to call// memmove and typeBitsBulkBarrier instead.func sendDirect(t *_type, sg *sudog, src unsafe.Pointer) &#123; // src is on our stack, dst is a slot on another stack. // Once we read sg.elem out of sg, it will no longer // be updated if the destination&#x27;s stack gets copied (shrunk). // So make sure that no preemption points can happen between read &amp; use. dst := sg.elem typeBitsBulkBarrier(t, uintptr(dst), uintptr(src), t.size) // No need for cgo write barrier checks because dst is always // Go memory. memmove(dst, src, t.size)&#125; 这里涉及到一个goroutine直接写另一个goroutine栈的操作，一般而言，不同goroutine的栈是各自独有的。而这也违反了GC的一些假设。为了不出问题，写的过程中增加了写屏障，保证正确的完成写操作。这样做的好处是减少了一次内存拷贝，不用先拷贝到channel的buf，直接由发送者到接收者，减少了中间一层，效率得以提高。然后解锁，唤醒接收者，等待调度器的光临，接收者得以重见天日，可以继续执行接收操作后续代码了。 接收接收操作有两种写法，一种带”ok”，表示channel是否被关闭；一种不带”ok”，这种写法当接收到相应类型的零值时无法知道是真实的发送者发送者发送过来的值，还是channel被关闭后，返回给接收者默认类型的零值。经过编译器的处理后，这两种写法对应源码以下的两个函数： 1234567891011// entry points for &lt;- c from compiled code//go:nosplitfunc chanrecv1(c *hchan, elem unsafe.Pointer) &#123; chanrecv(c, elem, true)&#125;//go:nosplitfunc chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) &#123; _, received = chanrecv(c, elem, true) return&#125; 有上述源码可见，最终都会调用chanrecv这个函数： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146// chanrecv receives on channel c and writes the received data to ep.// ep may be nil, in which case received data is ignored.// If block == false and no elements are available, returns (false, false).// Otherwise, if c is closed, zeros *ep and returns (true, false).// Otherwise, fills in *ep with an element and returns (true, true).// A non-nil ep must point to the heap or the caller&#x27;s stack.func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) &#123; // raceenabled: don&#x27;t need to check ep, as it is always on the stack // or is new memory allocated by reflect. if debugChan &#123; print(&quot;chanrecv: chan=&quot;, c, &quot;\\n&quot;) &#125; if c == nil &#123; // 如果是nil的channel if !block &#123; return &#125; gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(&quot;unreachable&quot;) &#125; // Fast path: check for failed non-blocking operation without acquiring the lock. if !block &amp;&amp; empty(c) &#123; // After observing that the channel is not ready for receiving, we observe whether the // channel is closed. // // Reordering of these checks could lead to incorrect behavior when racing with a close. // For example, if the channel was open and not empty, was closed, and then drained, // reordered reads could incorrectly indicate &quot;open and empty&quot;. To prevent reordering, // we use atomic loads for both checks, and rely on emptying and closing to happen in // separate critical sections under the same lock. This assumption fails when closing // an unbuffered channel with a blocked send, but that is an error condition anyway. if atomic.Load(&amp;c.closed) == 0 &#123; // Because a channel cannot be reopened, the later observation of the channel // being not closed implies that it was also not closed at the moment of the // first observation. We behave as if we observed the channel at that moment // and report that the receive cannot proceed. return &#125; // The channel is irreversibly closed. Re-check whether the channel has any pending data // to receive, which could have arrived between the empty and closed checks above. // Sequential consistency is also required here, when racing with such a send. if empty(c) &#123; // The channel is irreversibly closed and empty. if raceenabled &#123; raceacquire(c.raceaddr()) &#125; if ep != nil &#123; typedmemclr(c.elemtype, ep) &#125; return true, false &#125; &#125; var t0 int64 if blockprofilerate &gt; 0 &#123; t0 = cputicks() &#125; lock(&amp;c.lock) if c.closed != 0 &amp;&amp; c.qcount == 0 &#123; if raceenabled &#123; raceacquire(c.raceaddr()) &#125; unlock(&amp;c.lock) if ep != nil &#123; typedmemclr(c.elemtype, ep) &#125; return true, false &#125; if sg := c.sendq.dequeue(); sg != nil &#123; // Found a waiting sender. If buffer is size 0, receive value // directly from sender. Otherwise, receive from head of queue // and add sender&#x27;s value to the tail of the queue (both map to // the same buffer slot because the queue is full). recv(c, sg, ep, func() &#123; unlock(&amp;c.lock) &#125;, 3) return true, true &#125; // 有缓冲channel，buf里面有元素，可以正常接收 if c.qcount &gt; 0 &#123; // Receive directly from queue qp := chanbuf(c, c.recvx) if raceenabled &#123; racenotify(c, c.recvx, nil) &#125; if ep != nil &#123; // 不忽略要接收的值，不是&quot;&lt;-ch&quot;，而是&quot;val &lt;-ch&quot;，ep指向val typedmemmove(c.elemtype, ep, qp) &#125; typedmemclr(c.elemtype, qp) // 清理掉循环数组里相应位置的值 c.recvx++ // 接收游标向前移动 if c.recvx == c.dataqsiz &#123; c.recvx = 0 // 接收游标归零 &#125; c.qcount-- unlock(&amp;c.lock) return true, true &#125; if !block &#123; unlock(&amp;c.lock) return false, false &#125; // no sender available: block on this channel. gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 &#123; mysg.releasetime = -1 &#125; // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil c.recvq.enqueue(mysg) // Signal to anyone trying to shrink our stack that we&#x27;re about // to park on a channel. The window between when this G&#x27;s status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. atomic.Store8(&amp;gp.parkingOnChan, 1) gopark(chanparkcommit, unsafe.Pointer(&amp;c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2) // someone woke us up if mysg != gp.waiting &#123; throw(&quot;G waiting list is corrupted&quot;) &#125; gp.waiting = nil gp.activeStackChans = false if mysg.releasetime &gt; 0 &#123; blockevent(mysg.releasetime-t0, 2) &#125; success := mysg.success gp.param = nil mysg.c = nil releaseSudog(mysg) return true, success&#125; 关闭1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071func closechan(c *hchan) &#123; if c == nil &#123; panic(plainError(&quot;close of nil channel&quot;)) // 关闭一个nil的channel直接panic &#125; lock(&amp;c.lock) if c.closed != 0 &#123; unlock(&amp;c.lock) panic(plainError(&quot;close of closed channel&quot;)) // 关闭一个已经关闭的channel，panic &#125; if raceenabled &#123; callerpc := getcallerpc() racewritepc(c.raceaddr(), callerpc, funcPC(closechan)) racerelease(c.raceaddr()) &#125; c.closed = 1 var glist gList // release all readers for &#123; sg := c.recvq.dequeue() if sg == nil &#123; break &#125; if sg.elem != nil &#123; typedmemclr(c.elemtype, sg.elem) sg.elem = nil &#125; if sg.releasetime != 0 &#123; sg.releasetime = cputicks() &#125; gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled &#123; raceacquireg(gp, c.raceaddr()) &#125; glist.push(gp) &#125; // release all writers (they will panic) for &#123; sg := c.sendq.dequeue() if sg == nil &#123; break &#125; sg.elem = nil if sg.releasetime != 0 &#123; sg.releasetime = cputicks() &#125; gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled &#123; raceacquireg(gp, c.raceaddr()) &#125; glist.push(gp) &#125; unlock(&amp;c.lock) // Ready all Gs now that we&#x27;ve dropped the channel lock. for !glist.empty() &#123; gp := glist.pop() gp.schedlink = 0 goready(gp, 3) &#125;&#125; close逻辑比较简单，对于一个channel，recvq和sendq中分别保存了阻塞的发送者和接收者。关闭channel后，对于等待接收者而言，会收到一个相应类型的零值。对于等待发送者，会直接panic。所以，在不了解channel还有没有接收者的情况下，不能贸然关闭channel。 close函数先上一把大锁，接着把所有挂在这个channel上的sender和receiver全都连成一个sudog链表，再解锁。最后再将所有的sudog全都唤醒。 唤醒之后，该干什么干什么。sender会继续执行chansend函数里goparkunlock函数之后的代码，当检测到channel已经关闭了则会panic。receiver则会进行后续的扫尾工作，然后返回，这里selected会返回true，received会根据channel是否关闭返回不同的值。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"go语言变量逃逸分析","slug":"go/go语言变量逃逸分析","date":"2022-02-12T07:16:09.000Z","updated":"2022-06-28T16:22:59.830Z","comments":true,"path":"2022/02/12/go/go语言变量逃逸分析/","link":"","permalink":"https://zcej.github.io/2022/02/12/go/go%E8%AF%AD%E8%A8%80%E5%8F%98%E9%87%8F%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/","excerpt":"","text":"go实现了内存的自动管理，其主要包括两个动作：分配与释放。为了更好的理解逃逸分析，需要对堆和栈有一定的了解。 堆和栈应用程序的内存载体，可以简单分为堆和栈。 在go中，栈的内存是由编译器进行分配和释放，栈区往往存储着函数参数、局部变量和调用函数帧，它们随着函数的创建而分配，函数的退出而销毁。一个goroutine对应一个栈，栈是调用栈的简称。一个栈通常又包含了许多栈帧，它描述的函数之间的调用关系，每一帧对应一次尚未返回的函数调用，它本身也是以栈形式存放数据。 与栈不同的是，应用程序在运行时只会存在一个堆。狭隘的说，内存管理只是针对堆内存而言的。程序在运行期间可以主动从堆上申请内存，这些内存通过go的内存分配器分配，并由垃圾回收器回收。 另外，对于堆内存的回收，还需要通过标记清除阶段，如三色标记法。但是对于栈上的内存而言，其分配和释放非常廉价。简单的说，它只需要两个cpu指令，一个是分配入栈，一个是栈内释放，而这只需要借助栈相关的寄存器即可完成。 逃逸分析对于一个对象是被分配在堆上还是栈上，官网上也有这样的回答： 如果可以，go编译器会尽可能将变量分配到栈上。但是，当编译器无法证明函数返回后，该变量没有被引用，那么编译器就必须在堆上分配该变量，以此避免悬挂指针。另外如果局部变量非常大，也会将其分配在堆上。 而go编译器则是通过逃逸分析去选择堆或者是栈，逃逸分析的基本思想如下：检查变量的生命周期是否是完全可知的，如果通过检查，则可以在栈上分配。否则，就是逃逸，必须在堆上进行分配。 可以通过命令go build -gcflags &quot;-m -l&quot;来查看逃逸分析结果： -m：打印逃逸分析信息 -l：禁止内联优化 常见的逃逸情况如下所示： 情况一：变量类型不确定12345678910func main() &#123; a := 666 fmt.Println(a)&#125;// 输出如下// $ go build -gcflags &quot;-m -l&quot; main.go// # command-line-arguments// ./main.go:7:13: ... argument does not escape// ./main.go:7:13: a escapes to heap 变量a发生了逃逸是因为其被传入了fmt.Println中，这个方法参数自己发生了逃逸。 func Println(a ...interface&#123;&#125;) (n int, err error) 因为fmt.Println函数参数为interface类型，编译期无法确定参数的具体类型，故分配在堆上 情况二：暴露给外部指针123456789101112func foo() *int &#123; a := 666 return &amp;a&#125;func main() &#123; _ = foo()&#125;// # command-line-arguments// .\\main.go:4:2: moved to heap: a 变量存在外部引用则必定分配到堆上。 情况三：变量所占内存较大1234567891011121314func foo() &#123; s := make([]int, 10000, 10000) for i := 0; i &lt; len(s); i++ &#123; s[i] = i &#125;&#125;func main() &#123; foo()&#125;// # command-line-arguments// .\\main.go:4:11: make([]int, 10000, 10000) escapes to heap 这里需要注意，在go中执行用户代码的goroutine是一种用户态线程，其调用栈内存被称为用户栈，它其实也是从堆区分配的，但是我们仍然可以将其看作和系统栈一样的内存空间，它的分配和释放都是通过编译器完成的。与其对应的是系统栈，它的分配和释放是操作系统完成的。在GMP模型中，一个M对应一个系统栈(也称为M的g0栈)，M上的多个goroutine会共享该系统栈。 不同架构的系统栈最大限制不同，以x86_64为例，其系统栈最大为8mb 我们常说的goroutine初始大小为2kb，说的是用户栈，可在runtime/stack.go中找到 在go中大对象的范围为大于32kb，即上述代码中的n达到8192，就会逃逸 情况四：变量大小不确定123456789101112131415func foo() &#123; n := 1 s := make([]int, n) for i := 0; i &lt; len(s); i++ &#123; s[i] = i &#125;&#125;func main() &#123; foo()&#125;// # command-line-arguments// .\\main.go:5:11: make([]int, n) escapes to heap 这次，在make方法中，没有直接指定大小，而是填入了变量n，这时go逃逸分析也会将其分配到堆区去。可见，为了保证内存的绝对安全，go的编译器可能会将一些变量不合时宜地分配到堆上，但是因为这些对象最终也会被垃圾收集器处理，所以也能接受。 小结 发生逃逸的情况还有很多，理解其思想才是最为重要的。 理解逃逸分析可以帮助我们写出更好的程序，知道变量分配在堆栈上的差别，则尽可能写出分配在栈上的代码，堆上的变量变少了，可以减轻内存分配的开销，减小gc的压力，提高程序的运行速度。 你会发现有些go上线项目，它们在函数传参的时候，并没有传递结构体指针，而是直接传递的结构体。这个做法，虽然它需要值拷贝，但是这是在栈上完成的操作，开销远比变量逃逸后动态的在堆上分配内存少的多。当然这个做法不是绝对的，如果结构体较大，传递指针将更加合适。 从gc的角度来看，指针传递是个双刃剑，需要谨慎使用，否则线上调优解决gc延时会让人崩溃。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"channel到底需不需要手动关闭","slug":"go/channel到底需不需要手动关闭？","date":"2021-12-25T16:31:29.000Z","updated":"2022-05-23T09:41:33.091Z","comments":true,"path":"2021/12/26/go/channel到底需不需要手动关闭？/","link":"","permalink":"https://zcej.github.io/2021/12/26/go/channel%E5%88%B0%E5%BA%95%E9%9C%80%E4%B8%8D%E9%9C%80%E8%A6%81%E6%89%8B%E5%8A%A8%E5%85%B3%E9%97%AD%EF%BC%9F/","excerpt":"","text":"前景提要下面的代码是《go语言圣经》这本书的其中一个案例，其中主协程和子协程兼具生产消费两种身份了，最终当没有新的消息时代码会阻塞住，而书中没有给出该案例的终止方式，自己也是思考了很久，看来还是对go的channel理解不够深，在使用channel的时候一定要有自己的思考，不然可能会引发很多问题，小到程序莫名其妙的panic，大到出现goroutine以及channel的泄露等等！ 123456789101112131415161718192021222324252627282930313233343536373839func crawl(url string) []string &#123; urls, err := links.Extract(url) // 书中其他章节, 具体逻辑是提取网页中所有a标签的链接 if err != nil &#123; log.Print(err) &#125; return urls&#125;func main() &#123; worklist := make(chan []string) // lists of URLs, may have duplicates unseenLinks := make(chan string) // de-duplicated URLs urls := []string&#123;&quot;http://xxxx.com&quot;&#125; // Add command-line arguments to worklist. go func() &#123; worklist &lt;- urls &#125;() // Create 20 crawler goroutines to fetch each unseen link. for i := 0; i &lt; 20; i++ &#123; go func() &#123; for link := range unseenLinks &#123; foundLinks := crawl(link) go func() &#123; worklist &lt;- foundLinks &#125;() &#125; &#125;() &#125; // The main goroutine de-duplicates worklist items // and sends the unseen ones to the crawlers. seen := make(map[string]bool) for list := range worklist &#123; for _, link := range list &#123; if !seen[link] &#123; seen[link] = true unseenLinks &lt;- link &#125; &#125; &#125;&#125; 虽然上述并发案例书中未提及如何终止的问题，不过书里也提供了另外一种并发方式且可自动终止，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041// tokens is a counting semaphore used to// enforce a limit of 20 concurrent requests.var tokens = make(chan struct&#123;&#125;, 20)func crawl(w work, mutex sync.Locker) []work &#123; fmt.Println(url) tokens &lt;- struct&#123;&#125;&#123;&#125; // acquire a token urls, err := links.Extract(w.url) &lt;-tokens // release the token if err != nil &#123; log.Print(err) &#125; return urls&#125;func main() &#123; worklist := make(chan []string) var n int // number of pending sends to worklist url := []string&#123;&quot;http://xxxx.com&quot;&#125; // start n++ go func() &#123; worklist &lt;- []work&#123;url&#125; &#125;() // crawl the web concurrently visited := make(map[string]bool) for ; n &gt; 0; n-- &#123; works := &lt;-worklist for _, w := range works &#123; if !visited[w.url] &#123; visited[w.url] = true n++ go func(w work) &#123; worklist &lt;- crawl(w, &amp;lock) &#125;(w) &#125; &#125; &#125;&#125; 这种实现方式很巧妙，使用了计数器n进行了限制，主协程在n减为0的时候会终止，子协程也会随之退出。这里的channel在没有被goroutine引用的时候也会被gc所销毁，结合第一个没有终止的案例，我们必须手动去关闭掉生产消费，让程序达到所有消息消费完后自动终止的目的。那么以下知识点就是必须要掌握的！ https://juejin.cn/post/7033671944587182087 什么情况下关闭channel会引发panic？示例如下： 1234567891011121314151617181920212223242526272829303132333435363738394041// 1. 关闭未初始化的chanfunc TestCloseNilChan(t *testing.T) &#123; var errCh chan error close(errCh) // Output: // panic: close of nil channel&#125;// 2. 关闭已经关闭的chanfunc TestRepeatClosingChan(t *testing.T) &#123; errCh := make(chan error) close(errCh) close(errCh) // Output: // panic: close of closed channel&#125;// 3. 关闭chan后发送数据func TestSendOnClosingChan(t *testing.T) &#123; errCh := make(chan error) close(errCh) errCh &lt;- errors.New(&quot;chan error&quot;) // Output: // panic: send on closed channel&#125;// 4. 发送数据时关闭chanfunc TestCloseOnSendingToChan(t *testing.T) &#123; errCh := make(chan error) go func() &#123; errCh &lt;- errors.New(&quot;chan error&quot;) &#125;() time.Sleep(1 * time.Second) close(errCh) // Output: // panic: send on closed channel&#125; 总结， 下述四种情况下关闭channel会引发panic： 关闭未初始化的channel 关闭已经关闭的channel 在关闭channel后发送数据 在发送数据时关闭channel 另外，可总结出以下规律： 只能让channel的唯一发送者关闭此channel 如果有多个发送者，应该使用专门的信号通知stop channel是否有必要关闭channel？不关闭又如何？当channel的发送次数等于接收次数12345678910111213141516171819202122232425262728// 1. 当channel的发送次数等于接收次数func TestIsCloseChannelNecessary_on_equal(t *testing.T) &#123; fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) ch := make(chan int) // sender go func() &#123; for i := 0; i &lt; 3; i++ &#123; ch &lt;- i &#125; &#125;() // receiver go func() &#123; for i := 0; i &lt; 3; i++ &#123; fmt.Println(&lt;-ch) &#125; &#125;() time.Sleep(time.Second * 1) fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) // Output: // NumGoroutine: 2 // 0 // 1 // 2 // NumGoroutine: 2&#125; channel的发送次数等于接收次数时，发送者的goroutine和接收者的goroutine分别会在发送和接收结束时结束自己的goroutine，用于传输数据的channel也会由于代码没有使用被垃圾收集器回收。所以该种情况下不需手动关闭chanel。当channel的发送次数大于&#x2F;小于接收次数12345678910111213141516171819202122232425262728293031// 2. 当channel的发送次数大于/小于接收次数func TestIsCloseChannelNecessary_on_more_equal(t *testing.T) &#123; fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) ch := make(chan int) // sender go func() &#123; defer fmt.Println(&quot;exit 1&quot;) for i := 0; i &lt; 4; i++ &#123; ch &lt;- i &#125; &#125;() // receiver go func() &#123; defer fmt.Println(&quot;exit 2&quot;) for i := 0; i &lt; 3; i++ &#123; fmt.Println(&lt;-ch) &#125; &#125;() time.Sleep(time.Second * 1) fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) // Output: // NumGoroutine: 2 // 0 // 1 // 2 // exit 2 // NumGoroutine: 3&#125; channel的发送次数大于接收次数时，发送者goroutine会等待接收者接收而一直阻塞。所以发送者goroutine一直未退出，channel也会由于一直被发送者使用而无法被垃圾回收。未退出的goroutine和channel会造成内存泄露等问题。 总结： 在只有一个发送者和一个接收者的情况下，只要确保发送者或接收者不会阻塞，不关闭channel是可行的。 在无法判断channel的发送次数和接收次数时，应当在合适的时机关闭channel。 另外使用for range从channel取值的时候，需要手动close掉channel，否则消费者会一直阻塞进而panic抛出错误，会被判定为死锁。 如何判断channel是否关闭？ channel关闭后继续读取该chennel不会阻塞，而是返回对应类型的零值。 使用channel的多重返回值(如err, ok :&#x3D; &lt;- errCh)12345678910111213141516171819202122// 1. 使用channel的返回值判断其是否关闭func TestReadFromClosedChan(t *testing.T) &#123; var errCh = make(chan error) go func() &#123; defer close(errCh) errCh &lt;- errors.New(&quot;chan error&quot;) &#125;() go func() &#123; for i := 0; i &lt; 3; i++ &#123; err, ok := &lt;-errCh; fmt.Println(i, err, ok) &#125; &#125;() time.Sleep(time.Second) // Output: // 0 chan error true // 1 &lt;nil&gt; false // 2 &lt;nil&gt; false&#125; err, ok :&#x3D; &lt;- errCh的第二个值ok返回false表示该channel已关闭。 使用for range简化语法123456789101112131415161718192021// 2. 使用for range简化语法func TestReadFromClosedChan2(t *testing.T) &#123; var errCh = make(chan error) go func() &#123; defer close(errCh) errCh &lt;- errors.New(&quot;chan error&quot;) &#125;() go func() &#123; i := 0 for err := range errCh &#123; fmt.Println(i, err) i++ &#125; &#125;() time.Sleep(time.Second) // Output: // 0 chan error&#125; 如何优雅的关闭channel?详细案例参考文章：https://gfw.go101.org/article/channel-closing.html 在使用单通道的函数中错误的关闭channel的话，编译的时候就会报错 参考上述文章，针对常规情况下需要关闭channel的四种场景，做了以下总结： 一个发送者，一个接收者：发送者关闭channel；接收者使用select或for range判断channel是否关闭 一个发送者，多个接收者：同上 多个发送者，一个接收者：接收者接收完后，使用专门的信号channel关闭；发送者使用select监听该信号channel是否关闭 多个发送者，多个接收者：任意一方或第三方使用专门的信号channel关闭；发送者，接收者都使用select监听该信号channel是否关闭总结回到开头例举的爬虫案例，个人进行了改写，主要是添加了超过递归深度时的退出以及超时退出和使用信号channel通知所用生产消费的goroutine关闭。具体代码如下，还有很多完善的点，以后理解更深后再进行修改：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475type work struct &#123; url string depth int&#125;func crawl(w work, quit chan struct&#123;&#125;) []work &#123; fmt.Printf(&quot;depth: %d, url: %s\\n&quot;, w.depth, w.url) if w.depth &gt; 3 &#123; quit &lt;- struct&#123;&#125;&#123;&#125; return nil &#125; urls, err := links.Extract(w.url) if err != nil &#123; log.Print(err) &#125; var works []work for _, url := range urls &#123; works = append(works, work&#123;url, w.depth + 1&#125;) &#125; return works&#125;//!+func main() &#123; worklist := make(chan []work) // lists of URLs, may have duplicates unseenLinks := make(chan work) // de-duplicated URLs stopCh := make(chan struct&#123;&#125;) // signal chan to stop all goroutine quit := make(chan struct&#123;&#125;) urls := work&#123;&quot;http://zorelworld.com/&quot;, 1&#125; // Add command-line arguments to worklist. go func() &#123; worklist &lt;- []work&#123;urls&#125; &#125;() // Create 20 crawler goroutines to fetch each unseen link. for i := 0; i &lt; 20; i++ &#123; go func() &#123; for &#123; select &#123; case &lt;-stopCh: return case link, _ := &lt;-unseenLinks: foundLinks := crawl(link, quit) go func() &#123;worklist &lt;- foundLinks&#125;() &#125; &#125; &#125;() &#125; // The main goroutine de-duplicates worklist items // and sends the unseen ones to the crawlers. seen := make(map[string]bool) for &#123; select &#123; case list := &lt;-worklist: for _, link := range list &#123; if !seen[link.url] &#123; seen[link.url] = true unseenLinks &lt;- link &#125; &#125; case &lt;-quit: fmt.Println(&quot;Exit, 111&quot;) close(stopCh) return case &lt;-time.After(3 * time.Second): // 如果上面的ch一直没数据会阻塞, 那么select也会检测其他case条件, 检测到后3s超时退出 fmt.Println(&quot;Exit, timeout&quot;) close(stopCh) return &#125; &#125;&#125;","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"关于channel和goroutine的内存泄漏问题","slug":"go/关于channel和goroutine的内存泄露问题","date":"2021-11-19T15:18:41.000Z","updated":"2022-06-28T16:12:40.717Z","comments":true,"path":"2021/11/19/go/关于channel和goroutine的内存泄露问题/","link":"","permalink":"https://zcej.github.io/2021/11/19/go/%E5%85%B3%E4%BA%8Echannel%E5%92%8Cgoroutine%E7%9A%84%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%E9%97%AE%E9%A2%98/","excerpt":"","text":"本文主要了解为关闭channel情况下所引发的内存泄露问题。 一个发送者导致的内存泄露主要原因是接收者提前退出了，导致发送者一直阻塞，最后导致了goroutine泄露，如下所示： 123456789101112131415161718192021222324252627func TestLeakOfMemory(t *testing.T) &#123; fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) chanLeakOfMemory() time.Sleep(time.Second * 3) // 等待 goroutine 执行，防止过早输出结果 fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine())&#125;func chanLeakOfMemory() &#123; errCh := make(chan error) // (1) go func() &#123; // (5) time.Sleep(2 * time.Second) errCh &lt;- errors.New(&quot;chan error&quot;) // (2) &#125;() var err error select &#123; case &lt;-time.After(time.Second): // (3) 大家也经常在这里使用 &lt;-ctx.Done() fmt.Println(&quot;超时&quot;) case err = &lt;-errCh: // (4) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Println(nil) &#125; &#125;&#125; 上述代码分析： 由于没有发送方想errCh发送数据，故代码在(4)处阻塞 当(3)处超时后，函数退出且(4)处代码并未接收成功 之后(2)开始执行，由于errCh没有接收者，故一直阻塞在(2)出 因为(2)出的代码所在协程一直没有退出，故发生了内存泄露 这种情况处理起来也较为简单，只需将channel设置为有缓冲的就行。例如将(1)处代码改为errCh := make(chan error, 1)即可。 多个发送者导致的内存泄露产生原因也和上述相同，当接收者提前退出了，那么至少有一个goroutine无法退出，进而造成内存泄露。 12345678910111213141516171819202122232425262728293031func TestLeakOfMemory2(t *testing.T) &#123; fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) chanLeakOfMemory2() time.Sleep(time.Second * 3) // 等待 goroutine 执行，防止过早输出结果 fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine())&#125;func chanLeakOfMemory2() &#123; ich := make(chan int, 100) // (3) // sender go func() &#123; defer close(ich) for i := 0; i &lt; 10000; i++ &#123; ich &lt;- i time.Sleep(time.Millisecond) // 控制一下，别发太快 &#125; &#125;() // receiver go func() &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() for i := range ich &#123; // (2) if ctx.Err() != nil &#123; // (1) fmt.Println(ctx.Err()) return &#125; fmt.Println(i) &#125; &#125;()&#125; 尽管上述代码使用了有缓冲的channel，依然可能会出现接收者提前退出，导致有缓冲channel的缓存队列被占满，阻塞在第101个位置。这种情况需要使用一个额外的stop channel来结束发送者所在的goroutine，如下： 12345678910111213141516171819202122232425262728293031323334353637func TestLeakOfMemory2(t *testing.T) &#123; fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) chanLeakOfMemory2() time.Sleep(time.Second * 3) // 等待 goroutine 执行，防止过早输出结果 fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine())&#125;func chanLeakOfMemory2() &#123; ich := make(chan int, 100) stopCh := make(chan struct&#123;&#125;) // sender go func() &#123; defer close(ich) for i := 0; i &lt; 10000; i++ &#123; select &#123; case &lt;-stopCh: case ich &lt;- i: return &#125; time.Sleep(time.Millisecond) // 控制一下，别发太快 &#125; &#125;() // receiver go func() &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() for i := range ich &#123; if ctx.Err() != nil &#123; fmt.Println(ctx.Err()) close(stopCh) return &#125; fmt.Println(i) &#125; &#125;()&#125; 总结不论发送者发送一次还是多次，如果接收者在接收完channel中的数据之前退出，那么就会造成内存泄露。如果接收者需要在channel关闭之前退出，为了防止内存泄露，在发送者与接收者一对一时，应设置channel缓冲队列为1；在发送者与接收者一对多或多对多时，应使用专门的stop channel通知发送者关闭相应channel。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"关于channel发生死锁的情况总结","slug":"go/关于channel发生死锁的情况总结","date":"2021-11-03T13:09:18.000Z","updated":"2022-06-28T16:13:32.202Z","comments":true,"path":"2021/11/03/go/关于channel发生死锁的情况总结/","link":"","permalink":"https://zcej.github.io/2021/11/03/go/%E5%85%B3%E4%BA%8Echannel%E5%8F%91%E7%94%9F%E6%AD%BB%E9%94%81%E7%9A%84%E6%83%85%E5%86%B5%E6%80%BB%E7%BB%93/","excerpt":"","text":"时刻提醒自己必须深入理解channel的特性，有自己的思考，而不是死记硬背。之后可以阅读熟悉下channel的底层实现原理。 向无缓冲的channel发送&#x2F;接收数据无缓冲的channel必须有接收才能发送，下述代码在执行的时候会引发deadlock错误 12345func main() &#123; ch := make(chan int) ch &lt;- 1 // 这一行代码会引发死锁 // &lt;-ch // 直接取值也会引发死锁&#125; 解决方法是启用一个goroutine去接收值，如下： 12345678910func recv(c chan int) &#123; ret := &lt;-c fmt.Println(ret)&#125;func main() &#123; ch := make(chan int) go recv(ch) ch &lt;- 1&#125; 思考：下述情况会引发死锁吗？ 1234567func main() &#123; ch := make(chan int) go func() &#123; ch &lt;- 1 &#125;() time.Sleep(time.Second * 3)&#125; 答案是不会引发死锁，虽然子协程一直阻塞在传值语句，但是和主协程之间并无产生联系，当主协程退出的时候子协程也就跟着退出了。延伸：如果主协程和子协程之间建立了联系会产生死锁吗？ 123456789func main() &#123; ch1 := make(chan, int) ch2 := make(chan, int) go func() &#123; ch2 &lt;- 21 ch1 &lt;- 11 &#125;() &lt;-ch1&#125; 输出有缓冲的channel中所有的值当读取完channel中的数据后，继续读取的操作会造成阻塞，且阻塞发生在主协程中，故会引发阻塞。 12345678func main() &#123; ch := make(chan int, 2) ch &lt;- 1 ch &lt;- 2 for ch := range ch &#123; fmt.Println(ch) &#125;&#125; 解决方法是发送完所有数据后则关闭channel，或者通过select方法中的default进行处理，如下： 123456789101112131415161718func main() &#123; ch := make(chan int, 2) ch &lt;- 1 ch &lt;- 2 // solution 1: // close(ch) // solution 2: // select &#123; // case v := &lt;-ch: // fmt.Println(v) // default: // fmt.Println(&quot;nothing in channel&quot;) // &#125; for ch := range ch &#123; fmt.Println(ch) &#125;&#125; 过度向有缓冲的channel写入数据写入数据超过channel的容量的时候，也会引发死锁。 123456func main() &#123; ch := make(chan int, 2) ch &lt;- 1 ch &lt;- 2 ch &lt;- 3&#125; 解决方法是通过select方法中的default进行处理： 1234567891011func main() &#123; ch := make(chan int, 2) ch &lt;- 1 ch &lt;- 2 select &#123; case ch &lt;- 3: fmt.Println(&quot;ok&quot;) default: fmt.Println(&quot;wrong&quot;) &#125;&#125; 总结上述提到的死锁，是指在程序的主协程中发生的情况，如果上述情况是发生在非主协程中，读取或者写入的情况是发生阻塞的，而不是死锁(此时需要考虑是否需要主动关闭子协程)。实际上，阻塞情况省去了我们加锁的步骤，反而是更加有利于代码编写，要合理的运用阻塞。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"如何主动关闭goroutine","slug":"go/如何主动关闭goroutine？","date":"2021-10-22T12:22:41.000Z","updated":"2022-06-28T16:08:48.495Z","comments":true,"path":"2021/10/22/go/如何主动关闭goroutine？/","link":"","permalink":"https://zcej.github.io/2021/10/22/go/%E5%A6%82%E4%BD%95%E4%B8%BB%E5%8A%A8%E5%85%B3%E9%97%ADgoroutine%EF%BC%9F/","excerpt":"","text":"在学习go语言channel中，读到最多的一句话便是通过通信共享内存，而不是通过共享内存来进行通信（Do not communicate by sharing memory；instead，share memory by communicating.）那么如何来理解这句话呢？个人理解通过共享内存来通信的话必须保证数据的安全及正确性，即需要通过加锁等手段进行控制，但是此种方式带来的性能开销以及可能造成的死锁问题处理起来较为繁琐。而go语言则通过channel来通信，通过通信来传递内存数据，个人认为更加优雅简洁与高效。很多情况下我们需要主动关闭goroutine，那么如何实现呢？ 使用channel进行控制for-range结构for-range从channel上获取值，直到channel关闭。该结构对于从单一通道上获取数据去执行某些任务是十分方便的，如下所示： 123456789101112131415161718192021func producer(out chan&lt;- int) &#123; for i := 0; i &lt; 10; i++ &#123; data := i * i fmt.Println(&quot;生产者生产数据：&quot;, data) out &lt;- data &#125; close(out)&#125;func consumer(in &lt;-chan int) &#123; for data := range in &#123; fmt.Println(&quot;消费者得到数据：&quot;, data) &#125;&#125;func main() &#123; ch := make(chan int) go producer(ch) consumer(ch)&#125; for-select结构当channel比较多时，for-range结构就不是很方便了。此时可以使用for-select，select能够让goroutine在多个通信操作上等待（可以理解为监听多个channel）。 指定一个退出的channel12345678910111213141516171819202122232425262728func producer(out chan&lt;- int, exit chan struct&#123;&#125;) &#123; for i := 0; i &lt; 10; i++ &#123; data := i * i fmt.Println(&quot;生产者生产数据：&quot;, data) out &lt;- data &#125; exit &lt;- struct&#123;&#125;&#123;&#125;&#125;func consumer(in &lt;-chan int, exit chan struct&#123;&#125;) &#123; for &#123; select &#123; case &lt;-exit: fmt.Println(&quot;收到退出信号&quot;) // 不建议使用goto语句 return // 必须return, 否则goroutine不会结束 case data := &lt;-in: fmt.Println(&quot;消费者得到数据：&quot;, data) &#125; &#125;&#125;func main() &#123; ch := make(chan int) exitCh := make(chan struct&#123;&#125;) go producer(ch, exitCh) consumer(ch, exitCh)&#125; 多个channel都关闭才能退出12345678910111213141516171819202122232425262728293031323334353637383940func producer(out1, out2 chan&lt;- int) &#123; for i := 0; i &lt; 10; i++ &#123; data := i * i fmt.Println(&quot;生产者生产数据：&quot;, data) out1 &lt;- data time.Sleep(1 * time.Second) out2 &lt;- data * 2 &#125; close(out1) close(out2)&#125;func consumer(in1, in2 &lt;-chan int) &#123; for &#123; select &#123; case data, ok := &lt;-in1: if !ok &#123; fmt.Println(&quot;收到ch1关闭信号&quot;) in1 = nil &#125; fmt.Println(&quot;消费者得到数据：&quot;, data) case data, ok := &lt;-in2: if !ok &#123; fmt.Println(&quot;收到ch2关闭信号&quot;) in2 = nil &#125; fmt.Println(&quot;消费者得到数据：&quot;, data) &#125; if in1 == nil &amp;&amp; in2 == nil &#123; return &#125; &#125;&#125;func main() &#123; ch1 := make(chan int) ch2 := make(chan int) go producer(ch1, ch2) consumer(ch1, ch2)&#125; 使用content包进行控制context是官方提供的用于控制多个goroutine协作的包。 1234567891011121314151617181920212223242526272829303132333435363738394041func producer(out chan&lt;- int, ctx context.Context, cancel context.CancelFunc) &#123; for i := 0; i &lt; 10; i++ &#123; data := i * i fmt.Println(&quot;生产者生产数据：&quot;, data) out &lt;- data &#125; subCtx, _ := context.WithCancel(ctx) go consumer2(subCtx) cancel()&#125;func consumer(in &lt;-chan int, ctx context.Context) &#123; for &#123; select &#123; case data := &lt;-in: fmt.Println(&quot;消费者得到数据：&quot;, data) case &lt;-ctx.Done(): fmt.Println(&quot;收到结束信号&quot;) return // 必须return, 防止goroutine泄露 &#125; &#125;&#125;func consumer2(ctx context.Context) &#123; for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;收到结束信号, consumer2&quot;) return // 必须return, 防止goroutine泄露 &#125; &#125;&#125;func main() &#123; ctx, cancel := context.WithCancel(context.Background()) ch := make(chan int) go producer(ch, ctx, cancel) consumer(ch, ctx) time.Sleep(1 * time.Second)&#125; 总结在实际开发过程中，不会简单的启动goroutine就结束了。往往是需要有效的管理多个goroutine之间的协作，此时掌握如何主动关闭goroutine就显得尤为重要了。不仅如此，还需要学会分析go语言运行性能，下一个目标就是学习go语言中的性能大杀器pprof。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"如何控制并发速率","slug":"go/如何控制并发速率？","date":"2021-10-11T14:31:19.000Z","updated":"2022-06-28T16:09:56.259Z","comments":true,"path":"2021/10/11/go/如何控制并发速率？/","link":"","permalink":"https://zcej.github.io/2021/10/11/go/%E5%A6%82%E4%BD%95%E6%8E%A7%E5%88%B6%E5%B9%B6%E5%8F%91%E9%80%9F%E7%8E%87%EF%BC%9F/","excerpt":"","text":"为什么需要控制123456789101112func main() &#123; var wg sync.WaitGroup for i := 0; i &lt; math.MaxInt32; i++ &#123; wg.Add(1) go func(i int) &#123; defer wg.Done() fmt.Println(i) time.Sleep(time.Second) &#125;(i) &#125; wg.Wait()&#125; 过高的并发会将系统资源消耗殆尽，导致程序运行最终panic，关键的报错信息如下：panic: too many concurrent operations on a single file or socket (max 1048575) 导致出现上述错误的原因是源自fmt.Printf函数输出到标准输出，标准输出也可以视为文件，总之就是系统的资源被耗尽了。 就算注释掉fmt.Printf函数，也会因为内存不足而最终崩溃。 如何解决解决的主要方式就是限制并发的协程数量。 使用带缓冲的channel进行控制123456789101112131415func main() &#123; var wg sync.WaitGroup ch := make(chan struct&#123;&#125;, 3) for i := 0; i &lt; 10; i++ &#123; ch &lt;- struct&#123;&#125;&#123;&#125; wg.Add(1) go func(i int) &#123; defer wg.Done() log.Println(i) time.Sleep(time.Second) &lt;-ch &#125;(i) &#125; wg.Wait()&#125; 创建一个缓冲区大小为3的channel，在没有被接收的情况下，最多发送3个消息则被阻塞 开启协程前，调用ch &lt;- struct&#123;&#125;&#123;&#125;，若缓冲区满则阻塞 协程任务结束，调用&lt;-ch释放缓冲区 利用第三方库目前有很多第三方库实现了协程池，可以很方便的用来控制协程的并发数量，如Jeffail/tunny，panjf2000/ants，以tunny举例如下： 12345678910111213func main() &#123; pool := tunny.NewFunc(3, func(i interface&#123;&#125;) interface&#123;&#125; &#123; log.Println(i) time.Sleep(time.Second) return nil &#125;) defer pool.Close() for i := 0; i &lt; 10; i++ &#123; go pool.Process(i) &#125; time.Sleep(time.Second * 4)&#125; tunny.NewFunc(3, f)第一个参数是协程池的大小(poolSize)，第二个参数是协程运行的函数(worker) pool.Process(i)将参数i传递给协程池定义好的worker处理 pool.Close()关闭协程池 调整系统资源上限ulimit有些情况下，即使我们有效的限制了协程的并发数量，但是仍旧出现某一类资源不足的问题，例如： too many open files out of memory 操作系统通常会限制同时打开文件数量，栈空间大小等，ulimit -a可以看到系统的当前设置： 1234567891011121314151617[root@master ~]# ulimit -acore file size (blocks, -c) unlimiteddata seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 14997max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 100001pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 14997virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited 进而进行按需调整即可。 虚拟内存virtual memory虚拟内存是一项非常常见的技术，当内存不足时，将磁盘映射为内存使用，比如linux下的交换分区(swap space)。在linux上创建并使用交换分区是一件非常简单的事情： 12345sudo fallocate -l 20G /mnt/.swapfile # 创建 20G 空文件sudo mkswap /mnt/.swapfile # 转换为交换分区文件sudo chmod 600 /mnt/.swapfile # 修改权限为 600sudo swapon /mnt/.swapfile # 激活交换分区free -m # 查看当前内存使用情况(包括交换分区) 关闭交换分区也非常简单： 12sudo swapoff /mnt/.swapfilerm -rf /mnt/.swapfile 磁盘的 I&#x2F;O 读写性能和内存条相差是非常大的，例如 DDR3 的内存条读写速率很容易达到 20GB&#x2F;s，但是 SSD 固态硬盘的读写性能通常只能达到 0.5GB&#x2F;s，相差 40倍之多。因此，使用虚拟内存技术将硬盘映射为内存使用，显然会对性能产生一定的影响。如果应用程序只是在较短的时间内需要较大的内存，那么虚拟内存能够有效避免 out of memory 的问题。如果应用程序长期高频度读写大量内存，那么虚拟内存对性能的影响就比较明显了。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"go语言实现爬虫(三)","slug":"go/个人项目实战：go语言实现爬虫(三)","date":"2021-09-15T16:12:23.000Z","updated":"2022-06-28T16:18:26.065Z","comments":true,"path":"2021/09/16/go/个人项目实战：go语言实现爬虫(三)/","link":"","permalink":"https://zcej.github.io/2021/09/16/go/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%EF%BC%9Ago%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E7%88%AC%E8%99%AB(%E4%B8%89)/","excerpt":"","text":"添加grpc简单编写proto文件： 1234567891011121314151617181920212223242526272829syntax = &quot;proto3&quot;;option go_package = &quot;./;proto&quot;;service Crawler &#123; rpc Start (StartReq) returns (TaskInfoResp) &#123;&#125; rpc Stop (TaskInfoReq) returns (TaskInfoResp) &#123;&#125; rpc Status (TaskInfoReq) returns (TaskInfoResp) &#123;&#125; rpc Pause (TaskInfoReq) returns (TaskInfoResp) &#123;&#125; rpc Resume (TaskInfoReq) returns (TaskInfoResp) &#123;&#125; rpc Result (TaskInfoReq) returns (TaskInfoResp) &#123;&#125;&#125;message StartReq &#123; string taskID = 1; repeated string urls = 2; int32 threads = 3; int32 timeout = 4; int32 depth = 5;&#125;message TaskInfoReq &#123; string taskID = 1;&#125;message TaskInfoResp &#123; int32 code = 1; string msg = 2; repeated string data = 3;&#125; 运行测试","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"go语言实现爬虫(二)","slug":"go/个人项目实战：go语言实现爬虫(二)","date":"2021-09-13T13:05:57.000Z","updated":"2022-06-28T16:21:25.740Z","comments":true,"path":"2021/09/13/go/个人项目实战：go语言实现爬虫(二)/","link":"","permalink":"https://zcej.github.io/2021/09/13/go/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%EF%BC%9Ago%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E7%88%AC%E8%99%AB(%E4%BA%8C)/","excerpt":"","text":"使用gin封装项目目录结构如下： api：主要业务逻辑实现，结合gin的上下文进行封装 config：项目主要配置文件 global：全局变量管理 model：结构体定义的地方 proto：定义proto文件，存放其生成的go文件 router：路由控制 storage：运行日志存储及临时结果存放 util：常用的工具类封装 1234567891011121314151617181920212223242526272829303132333435363738├─api│ │ base.go│ ││ └─crawler│ │ crawl.go│ ││ └─links│ links.go│├─config│ settings.go│├─global│ global.go│├─model│ ├─request│ │ request.go│ ││ └─response│ response.go│├─proto│ crawler.proto│├─router│ router.go│├─storage│ ├─logs│ └─tasks│─utils│ └─writer│ write_data.go│ go.mod│ go.sum│ main.go│ readme.md 完善各控制流程任务定义及初始化如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445type work struct &#123; url string // 网页链接 currDepth int // 当前深度&#125;type WlcTask struct &#123; taskID string // 任务ID workList chan []work // 存放每一个链接下一层的所有链接 workListBak chan []work // workList的备份, 用于任务的暂停与恢复 unVisitedLinks chan work // 存放未访问过的链接 stopSignalCh chan struct&#123;&#125; // 用于通知所有生产消费的goroutine退出, 防止内存泄露 quitCh chan struct&#123;&#125; // 用于主动停止任务, 通过递归深度判断 statusCh chan string // 用于记录任务状态变化 visited map[string]bool // 标记已访问过的链接 startUrl []work // 开始链接 concurrency int // 并发数量 timeOut int // 超时时间设置 depth int // 递归深度 currDepth int // 当前递归深度 status string // 任务状态 created running stopped finished pausing resuming&#125;func NewWclTask(wlcReq *request.WlcTaskReq) *WlcTask &#123; var startUrl []work for _, url := range wlcReq.Urls &#123; startUrl = append(startUrl, work&#123;url: url, currDepth: 1&#125;) &#125; workListCh := make(chan []work) return &amp;WlcTask&#123; taskID: wlcReq.TaskID, workList: workListCh, workListBak: workListCh, unVisitedLinks: make(chan work), stopSignalCh: make(chan struct&#123;&#125;), quitCh: make(chan struct&#123;&#125;), statusCh: make(chan string), visited: make(map[string]bool), startUrl: startUrl, concurrency: wlcReq.Concurrency, timeOut: wlcReq.Timeout, depth: wlcReq.Depth, currDepth: 1, status: config.TaskStatus.Created, &#125;&#125; 另外，还针对WlcTask封装了一个改变任务状态的方法： 1234567891011121314151617181920212223242526func (w *WlcTask) ChangeTaskStatus() &#123; for &#123; select &#123; case &lt;-w.stopSignalCh: log.Printf(&quot;[Start] record task(%s) status goroutine exit...&quot;, w.taskID) return case taskStr, ok := &lt;-w.statusCh: if ok &#123; arr := strings.Split(taskStr, &quot;,&quot;) w.status = arr[0] currDepth, err := strconv.Atoi(arr[1]) if err != nil &#123; log.Println(err) &#125; log.Printf(&quot;[Start] change task(%s) status to %s, depth is, %d&quot;, w.taskID, w.status, currDepth) // recode the task info to a json file task := request.TaskInfo&#123; Status: arr[0], CurrDepth: currDepth, &#125; writer.TaskInfoWriter(w.taskID, &amp;task) &#125; &#125; &#125;&#125; 启动12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061func (w *WlcTask) StartHandler(globalTask map[string]*WlcTask) &#123; // record the task status change go w.ChangeTaskStatus() go func() &#123; w.workList &lt;- w.startUrl &#125;() w.statusCh &lt;- fmt.Sprintf(&quot;%s,%d&quot;, config.TaskStatus.Running, w.currDepth) for i := 0; i &lt; w.concurrency; i++ &#123; go func(num int) &#123; for &#123; select &#123; case &lt;-w.stopSignalCh: log.Printf(&quot;[Start] task(%s) goroutine %d exit...&quot;, w.taskID, num) return case link, _ := &lt;-w.unVisitedLinks: foundLinks := crawl(link, w.depth, w.quitCh) go func() &#123; w.workList &lt;- foundLinks &#125;() &#125; &#125; &#125;(i) &#125; for &#123; select &#123; case list := &lt;-w.workList: // change taskStatus from resuming to running if w.status != config.TaskStatus.Running &#123; w.status = config.TaskStatus.Running &#125; for _, link := range list &#123; if !w.visited[link.url] &#123; w.visited[link.url] = true w.unVisitedLinks &lt;- link // write crawl result to file and update currDepth writer.TaskResultWriter(fmt.Sprintf(&quot;%s.txt&quot;, w.taskID), fmt.Sprintln(link.url)) if link.currDepth != w.currDepth &#123; w.currDepth = link.currDepth &#125; &#125; &#125; case &lt;-w.quitCh: log.Printf(&quot;[Start] task(%s) over than crawl depth, get quit signal and exit&quot;, w.taskID) w.statusCh &lt;- fmt.Sprintf(&quot;%s,%d&quot;, config.TaskStatus.Stopped, w.currDepth) close(w.stopSignalCh) delete(globalTask, w.taskID) return case &lt;-time.After(time.Duration(w.timeOut) * time.Second): if w.status == config.TaskStatus.Pausing || w.status == config.TaskStatus.Resuming &#123; continue &#125; else &#123; log.Printf(&quot;[Start] task(%s) execute timeout, get timeout signal and exit&quot;, w.taskID) w.statusCh &lt;- fmt.Sprintf(&quot;%s,%d&quot;, config.TaskStatus.Finished, w.currDepth) close(w.stopSignalCh) delete(globalTask, w.taskID) return &#125; &#125; &#125;&#125; 停止停止较为简单，直接向退出信号channel发送消息即可： 123func (w *WlcTask) StopHandler() &#123; w.quitCh &lt;- struct&#123;&#125;&#123;&#125;&#125; 暂停暂停的思路是将数据传输的channel赋值为nil，则相关的goroutine会阻塞进而整个执行暂停。 12345678910111213func (w *WlcTask) PauseHandler() &#123; if w.status == config.TaskStatus.Pausing &#123; log.Printf(&quot;[Pause] task(%s) is already pause, can&#x27;t pause again&quot;, w.taskID) return &#125; if w.status == config.TaskStatus.Stopped || w.status == config.TaskStatus.Finished &#123; log.Printf(&quot;[Pause] task(%s) is closed, can&#x27;t pause&quot;, w.taskID) return &#125; w.statusCh &lt;- fmt.Sprintf(&quot;%s,%d&quot;, config.TaskStatus.Pausing, w.currDepth) w.workList = nil log.Printf(&quot;[Pause] task(%s) is pausing&quot;, w.taskID)&#125; 恢复将之前备份好的数据channel重新赋值给当前使用的channel，则相关goroutine会接着运行。 123456789func (w *WlcTask) ResumingHandler() &#123; if w.status != config.TaskStatus.Pausing &#123; log.Printf(&quot;[Resume] task(%s) is not pausing, can&#x27;t resume&quot;, w.taskID) return &#125; w.workList = w.workListBak w.statusCh &lt;- fmt.Sprintf(&quot;%s,%d&quot;, config.TaskStatus.Resuming, w.currDepth) log.Printf(&quot;[Resume] task(%s) is resuming&quot;, w.taskID)&#125; 状态及结果获取状态获取： 123func (w *WlcTask) StatusHandler() (status string, currDepth int) &#123; return w.status, w.currDepth&#125; 结果获取： 12345678func ResultHandler(taskID string) (links []string, err error) &#123; f, err := ioutil.ReadFile(taskID + &quot;.txt&quot;) if err != nil &#123; return nil, err &#125; links = strings.Split(string(f), &quot;\\n&quot;) return links[:len(links)-1], nil&#125; 思考 本文使用的是channel控制整个流程，当换成标准库context时如何编写？ 路由的地方有重复性的地方，考虑如何优化？ 当前项目未自定义错误，如何完善整个项目的异常处理？","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"go语言实现爬虫(一)","slug":"go/个人项目实战：go语言实现爬虫(一)","date":"2021-09-06T11:47:11.000Z","updated":"2022-06-28T16:17:38.631Z","comments":true,"path":"2021/09/06/go/个人项目实战：go语言实现爬虫(一)/","link":"","permalink":"https://zcej.github.io/2021/09/06/go/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%EF%BC%9Ago%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E7%88%AC%E8%99%AB(%E4%B8%80)/","excerpt":"","text":"本项目适合在快速学习完go语言后的一个简单练手，主要达成以下功能： 能够递归的抓取网页链接，通过递归深度进行控制停止 支持爬取的并发控制，超时处理，以及其执行过程的暂停与恢复 基于gin提供restful的api接口，包括启动，停止，暂停，恢复，查看状态，获取结果等 提供grpc远程调用功能，并调研grpc-gateway，简单做一个学习案例 注：本文仅总结了重要的部分，还需不断进行完善，具体项目点击链接查看。 页面解析依赖模块golang.org/x/net/html，Extract函数向给定URL发起HTTP GET请求，解析HTML并返回HTML文档中存在的链接，如果要在此部分添加或删除规则，那么可以修改此函数。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263func Extract(url string) ([]string, error) &#123; resp, err := http.Get(url) if err != nil &#123; return nil, err &#125; if resp.StatusCode != http.StatusOK &#123; return nil, fmt.Errorf(&quot;getting %s: %s&quot;, url, resp.Status) &#125; doc, err := html.Parse(resp.Body) defer resp.Body.Close() if err != nil &#123; return nil, fmt.Errorf(&quot;parsing %s as HTML: %v&quot;, url, err) &#125; var links []string visitNode := func(n *html.Node) &#123; if n.Type == html.ElementNode &amp;&amp; n.Data == &quot;a&quot; &#123; for _, a := range n.Attr &#123; if a.Key != &quot;href&quot; &#123; continue &#125; link, err := resp.Request.URL.Parse(a.Val) if err != nil &#123; continue // ignore bad URLs &#125; links = append(links, link.String()) &#125; &#125; &#125; forEachNode(doc, visitNode, nil) //forEachNode(doc, startElement, endElement) return links, nil&#125;func forEachNode(n *html.Node, pre, post func(n *html.Node)) &#123; if pre != nil &#123; pre(n) &#125; for c := n.FirstChild; c != nil; c = c.NextSibling &#123; forEachNode(c, pre, post) &#125; if post != nil &#123; post(n) &#125;&#125;var depth intfunc startElement(n *html.Node) &#123; if n.Type == html.ElementNode &#123; fmt.Printf(&quot;%*s&lt;%s&gt;\\n&quot;, depth*2, &quot;&quot;, n.Data) depth++ &#125;&#125;func endElement(n *html.Node) &#123; if n.Type == html.ElementNode &#123; depth-- fmt.Printf(&quot;%*s&lt;/%s&gt;\\n&quot;, depth*2, &quot;&quot;, n.Data) &#125;&#125; 然后再根据广度优先遍历的思想新建一个函数breadthFirst，breadthFirst对每个worklist元素调用f，并将返回的内容添加到worklist中，对每一个元素，最多调用一次f。 123456789101112131415161718192021222324252627282930313233343536373839func breadthFirst(f func(item string) []string, worklist []string) &#123; seen := make(map[string]bool) for len(worklist) &gt; 0 &#123; items := worklist worklist = nil for _, item := range items &#123; if !seen[item] &#123; seen[item] = true worklist = append(worklist, f(item)...) &#125; &#125; &#125;&#125;func crawl(urlStr string) []string &#123; fmt.Println(urlStr) list, err := links.Extract(urlStr) if err != nil &#123; log.Print(err) &#125; //// extract same domain //var filterList []string //u, _ := url.Parse(urlStr) //for _, link := range list &#123; // l, _ := url.Parse(link) // if u.Hostname() == l.Hostname() &#123; // filterList = append(filterList, link) // &#125; //&#125; return list&#125;func main() &#123; urls := []string&#123;&quot;http://www.xxxx.com&quot;&#125; breadthFirst(crawl, urls)&#125; 并发控制在go语言中实现并发较为简单，只需要在函数定义前加上关键字go即可。对于爬虫而言，过高的并行度也不是一个好的做法，如何合理的控制并发速率也成为了当前需要控制的重点，下面介绍两种并发控制方式。 方式一利用有缓冲的channel控制并发，并灵活的通过一个计数器n来控制程序自动结束。 12345678910111213141516171819202122232425262728293031323334353637383940// tokens is a counting semaphore used to// enforce a limit of 20 concurrent requests.var tokens = make(chan struct&#123;&#125;, 20)func crawl(url string) []string &#123; fmt.Println(url) tokens &lt;- struct&#123;&#125;&#123;&#125; // acquire a token list, err := links.Extract(url) &lt;-tokens // release the token if err != nil &#123; log.Print(err) &#125; return list&#125;func main() &#123; worklist := make(chan []string) var n int url := &quot;http://www.xxxx.com&quot; // start n++ go func() &#123; worklist &lt;- []string&#123;url&#125; &#125;() // crawl the web concurrently visited := make(map[string]bool) for ; n &gt; 0; n-- &#123; list := &lt;-worklist for _, link := range list &#123; if !visited[link] &#123; visited[link] = true n++ go func(link string) &#123; worklist &lt;- crawl(link) &#125;(link) &#125; &#125; &#125;&#125; 方式二使用一定数量常驻goroutine控制并发，并在channel中没有数据后一定时间内超时退出。 123456789101112131415161718192021222324252627282930313233func main() &#123; worklist := make(chan []string) // lists of URLs, may have duplicates unseenLinks := make(chan string) // de-duplicated URLs // Add command-line arguments to worklist. go func() &#123; worklist &lt;- os.Args[1:] &#125;() // Create 20 crawler goroutines to fetch each unseen link. for i := 0; i &lt; 20; i++ &#123; go func() &#123; for link := range unseenLinks &#123; foundLinks := crawl(link) go func() &#123; worklist &lt;- foundLinks &#125;() &#125; &#125;() &#125; // The main goroutine de-duplicates worklist items // and sends the unseen ones to the crawlers. seen := make(map[string]bool) for &#123; select &#123; case list := &lt;-worklist &#123; for _, link := range list &#123; if !seen[link] &#123; seen[link] = true unseenLinks &lt;- link &#125; &#125; case &lt;- time.After(3 * time.Second) fmt.Println(&quot;Exit, timeout&quot;) return &#125; &#125;&#125; 递归深度要控制抓取的递归深度可以从crawl函数入手，将url进行封装，添加一个depth属性，当获取这个url的下一层链接时则对depth进行加一。另外还需添加一个信号控制channel，当递归层数满足要求时，发送信号控制程序退出。 123456789101112131415161718192021222324type work struct &#123; url string depth int&#125;func crawl(w work, quit chan struct&#123;&#125;) []work &#123; fmt.Printf(&quot;depth: %d, url: %s\\n&quot;, w.depth, w.url) if w.depth &gt; 3 &#123; quit &lt;- struct&#123;&#125;&#123;&#125; return nil &#125; urls, err := links.Extract(w.url) if err != nil &#123; log.Print(err) &#125; var works []work for _, url := range urls &#123; works = append(works, work&#123;url, w.depth + 1&#125;) &#125; return works&#125;","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"go语言中string和[]byte之间的转换","slug":"go/go语言中string和[]byte之间的转换","date":"2021-08-29T14:52:38.000Z","updated":"2022-06-28T16:22:22.880Z","comments":true,"path":"2021/08/29/go/go语言中string和[]byte之间的转换/","link":"","permalink":"https://zcej.github.io/2021/08/29/go/go%E8%AF%AD%E8%A8%80%E4%B8%ADstring%E5%92%8C[]byte%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BD%AC%E6%8D%A2/","excerpt":"","text":"在项目实际运用中发现数据量较大时，通过pprof进行性能分析发现string到byte的标准转换内存消耗十分大，后使用了unsafe包进行强转后性能有了很大的提升，在此记录下。 转换方式标准转换123456// string to []bytes1 := &quot;hello&quot;b := []byte(s1)// []byte to strings2 := string(b) 强转换1234567func string2bytes(s string) []byte &#123; return *(*[]byte)(unsafe.Pointer(&amp;s))&#125;func bytes2string(b []byte) string &#123; return *(*string)(unsafe.Pointer(&amp;b))&#125; 性能对比123456789101112131415161718192021222324252627func Benchmark_NormalString2Bytes(b *testing.B) &#123; x := &quot;Test Normal String 2 Bytes With Go!&quot; for i := 0; i &lt; b.N; i++ &#123; _ = []byte(x) &#125;&#125;func Benchmark_Bytes2String(b *testing.B) &#123; x := []byte(&quot;Test Unsafe Bytes 2 String With Go!&quot;) for i := 0; i &lt; b.N; i++ &#123; _ = bytes2string(x) &#125;&#125;func Benchmark_NormalString2Bytes(b *testing.B) &#123; x := &quot;Test Normal String 2 Bytes With Go!&quot; for i := 0; i &lt; b.N; i++ &#123; _ = []byte(x) &#125;&#125;func Benchmark_String2Bytes(b *testing.B) &#123; x := &quot;Test Normal String 2 Bytes With Go!&quot; for i := 0; i &lt; b.N; i++ &#123; _ = string2bytes(x) &#125;&#125; 测试结果如下： 123456789101112D:\\goproject\\study_go\\study_unsafe\\test_byte_string&gt;go test -bench=&quot;.&quot; -benchmemgoos: windowsgoarch: amd64pkg: study_go/study_unsafe/test_byte_stringcpu: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHzBenchmark_NormalBytes2String-12 43473496 28.20 ns/op 48 B/op 1 allocs/opBenchmark_Bytes2String-12 1000000000 0.2593 ns/op 0 B/op 0 allocs/opBenchmark_NormalString2Bytes-12 31570804 35.06 ns/op 48 B/op 1 allocs/opBenchmark_String2Bytes-12 1000000000 0.2626 ns/op 0 B/op 0 allocs/opPASSok study_go/study_unsafe/test_byte_string 4.436s 由上述可见，强转换性能明显优于标准转换 原理分析首先需要了解string和slice的底层数据结构： 12345678910type StringHeader struct &#123; Data uintptr Len int&#125;type SliceHeader struct &#123; Data uintptr Len int Cap int&#125; 在go中，任何类型的指针*T都可以转化为unsafe.Pointer类型的指针，它可以存储任何变量的地址 unsafe.Pointer类型的指针也可以转换回普通指针，而且不必和之前的类型*T相同 unsafe.Pointer类型还可以转换为uintptr类型，该类型保存了指针所指向地址的数值，从而可以对地址进行数值计算。 思考总结为什么强转换性能比标准转换好？ 对于标准转换，无论是从[]byte转string还是从string转[]byte都会涉及到底层数组的拷贝。而强转换是直接替换指针的指向，从而使得string和[]byte指向同一个底层数组。故后者的性能会更好 在上述测试中，当数据较大时，标准转换会有一次分配内存的操作，从而导致其性能更差，而为什么强转换不受影响？ 标准转换时，当数据长度大于32个字节时，需要通过mallocgc申请新的内存，之后再进行数据拷贝工作。而强转换只是更改指针的指向。故当数据较大时，两者性能差距越明显。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"go语言中的数据结构","slug":"go/go语言中的数据结构","date":"2021-08-21T15:01:04.000Z","updated":"2022-06-28T16:21:51.794Z","comments":true,"path":"2021/08/21/go/go语言中的数据结构/","link":"","permalink":"https://zcej.github.io/2021/08/21/go/go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","excerpt":"","text":"数组初始化12arr1 := [3]int&#123;1, 2, 3&#125; // 显示指定数组大小arr2 := [...]int&#123;1, 2 ,3&#125; // 使用[...]T声明数组 [...]T初始化数组的方式是go语言提供的一种语法糖，最终也会转化为具体元素数量 在不考虑逃逸分析的情况下，如果数组中元素个数小于等于4个，则所有的变量会直接在栈上初始化；反之如果数组元素大于4个，变量就会在静态存储去初始化然后拷贝到栈上。 访问和赋值 无论是在栈上还是静态存储区，数组在内存中都是一连串的内存空间。我们通过指向数组开头的指针、元素的数量以及元素类型占的空间大小表示数组。 数组和字符串的一些简单的越界错误都会在编译期间发现。如使用整数或常量访问数组，但是如果使用变量去访问数组或字符串时，编译器就无法提前发现错误，此时会在运行时阻止不合法的访问。小结对数组的访问和赋值同时需要依赖编译器和运行时支持，其大多数操作在编译期间都会转换成直接读写内存，在中间代码生成期间，编译器还会插入运行时方法runtime.panicIndex防止发生越界错误。切片数据结构切片在运行时由reflect.SliceHeader结构体表示，如下：12345type SliceHeader struct &#123; Data uintptr // 指向数组的指针 Len int // 当前切片的长度 Cap int // 当前切片的容量, 即Data数组的大小&#125; 初始化有以下三种初始化切片的方式：12345678// 1. 通过下标的方式获得数组或切片的一部分arr[0:3] or slice[0:3]// 2. 使用字面量初始化新的切片slice := []int&#123;1, 2, 3&#125;// 3. 使用make关键字slice := make([]int, 10) 使用下标：使用下标初始化切片不会拷贝原数组或原切片中的数据，它只会创建一个指向原数组的切片结构体，所以修改新切片的数据也会修改原切片。 使用字面量：根据切片中的元素数量对底层数组的大小进行推断并创建一个数组，将字面量元素存储到初始化的数组中，创建一个同样指向相同类型的数组指针，将初始化的数组赋值给指针所在的地址，通过[:]操作获取一个底层使用该地址的切片。 访问元素切片的操作基本都是在编译期间完成的，除了访问切片的长度、容量或者其中的元素之外，编译期间也会将包含range关键字的遍历转换成形式更简单的循环。 追加和扩容当切片容量不足时，会调用runtime.growslice进行切片扩容。扩容是为切片分配新的内存空间并拷贝原切片中元素的过程，那么新切片的容量如何确定呢？ 如果期望容量大于当前容量的两倍就会使用当前容量 如果当前切片的长度小于1024就会将容量翻倍 如果当前切片的长度大于1024就会每次增加25%的容量，直到新容量大于期望容量 另外上述调用仅会确定切片的大致容量，还需要根据切片中的元素大小进行内存对齐。 拷贝切片无论是编译期间拷贝还是运行时拷贝，两种拷贝方式都会通过runtime.memmove将整块内存的内容拷贝到目标的内存区域中，相比于依次拷贝元素，runtime.memmove能提供更好的性能。 小结切片的很多功能都是由运行时实现的，无论是初始化切片，还是对切片进行追加或扩容都需要运行时的支持，需要注意的是在遇到大切片扩容或者复制时可能会发生大规模的内存拷贝，一定要减少类似的操作避免影响程序的性能。 字典哈希冲突开放寻址法拉链法 数据结构go语言运行时使用了多个数据结构组合表示哈希表，最核心的结构体runtime.hmap如下所示： 12345678910111213141516171819type hmap struct &#123; count int // 表示当前哈希表中的元素数量 flags uint8 B uint8 // 表示当前哈希表持有的buckets数量(都是2的倍数) noverflow uint16 hash0 uint32 // 哈希种子，为哈希函数的结果引入随机性 buckets unsafe.Pointer oldbuckets unsafe.Pointer // 扩容时用于保存之前buckets字段 nevacuate uintptr extra *mapextra&#125;type mapextra struct &#123; overflow *[]*bmap oldoverflow *[]*bmap nextOverflow *bmap&#125; 如上所示哈希表runtime.hmap的桶是runtime.bmap，每一个runtime.bmap都能存储8个键值对。当哈希表中存储的数据过多，单个桶已经装满时就会使用extra.nextOverflow中桶存储溢出的数据。这两种不同的桶在内存中都是连续的，分别称之为正常桶和溢出桶 初始化字面量 12345hash := map[string]int&#123; &quot;1&quot;: 2, &quot;2&quot;: 4, &quot;5&quot;: 6,&#125; 使用字面量初始化的过程都会使用go语言中的关键字make来创建新的哈希并通过最原始的[]语法向哈希追加元素，另外最终都是调用runtime.makemap。 读写操作扩容在以下两种情况下会进行扩容： 装载因子已经超过6.5 哈希使用了太多溢出桶 小结 go语言使用了拉链法来解决哈希碰撞的问题实现了哈希表，它的读写等操作都是在编译期间转换成了运行时的函数或方法。哈希在每一个桶中存储键对应哈希的前8位，当对哈希进行操作时，这些tophash就成为可以帮助哈希快速遍历桶中元素的缓存。 哈希表的每个桶都只能存储8个键值对，一旦当前哈希的某个桶超出8个，新的键值对就会存储到哈希的溢出桶中。随着键值对数量的增加，溢出桶的数量和哈希的装载因子也会逐渐升高，超过一定范围就会触发扩容，扩容会将桶的数量翻倍，元素再分配的过程也是在调用写操作时增量进行的，不会造成性能的瞬时巨大抖动。字符串数据结构字符串在运行时会使用如下的reflect.StringHeader表示：1234type StringHeader struct &#123; Data uintptr // 指向字节数组的指针 Len int // 数组的大小&#125; 字符串是只读的类型，我们并不会直接向字符串追加元素改变其本身的内存空间，所有字符串上的写入操作都是通过拷贝实现的。 解析过程1234str1 := &quot;this is a string&quot;str2 := `this is anotherstring` 类型转换 当解析和序列化json等数据格式时，经常需要将数据在string和[]byte之间来回转换，而类型转换的开销并没有想象的那么小。 字符串和[]byte中的内容虽然一样，但是字符串的内容是只读的，我们不能通过下标或者其他形式改变其中的数据，而跑[]byte中的内容是可读写的。不过无论从哪种类型转换到另一种都需要拷贝数据，而内存拷贝的性能损耗会随着字符串和[]byte长度的增长而增长。小结字符串作为只读的数据类型，我们无法改变其本身的结构，但是在做拼接和类型转换等操作时一定要注意性能的损耗，遇到需要极致性能的场景一定要尽量减少类型转换的次数。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"go语言中make和new的区别","slug":"go/go语言中make和new的区别","date":"2021-08-03T13:11:27.000Z","updated":"2022-05-23T01:08:55.098Z","comments":true,"path":"2021/08/03/go/go语言中make和new的区别/","link":"","permalink":"https://zcej.github.io/2021/08/03/go/go%E8%AF%AD%E8%A8%80%E4%B8%ADmake%E5%92%8Cnew%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"make用于初始化内置的数据结构，如slice，map，channel new的作用是根据传入的类型分配一片内存空间并返回指向这片内存空间的指针123slice := make([]int, 0, 100)hash := make(map[int]bool, 10)ch := make(chan int, 5) slice是一个包含data，cap和len的结构体reflect.SliceHeader hash是一个指向runtime.hmap结构体的指针 ch是一个指向runtime.hchan结构体的指针 1234i := new(int)var v inti := &amp;v 上述代码片段两种初始化方法是等价的，它们都会创建一个指向int零值的指针 make在编译期间的类型检查阶段，go语言会将代表make关键字的OMAKE节点根据参数类型的不同转换成了OMAKESLICE、OMAKEMAP和OMAKECHAN三种不同类型的节点，这些节点会调用不同的运行时函数来初始化相应的数据结构。 new编译器会在中间代码生成阶段通过以下两个函数处理该关键字： cmd/compile/internal/gc.callnew会将关键字转换成ONEWOBJ类型的节点 cmd/complie/internal/gc.state.expr会根据申请空间的大小分两种情况处理 如果申请的空间为0，就会返回一个表示空指针的zerobase变量 在遇到其他情况时会将关键字转换成runtime.newobject函数小结简单总结一下go语言中make和new关键字的实现原理，make关键字的作用是创建切片、哈希表和Channel等内置的数据结构，而new的作用是为类型申请一片内存空间，并返回指向这片内存的指针。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"在Django中使用缓存","slug":"django/在Django中使用缓存","date":"2020-08-16T04:19:21.000Z","updated":"2022-06-28T16:26:28.416Z","comments":true,"path":"2020/08/16/django/在Django中使用缓存/","link":"","permalink":"https://zcej.github.io/2020/08/16/django/%E5%9C%A8Django%E4%B8%AD%E4%BD%BF%E7%94%A8%E7%BC%93%E5%AD%98/","excerpt":"","text":"快速开始缓存是什么(What?) 缓存就是数据交换的缓冲区(称作Cache)，是存储数据的临时地方。当用户查询数据，首先在缓存中寻找，如果找到了则直接执行。如果找不到，则去数据库查找。 缓存的本质就是用空间换时间，牺牲数据的实时性，以服务器内存中的数据暂时代替从数据库读取的数据，减少数据库IO，减轻服务器压力，减少网络延迟，加快页面打开速度。 存储介质访问速度比较 来自Google工程师Jeff Dean的分享，仅供参考： 存储介质 速度 L1 cache reference 读取CPU的一级缓存 0.5 ns Branch mispredict(转移、分支预测) 5 ns L2 cache reference 读取CPU的二级缓存 7 ns Mutex lock&#x2F;unlock 互斥锁\\解锁 100 ns Main memory reference 读取内存数据 100 ns Compress 1K bytes with Zippy 1k字节压缩 10,000 ns Send 2K bytes over 1 Gbps network 在1Gbps的网络上发送2k字节 20,000 ns Read 1 MB sequentially from memory 从内存顺序读取1MB 250,000 ns Round trip within same datacenter 从一个数据中心往返一次，ping一下 500,000 ns Disk seek 磁盘搜索 10,000,000 ns Read 1 MB sequentially from network从网络上顺序读取1兆的数据 10,000,000 ns Read 1 MB sequentially from disk 从磁盘里面读出1MB 30,000,000 ns Send packet CA-&gt;Netherlands-&gt;CA 一个包的一次远程访问 150,000,000 ns 访问流程： 1234567graph TBA(读操作_) --&gt; B&#123;查询缓存_&#125;B --&gt; |有缓存_| C[返回_]B --&gt; |无缓存_| D[查询数据库_]D --&gt; E[放入缓存_] 缓存的优点: 减少了磁盘和网络IO来提高吞吐量，减少计算量(CPU计算)释放CPU，提高系统的响应速度。 面向切面的处理发出，可以在各层进行插拔，是所有性能优化的最简单有效的解决方案。 缓存应用场景(Where?) 对于数据实时性要求不高对于一些经常访问但是很少改变的数据，读明显多于写，使用缓存就很有必要。比如一些网站配置项。 对于性能要求高比如一些秒杀活动场景。 基于DRF快速开始(How?)pip install drf-extensions key值计算: {“view_instance”: “”, “view_method”: “”, “request”:””, “args”:””, “kwargs”: “”} –&gt; json –&gt; md5\\rest_framework_extensions\\key_constructor\\constructors.py 123456789101112131415161718192021222324252627282930313233343536373839404142# settings.py REST_FRAMEWORK_EXTENSIONS = &#123; &#x27;DEFAULT_OBJECT_CACHE_KEY_FUNC&#x27;: &#x27;rest_framework_extensions.utils.default_object_cache_key_func&#x27;, &#x27;DEFAULT_LIST_CACHE_KEY_FUNC&#x27;: &#x27;rest_framework_extensions.utils.default_list_cache_key_func&#x27;, &#x27;DEFAULT_CACHE_RESPONSE_TIMEOUT&#x27;: 60 * 15, &#x27;DEFAULT_CACHE_ERRORS&#x27;: False &#125; # views.py # usage 1: don&#x27;t overwirte list, retrieve method from rest_framework_extensions.cache.mixins import CacheResponseMixin class StudentViewSet(CacheResponseMixin, viewsets.ModelViewSet): pass # usage: 2 from rest_framework_extensions.cache.decorators import cache_response from rest_framework_extensions.utils import default_object_cache_key_func class StudentViewSet(CacheResponseMixin, viewsets.ModelViewSet): @cache_response(key_func=default_object_cache_key_func, cache_errors=False) def retrieve(self, request, *args, **kwargs): pass ``` &gt; python自带的缓存机制```pythonimport timeitfrom functools import lru_cache# @lru_cache(None)def fib(n): if n &lt; 2: return n return fib(n - 2) + fib(n - 1) print(timeit.timeit(lambda: fib(35), number=1)) 一、缓存类型1. 数据库缓存 常用的缓存方案有memcached、redis等 。把经常要从数据库查询的数据，或经常更新的数据放入到缓存中。这样下次查询时，直接从缓存直接返回，减轻数据库压力，提升数据库性能。 2. 服务器端缓存2.1 代理服务器缓存 代理服务器是浏览器和源服务器之间的中间服务器，浏览器先向这个中间服务器发起Web请求，经过处理后(比如权限验证，缓存匹配等)，再将请求转发到源服务器。 代理服务器缓存的运作原理跟浏览器的运作原理差不多，只是规模更大。可以把它理解为一个共享缓存，不只为一个用户服务，一般为大量用户提供服务，因此在减少响应时间和带宽使用方面很有效，同一个副本会被重用多次。 2.2 CDN缓存 也叫网关缓存、反向代理缓存。CDN缓存一般是由网站管理员自己部署，为了让他们的网站更容易扩展并获得更好的性能。 浏览器先向CDN网关发起Web请求，网关服务器后面对应着一台或多台负载均衡源服务器，会根据它们的负载请求，动态将请求转发到合适的源服务器上。 虽然这种架构负载均衡源服务器之间的缓存没法共享，但却拥有更好的处扩展性。从浏览器角度来看，整个CDN就是一个源服务器。 2.3 DNS缓存 万维网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。DNS协议运行在UDP协议之上，使用端口号53。 有dns的地方,就有缓存。浏览器、操作系统、Local DNS、根域名服务器，它们都会对DNS结果做一定程度的缓存。 DNS查询过程如下: 首先搜索浏览器自身的DNS缓存,如果存在，则域名解析到此完成。 如果浏览器自身的缓存里面没有找到对应的条目，那么会尝试读取操作系统的hosts文件看是否存在对应的映射关系,如果存在，则域名解析到此完成。 如果本地hosts文件不存在映射关系，则查找本地DNS服务器(ISP服务器,或者自己手动设置的DNS服务器),如果存在,域名到此解析完成。 如果本地DNS服务器还没找到的话,它就会向根服务器发出请求,进行递归查询。 3. 浏览器缓存 浏览器缓存根据一套与服务器约定的规则进行工作，在同一个会话过程中会检查一次并确定缓存的副本足够新。如果在浏览过程中前进或后退时访问到同一个图片，这些图片可以从浏览器缓存中调出而即时显示。 4. web应用层缓存 应用层缓存指的是从代码层面上，通过代码逻辑和缓存策略，实现对数据、页面、图片等资源的缓存，可以根据实际情况选择将数据存在文件系统或者内存中，减少数据库查询或者读写瓶颈，提高响应效率。 二、缓存淘汰策略1. FIFOFIFO (First in First out)， 先进先出。核心原则就是: 如果一个数据最先进入缓存中，则应最早淘汰掉。 2. LFULFU (Least Frequently Used)，最不频繁使用，以使用次数作为参考。 核心思想：如果数据过去被访问多次，那么将来被访问的几率也更高。 3. LRULRU(Least Recently Used)，最近最少使用，以时间作为参考。 核心思想：如果数据最近被访问过，那么将来被访问的频率也更高 三、Django缓存系统伪代码解释动态网站生成页面时，缓存是怎么工作的 123456789101112131415161718192021222324given a URL, try finding that page in the cache if the page is in the cache: return the cached page else: generate the page save the generated page in the cache (for next time) return the generated page ``` ## 设置缓存 ### django-redis - 更多详细配置参阅[官方文档](https://github.com/jazzband/django-redis)- `pip install django-redis` ```pythonCACHES = &#123; &quot;default&quot;: &#123; &quot;BACKEND&quot;: &quot;django_redis.cache.RedisCache&quot;, &quot;LOCATION&quot;: &quot;redis://127.0.0.1:6379/1&quot;, # &quot;LOCATION&quot;: &quot;redis://username:password@localhost:6379/0&quot; &quot;OPTIONS&quot;: &#123; &quot;CLIENT_CLASS&quot;: &quot;django_redis.client.DefaultClient&quot;, &#125; &#125;&#125; memcached 完全基于内存的缓存服务器： 是Django支持的最快，最高效的缓存类型。—&gt; Facebook，Wikipedia都有使用其来减少数据库访问并显著提高网站性能缓存的数据存储在内存中，如果服务器崩溃，那么数据将会丢失。 pip install python-memached pip install pylibmc 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115# use python-memcached CACHES = &#123; &#x27;default&#x27;: &#123; &#x27;BACKEND&#x27;: &#x27;django.core.cache.backends.memcached.MemcachedCache&#x27;, &#x27;LOCATION&#x27;: &#x27;127.0.0.1:11211&#x27;, # &#x27;LOCATION&#x27;: &#x27;unix:/tmp/memcached.sock&#x27;, # 能在多个服务器上共享缓存，即无需再每台机器上复制缓存值 # &#x27;LOCATION&#x27;: [ # &#x27;172.19.26.240:11211&#x27;, # &#x27;172.19.26.242:11211&#x27;, # ] &#125; &#125; # use pylibmc CACHES = &#123; &#x27;default&#x27;: &#123; &#x27;BACKEND&#x27;: &#x27;django.core.cache.backends.memcached.PyLibMCCache&#x27;, &#x27;LOCATION&#x27;: &#x27;/tmp/memcached.sock&#x27;, &#125; &#125; ``` ### 数据库缓存 - 适用于有一个快速，索引正常的数据库服务器。 - `python manage.py createcachetable` ```python CACHES = &#123; &#x27;default&#x27;: &#123; &#x27;BACKEND&#x27;: &#x27;django.core.cache.backends.db.DatabaseCache&#x27;, &#x27;LOCATION&#x27;: &#x27;my_cache_table&#x27;, &#125; &#125; ``` ### 文件系统缓存 - 一个缓存值为一个单独的文件 - 注意指定目的写权限问题。 ```python CACHES = &#123; &#x27;default&#x27;: &#123; &#x27;BACKEND&#x27;: &#x27;django.core.cache.backends.filebased.FileBasedCache&#x27;, &#x27;LOCATION&#x27;: &#x27;/var/tmp/django_cache&#x27;, # &#x27;LOCATION&#x27;: &#x27;c:/foo/bar&#x27;, &#125; &#125; ``` ### 本地内存缓存 - 是默认的缓存方式 - 使用LRU淘汰策略 &gt; 每个进程都有其自己的私有缓存实例，意味着不存在跨进程的缓存。 &gt; 也意味着本地缓存不是特别节省内存，不是生产环境的好选择，但在开发环境表现很好。 ```python CACHES = &#123; &#x27;default&#x27;: &#123; &#x27;BACKEND&#x27;: &#x27;django.core.cache.backends.locmem.LocMemCache&#x27;, &#x27;LOCATION&#x27;: &#x27;unique-snowflake&#x27;, &#125; &#125; ``` ### 虚拟缓存(用于开发模式) - 只是实现了缓存接口，并不做其他操作 - 如果你有一个正式网站在不同地方使用了重型缓存，但你不想在开发环境使用缓存时非常有用。 ```python CACHES = &#123; &#x27;default&#x27;: &#123; &#x27;BACKEND&#x27;: &#x27;django.core.cache.backends.dummy.DummyCache&#x27;, &#125; &#125; ``` ### 缓存参数 - **`TIMEOUT`**: 超时时间，默认为300秒。设置为`None`表示永不过时。 - **`OPTIONS`**: 实现自有的淘汰策略的缓存后端（比如 `locmem`, `filesystem` 和 `database` 后端）将遵循以下选项 -- **`MAX_ENTRIES`**: 允许缓存的最大条目， 默认为300。 -- **`CULL_FREQUENCY`**: 当达到最大条目时淘汰的条目数量，默认为3。比率为1 / CULL_FREQUENCY，为0是清空整个缓存。 - **`KEY_PREFIX`**: Django 服务器使用的所有缓存键的字符串。 - **`VERSION`**: 通过 Django 服务器生成的缓存键的默认版本号。 - **`KEY_FUNCTION`**: 一个包含指向函数的路径的字符串，该函数定义将如何前缀、版本和键组成最终的缓存键。 ## 站点缓存 ```python MIDDLEWARE = [ &#x27;django.middleware.cache.UpdateCacheMiddleware&#x27;, &#x27;django.middleware.common.CommonMiddleware&#x27;, &#x27;django.middleware.cache.FetchFromCacheMiddleware&#x27;, ] ``` ## 视图缓存 &gt; **cache_page**设置的缓存超时优先于Cache-Control头中的&quot;max_age&quot;&gt; 和缓存站点一样，对试图缓存以URL为键。如果多个URL指向相同的试图，每个URL将被单独缓存。```python from django.views.decorators.cache import cache_page @cache_page(60 * 15, cache=&quot;default&quot;, key_frefix=&quot;site1&quot;) def my_view(request): pass ``` ## 底层缓存API &gt; 以任意级别粒度在缓存中存储对象，如：模型对象的字符串、字典、列表，或者其他(pickle)。### 访问缓存&gt; 可通过`django.core.cache.caches`对象访问在CACHES配置的缓存。&gt; 重复请求同一个线程里的同一个别名将返回同一个对象。```pythonfrom django.core.cache import cachescache1 = caches[&#x27;myalias&#x27;]cache2 = caches[&#x27;myalias&#x27;]cache1 is cache2 # True 作为快捷方式，默认缓存可以通过django.core.cache.cache引用。等价于caches[&#39;default&#39;] 基本用法 cache.set(key, value, timeout&#x3D;DEFAULT_TIMEOUT, version&#x3D;None) cache.get(key, default&#x3D;None, version&#x3D;None) cache.add(key, value, timeout&#x3D;DEFAULT_TIMEOUT, version&#x3D;None) cache.get_or_set(key, default, timeout&#x3D;DEFAULT_TIMEOUT, version&#x3D;None) cache.get_many(keys, version&#x3D;None) cache.set_many(dict, timeout) cache.delete(key, version&#x3D;None) cache.delete_many(keys, version&#x3D;None) cache.clear() cache.touch(key, timeout&#x3D;DEFAULT_TIMEOUT, version&#x3D;None) 12345678# delete cachefrom django.core.cache import cachefrom django.utils.cache import get_cache_keyclass StudentViewSet(CacheResponseMixin, BaseModelViewSet): def update(self, request, *args, **kwargs): cache.delete(get_cache_key(request)) 下游缓存略 使用Vary标头略 四、常用的缓存组件1. Memcache详见另一篇笔记。 启动命令：memcached -d -m 10m -p 11211 -u root缓存过期策略：当内存容量达到指定值之后，就会基于LRU算法自动删除不使用的缓存。 2. Redis详见另一篇笔记。缓存过期策略： # MAXMEMORY POLICY: how Redis will select what to remove when maxmemory # is reached. You can select one from the following behaviors: # volatile-lru -&gt; Evict using approximated LRU, only keys with an expire set. # allkeys-lru -&gt; Evict any key using approximated LRU. # volatile-lfu -&gt; Evict using approximated LFU, only keys with an expire set. # allkeys-lfu -&gt; Evict any key using approximated LFU. # volatile-random -&gt; Remove a random key having an expire set. # allkeys-random -&gt; Remove a random key, any key. # volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL) # noeviction -&gt; Don&#39;t evict anything, just return an error on write operations. # # LRU means Least Recently Used # LFU means Least Frequently Used # # Both LRU, LFU and volatile-ttl are implemented using approximated # randomized algorithms. # # Note: with any of the above policies, Redis will return an error on write # operations, when there are no suitable keys for eviction. # # At the date of writing these commands are: set setnx setex append # incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd # sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby # zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby # getset mset msetnx exec sort # # The default is: # # maxmemory-policy noeviction Redis过期机制参考 五、缓存带来的问题1. 数据一致性 产生原因： ①先删除缓存：在写数据库之前，如果有读请求发生，可能导致旧数据入缓存， 引发数据不一致。②先修改数据库： a.在有缓存的情况下，两个并发的读写操作。写操作在删除缓存的时候，缓存删除失败，读操作此时读到的数据是老数据，引发数据不一致。(此处考虑是删除缓存还是更新缓存)b.在没有缓存的情况下，两个并发的读写操作。读操作没有及时的把数据放入缓存，写操作进来修改了数据库，删除了缓存，然后读操作恢复，把老数据写进了缓存。 解决方案： 延迟双删–&gt;改进–&gt;内存队列删除缓存(如果删除缓存失败，可以多次尝试)考虑到系统复杂度，一般情况下先修改数据库，后删除缓存就行。 2. 缓存击穿 产生原因： 针对某一key，该缓存在某一时间点过期的时候，刚好有对应这个key的大量并发请求过来，此时请求会直接走到数据库，可能回导致数据库崩溃。 解决方案： **①使用互斥锁(mutex key)**：使用zookeeper或者Redis实现互斥锁，等待第一个请求创建完缓存之后才允许后续请求继续访问。**②”数据永不过期”**：在value的内部设置一个超时值(timeout1)，timeout1比实际的超时时间小。当从缓存读取到timeout1发现其已经过期时，马上延迟timeout1并重新设置到缓存。然后再从数据库加载数据并这是到缓存中。 3. 缓存穿透 产生原因： 由于缓存是不命中时被动写的，且出于容错考虑，如果从数据库查不到数据就不写入缓存，当数据库中本来就不存在的数据一直被请求，在流量大时，数据库可能就会崩溃。 解决方案: ①请求校验：对请求url进行校验，有可能是恶意攻击。②使用布隆过滤器：将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层数据库的查询压力。③对空结果进行缓存：如果查询一个数据返回为空(不管是数据不存在还是系统故障)，仍然将这个空结果进行缓存，但需要设置过期时间。 4. 缓存雪崩 产生原因： 由于设置缓存时采用了相同的过期时间(或者服务器宕机)，导致缓存在某一时刻同时失效，请求全部转发到数据库，数据库瞬间压力过重而导致崩溃。 解决方案： ①将过期时间分散：在过期时间后面加上一个随机数，让key均匀的失效。②使用队列或锁控制：用队列或者锁让程序执行在压力范围之内，当然这种方案可能会影响并发量。③配置redis高可用，服务降级，缓存数据持久化","categories":[{"name":"django","slug":"django","permalink":"https://zcej.github.io/categories/django/"}],"tags":[]},{"title":"pyenv的使用","slug":"python/pyenv的使用","date":"2020-07-29T10:02:49.000Z","updated":"2022-05-23T08:42:48.553Z","comments":true,"path":"2020/07/29/python/pyenv的使用/","link":"","permalink":"https://zcej.github.io/2020/07/29/python/pyenv%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"pyenv安装(ubuntu)1. 拉取源代码git clone https://github.com/pyenv/pyenv.git ~/.pyenv 2. 定义环境变量1234echo &#x27;export PYENV_ROOT=&quot;$HOME/.pyenv&quot;&#x27; &gt;&gt; ~/.bashrcecho &#x27;export PATH=&quot;PYENV_ROOT/bin:$PATH&quot;&#x27; &gt;&gt; ~/.bashrcecho -e &#x27;if command -v pyenv 1&gt;/dev/null 2&gt;&amp;1;then\\n eval &quot;$(pyenv init -)&quot;\\nfi&#x27; &gt;&gt; ~/.bashrcsource /root/.bashrc 3. 安装python编译依赖1234sudo apt-get install -y build-essential libbz2-dev libssl-dev libreadline-dev libsqlite3-dev tk-dev libffi-dev# for Numpy,Matplotlibb,Scipy,etc.sudo apt-get install -y libpng-dev libfreetype6-dev python安装1. 修改镜像源export PYTHON_BUILD_MIRROR_URL=&quot;https://mirrors.huaweicloud.com&quot; 2. 安装指定版本123# 镜像源没用的话，提前下载好tar.xz包pyenv install 3.9.0 插件pyenv-virtualenv安装1. 下载插件到指定文件夹git clone https://github.com/pyenv/pyenv-virtualenv.git /root/.pyenv/plugins/pyenv-virtualenv 2. 添加到环境变量echo &#39;eval &quot;$(pyenv virtualenv-init-)&quot;&#39; &gt;&gt; ~/.bash_profile 3. 创建虚拟环境pyenv virtualenv 3.9.0 venvFirmadyne 4. 重启shell使其生效exec &quot;$SHELL&quot; 5. 激活及退出虚拟环境12pyenv activate venvFirmadynepyenv deactivate 6. 删除虚拟环境rm -rf /root/.pyenv/version/3.9.0/envs/venvFirmadyne pip源更换123456vim /root/.pip/pip.conf[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple[install]trusted-host = pypi.tuna.tsinghua.edu.cn 图片插入示例","categories":[{"name":"python","slug":"python","permalink":"https://zcej.github.io/categories/python/"}],"tags":[]},{"title":"python协程的相关总结","slug":"python/python协程的相关总结","date":"2020-07-26T11:35:21.000Z","updated":"2022-06-28T16:27:09.611Z","comments":true,"path":"2020/07/26/python/python协程的相关总结/","link":"","permalink":"https://zcej.github.io/2020/07/26/python/python%E5%8D%8F%E7%A8%8B%E7%9A%84%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93/","excerpt":"","text":"生成器可迭代对象、迭代器、生成器 可迭代对象：实现了方法__iter__或__getitem__就是可迭代的。 迭代器：在可迭代对象的基础上实现了__next__方法，__iter__方法需返回一个迭代器，如果自身是迭代器则返回self。 生成器：可以理解为在迭代器的基础上再实现了yield，yield返回新的值后，会在当前位置阻塞，等待下一次的调用。 如何激活生成器 next() generator.send(None) 生成器的执行状态 GEN_CREATED GEN_RUNNING GEN_SUSPENDED GEN_CLOSED 生成器的异常处理当生成器不满足生成元素的条件时，就应该抛出异常StopIteration 从生成器过度到协程 协程是为非抢占式多任务产生子程序的计算机程序组件，协程允许不同入口点在不同位置暂停或开始执行程序。 如何向生成器中发送消息： 12345678910111213141516def jumping_range(N): index = 0 while index &lt; N: # 通过send()发送的消息将赋值给jump jump = yield index if jump is None: jump += 1 index += jumpif __name__ == &#x27;__main__&#x27;: itr = jumping_range(5) print(next(itr)) # 0 print(itr.send(2)) # 2 print(next(itr)) # 3 print(itr.send(-1)) # 2 重点在于jump = yield index yield index 是将index return给外部调用程序 jump = yield 是可以接收外部程序通过send()发送的信息，并赋值给jump yield from 语法为什么要使用协程如果没有协程，要去实现一个并发程序，可能会有以下问题 使用最常规的同步编程要实现异步并发效果并不理想，或者难度极高 由于GIL锁的存在，多线程的运行需要频繁的加锁解锁，切换线程，这极大的降低了并发性能 而协程的出现，刚好可以解决以上的问题，它的特点有 协程是在单线程里实现任务的切换的 利用同步的方式去实现异步 不再需要锁，提高了并发性能 yield from用法详解yield from 是在python3.3才出现的语法。这个特性是在python2中没有的。yield from 后面是需要加可迭代对象，它可以普通的可迭代对象，也可以是迭代器，甚至是生成器。 1234567891011121314151617# usage: yielddef gen_1(*args, **kwargs): for item in args: for i in item: yield idef gen_2(*args, **kwargs): for item in args: yield from itemstr_1 = &quot;test&quot;list_1 = [1, 2, 3]ret_1 = gen_1(str_1, list_1)ret_2 = gen_2(str_1, list_1)# [&#x27;t&#x27;, &#x27;e&#x27;, &#x27;s&#x27;, &#x27;t&#x27;, 1, 2, 3] 生成器嵌套 调用方：调用委托生成器的客户端代码 委托生成器：包含yield from的表达式生成器函数 子生成器：yield from 后面加的生成器函数","categories":[{"name":"python","slug":"python","permalink":"https://zcej.github.io/categories/python/"}],"tags":[]}],"categories":[{"name":"python","slug":"python","permalink":"https://zcej.github.io/categories/python/"},{"name":"爬虫","slug":"python/爬虫","permalink":"https://zcej.github.io/categories/python/%E7%88%AC%E8%99%AB/"},{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"},{"name":"项目实战","slug":"go/项目实战","permalink":"https://zcej.github.io/categories/go/%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"},{"name":"django","slug":"django","permalink":"https://zcej.github.io/categories/django/"}],"tags":[]}