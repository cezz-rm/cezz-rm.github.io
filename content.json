{"meta":{"title":"Hexo","subtitle":"","description":"","author":"CeJ","url":"https://zcej.github.io","root":"/"},"pages":[{"title":"书单","date":"2022-05-23T01:25:50.000Z","updated":"2022-05-23T01:26:28.458Z","comments":false,"path":"books/index.html","permalink":"https://zcej.github.io/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2022-04-10T06:46:53.000Z","updated":"2022-04-10T06:49:32.991Z","comments":false,"path":"categories/index.html","permalink":"https://zcej.github.io/categories/index.html","excerpt":"","text":""},{"title":"关于","date":"2022-05-23T01:27:43.000Z","updated":"2022-05-23T03:29:43.790Z","comments":false,"path":"about/index.html","permalink":"https://zcej.github.io/about/index.html","excerpt":"","text":"12345678910111213141516171819202122232425262728293031323334353637&#123; &quot;name&quot;: &quot;CeJ&quot;, &quot;age&quot;: 27, &quot;gender&quot;: &quot;man&quot;, &quot;profression&quot;: &quot;python &amp; go Developer&quot;, &quot;experience&quot;: &quot;4 years&quot;, &quot;address&quot;: &quot;BeiJing&quot;, &quot;education&quot;: &quot;Southwest Jiaotong University&quot;, &quot;major&quot;: &quot;mechanical design, manufacturing and automation&quot;, &quot;github&quot;: &quot;https://github.com/zcej&quot;, &quot;description&quot;: &quot;faithful to your heart, fruitful to your result&quot;, &quot;skills&quot;: [ [&quot;HTML5&quot;, &quot;javascript&quot;, &quot;jquery&quot;, &quot;css&quot;], [&quot;python&quot;, &quot;go&quot;], [&quot;django&quot;, &quot;flask&quot;, &quot;gin&quot;, &quot;grpc&quot;, &quot;vue&quot;], [&quot;mysql&quot;, &quot;redis&quot;, &quot;mongodb&quot;], [&quot;linux&quot;, &quot;shell&quot;], [&quot;rabbitmq&quot;], [&quot;git&quot;, &quot;svn&quot;], [&quot;docker&quot;, &quot;kubernetes&quot;], ], &quot;devTools&quot;: [ [&quot;pycharm&quot;, &quot;goland&quot;, &quot;webstorm&quot;], [&quot;sublime&quot;, &quot;nptepad++&quot;], [&quot;chrome&quot;, &quot;fiddler&quot;], [&quot;navicat&quot;], [&quot;mobaxterm&quot;], [&quot;snipaste&quot;, &quot;faststone&quot;, &quot;processon&quot;], ], &quot;hobby&quot;: &#123; &quot;sports&quot;: [&quot;ping-pong&quot;, &quot;badminton&quot;], &quot;animation&quot;: [&quot;one piece&quot;, &quot;naruto&quot;, &quot;black&quot;] &#125;&#125;"},{"title":"友链","date":"2022-05-23T01:26:49.000Z","updated":"2022-05-23T01:27:19.285Z","comments":false,"path":"links/index.html","permalink":"https://zcej.github.io/links/index.html","excerpt":"","text":""},{"title":"tags","date":"2022-05-23T01:21:14.000Z","updated":"2022-05-23T01:22:32.583Z","comments":false,"path":"tags/index.html","permalink":"https://zcej.github.io/tags/index.html","excerpt":"","text":""},{"title":"项目","date":"2022-05-23T01:24:19.000Z","updated":"2022-05-23T01:25:24.126Z","comments":false,"path":"repository/index.html","permalink":"https://zcej.github.io/repository/index.html","excerpt":"","text":""}],"posts":[{"title":"go语言实现大根堆、小根堆及堆排序","slug":"go/go实现大根堆、小根堆及堆排序","date":"2022-03-18T13:07:38.000Z","updated":"2022-05-23T09:53:41.272Z","comments":true,"path":"2022/03/18/go/go实现大根堆、小根堆及堆排序/","link":"","permalink":"https://zcej.github.io/2022/03/18/go/go%E5%AE%9E%E7%8E%B0%E5%A4%A7%E6%A0%B9%E5%A0%86%E3%80%81%E5%B0%8F%E6%A0%B9%E5%A0%86%E5%8F%8A%E5%A0%86%E6%8E%92%E5%BA%8F/","excerpt":"","text":"二叉堆是一种特殊的堆，它满足两个性质：结构性和堆序性 结构性：二叉堆是一棵完全二叉树，完全二叉树可以用一个数组表示，不需要指针，所以效率更高。当用数组表示时，数组中任一位置i上的元素，其左子树在位置2i上，右子树在位置2i+1上，其父节点在位置i&#x2F;2上。 堆序性质：堆的最小值或最大值在根节点上，所以可以快速找到最大值或最小值。 最大堆和最小堆是二叉堆的两种形式： 最大堆：根节点的键值是所有堆节点键值中最大者的堆。 最小堆：根节点的键值是所有堆节点键值中最小者的堆。 最小堆实现插入和删除当向最小堆插入元素时： 将元素插入末尾 判断该元素是否需要上移(与父节点比较，如果比父节点小则上移) 重复上述步骤，直到满足最小堆特性 当向最小堆删除元素时： 删除堆顶元素 判断目前的堆顶元素是否需要下调(与子节点比较，和其中较小的节点交换位置) 重复上述步骤，直到满足最小堆特性 具体实现下面以求数据流中第k大的元素为问题实现一个最小堆，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253type minHeap struct &#123; k int // 容量 heap []int // heap数组&#125;func createMinHeap(k int, nums []int) *minHeap &#123; heap := &amp;minHeap&#123;k: k, heap: []int&#123;&#125;&#125; for _, n := range nums &#123; heap.add(n) &#125; return heap&#125;func (m *minHeap) add(num int) &#123; if len(m.heap) &lt; m.k &#123; m.heap = append(m.heap, num) m.up(len(m.heap) - 1) &#125; else if num &gt; m.heap[0] &#123; m.heap[0] = num m.down(0) &#125;&#125;// 元素上浮func (m *minHeap) up(i int) &#123; for i &gt; 0 &#123; parent := (i - 1) &gt;&gt; 1 // 找到父节点在heap数组中的位置 // 如果比父节点元素小，则交换位置并更新索引 if m.heap[parent] &gt; m.heap[i] &#123; m.heap[parent], m.heap[i] = m.heap[i], m.heap[parent] i = parent &#125; else &#123; break // 当前节点比父节点小，满足最小堆性质，退出 &#125; &#125;&#125;// 元素下沉(包括切片中第一个元素，索引为0)func (m *minHeap) down(i int) &#123; for 2*i+1 &lt; len(m.heap) &#123; // 左子节点越界，则退出循环 child := 2*i + 1 // 左子节点在heap切片中的位置 if child+1 &lt; len(m.heap) &amp;&amp; m.heap[child+1] &lt; m.heap[child] &#123; child++ // 如果右子节点没有越界，且值比左子节点更小，则选择下沉右子节点 &#125; // 将当前元素与子节点最大元素对比，然后交换并更新索引 if m.heap[i] &gt; m.heap[child] &#123; m.heap[child], m.heap[i] = m.heap[i], m.heap[child] i = child &#125; else &#123; break // 子节点都比自己大，满足最小堆属性，退出 &#125; &#125;&#125; 应用如果要求输出数据流中的第k大元素，正好可以使用最小堆实现： 123456789101112type KthLargest struct &#123; heap *minHeap&#125;func Constructor(k int, nums []int) KthLargest &#123; return KthLargest&#123;heap: createMinHeap(k, nums)&#125;&#125;func (k *KthLargest) Add(val int) int &#123; k.heap.add(val) return k.heap.heap[0]&#125; 使用heap包实现heap源码中定义了一个Interface接口，该接口一共包含5个方法，定义一个实现了该接口的结构体就实现了一个二叉堆。container/heap/heap.go 12345678// Note that Push and Pop in this interface are for package heap&#x27;s// implementation to call. To add and remove things from the heap,// use heap.Push and heap.Pop.type Interface interface &#123; sort.Interface Push(x interface&#123;&#125;) // add x as element Len() Pop() interface&#123;&#125; // remove and return element Len() - 1.&#125; sort/sort.go 1234567891011121314151617181920212223242526// An implementation of Interface can be sorted by the routines in this package.// The methods refer to elements of the underlying collection by integer index.type Interface interface &#123; // Len is the number of elements in the collection. Len() int // Less reports whether the element with index i // must sort before the element with index j. // // If both Less(i, j) and Less(j, i) are false, // then the elements at index i and j are considered equal. // Sort may place equal elements in any order in the final result, // while Stable preserves the original input order of equal elements. // // Less must describe a transitive ordering: // - if both Less(i, j) and Less(j, k) are true, then Less(i, k) must be true as well. // - if both Less(i, j) and Less(j, k) are false, then Less(i, k) must be false as well. // // Note that floating-point comparison (the &lt; operator on float32 or float64 values) // is not a transitive ordering when not-a-number (NaN) values are involved. // See Float64Slice.Less for a correct implementation for floating-point values. Less(i, j int) bool // Swap swaps the elements with indexes i and j. Swap(i, j int)&#125; 定义一个最大堆，实现上述接口如下： 12345678910111213141516171819202122232425262728293031323334type MaxHeap []intfunc (h MaxHeap) Len() int &#123; return len(h)&#125;func (h MaxHeap) Less(i, j int) bool &#123; return h[i] &gt; h[j] // 因为实现最大堆，所以使用大于号&#125;func (h *MaxHeap) Swap(i, j int) &#123; (*h)[i], (*h)[j] = (*h)[j], (*h)[i]&#125;func (h *MaxHeap) Push(x interface&#123;&#125;) &#123; *h = append(*h, x.(int))&#125;// Pop 弹出堆顶元素func (h *MaxHeap) Pop() interface&#123;&#125; &#123; res := (*h)[len(*h)-1] *h = (*h)[:len(*h)-1] return res&#125;func main() &#123; h := &amp;MaxHeap&#123;3, 1, 2, 5&#125; heap.Init(h) heap.Push(h, 8) for h.Len() &gt; 0 &#123; fmt.Printf(&quot;%d &quot;, heap.Pop(h)) &#125;&#125; 堆排序堆排序是一种选择排序，它的最坏、最好、平均时间复杂度均为O(nlogn)，它也是不稳定排序。 排序的过程主要由构建初始堆，交换堆顶元素和末尾元素并重建堆两部分组成 升序使用最大堆，每次和末尾元素交换，然后重新构建最大堆，整体数组减一；反之降序使用最小堆 堆构建从第一个非叶子节点开始，也就是len/2 - 1所在位置的元素 12345678910111213141516171819202122232425262728293031323334353637func maxHeap(nums []int, length int) []int &#123; if length &lt;= 1 &#123; return nums &#125; parent := length/2 + 1 // 第一个非叶子节点 for i := parent; i &gt;= 0; i-- &#123; // 比较三个节点的大小并将较大的节点上浮 max := i leftChild := 2*i + 1 rightChild := 2*i + 2 if leftChild &lt;= length-1 &amp;&amp; nums[leftChild] &gt; nums[max] &#123; max = leftChild &#125; if rightChild &lt;= length-1 &amp;&amp; nums[rightChild] &gt; nums[max] &#123; max = rightChild &#125; if max != i &#123; nums[i], nums[max] = nums[max], nums[i] &#125; &#125; return nums&#125;func sortHeap(nums []int) []int &#123; length := len(nums) for i := 0; i &lt; length; i++ &#123; lastLength := length - i // 剔除已经排完序的元素 nums = maxHeap(nums, lastLength) // 重新构建最大堆 nums[0], nums[lastLength-1] = nums[lastLength-1], nums[0] &#125; return nums&#125;func main() &#123; nums := []int&#123;8, 5, 11, 2, 7, 9&#125; fmt.Println(sortHeap(nums))&#125;","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"channel的底层实现","slug":"go/channel的底层实现","date":"2022-03-05T11:43:21.000Z","updated":"2022-05-23T09:46:25.833Z","comments":true,"path":"2022/03/05/go/channel的底层实现/","link":"","permalink":"https://zcej.github.io/2022/03/05/go/channel%E7%9A%84%E5%BA%95%E5%B1%82%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"本文基于go版本1.16 数据结构其底层数据结构为runtime包下的一个hchan的结构体，如下： 12345678910111213141516171819202122232425type hchan struct &#123; qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G&#x27;s status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex&#125;type waitq struct &#123; first *sudog last *sudog&#125; buf指向底层循环数组，只有缓冲型的channel才有 sendx, recvx均指向底层循环数组，表示当前可以发送和接收的元素位置索引值（相对于底层数组） sendq, recvq分别表示向channel读取或发送数据而阻塞的goroutine队列 waitq是sudog的一个双向链表（sudog实际上是对goroutine的封装） lock用来保证每个读channel或写channel的操作都是原子的 创建使用make能创建一个能收能发的channel： 12345// 无缓冲通道ch1 := make(chan int)// 有缓冲通道ch2 := make(chan int, 10) 通过汇编分析（go complie），找到最终创建chan的函数是位于runtime&#x2F;chan.go下的函数makechan： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455const ( maxAlign = 8 hchanSize = unsafe.Sizeof(hchan&#123;&#125;) + uintptr(-int(unsafe.Sizeof(hchan&#123;&#125;))&amp;(maxAlign-1)) debugChan = false)func makechan(t *chantype, size int) *hchan &#123; elem := t.elem // compiler checks this but be safe. if elem.size &gt;= 1&lt;&lt;16 &#123; throw(&quot;makechan: invalid channel element type&quot;) &#125; if hchanSize%maxAlign != 0 || elem.align &gt; maxAlign &#123; throw(&quot;makechan: bad alignment&quot;) &#125; mem, overflow := math.MulUintptr(elem.size, uintptr(size)) if overflow || mem &gt; maxAlloc-hchanSize || size &lt; 0 &#123; panic(plainError(&quot;makechan: size out of range&quot;)) &#125; // Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers. // buf points into the same allocation, elemtype is persistent. // SudoG&#x27;s are referenced from their owning thread so they can&#x27;t be collected. // TODO(dvyukov,rlh): Rethink when collector can move allocated objects. var c *hchan switch &#123; case mem == 0: // Queue or element size is zero. c = (*hchan)(mallocgc(hchanSize, nil, true)) // Race detector uses this location for synchronization. c.buf = c.raceaddr() case elem.ptrdata == 0: // Elements do not contain pointers. // Allocate hchan and buf in one call. c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: // Elements contain pointers. c = new(hchan) c.buf = mallocgc(mem, elem, true) &#125; c.elemsize = uint16(elem.size) c.elemtype = elem c.dataqsiz = uint(size) lockInit(&amp;c.lock, lockRankHchan) if debugChan &#123; print(&quot;makechan: chan=&quot;, c, &quot;; elemsize=&quot;, elem.size, &quot;; dataqsiz=&quot;, size, &quot;\\n&quot;) &#125; return c&#125; 发送123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool &#123; if c == nil &#123; // 当channel是nil if !block &#123; return false // 非阻塞直接返回false，表示发送失败 &#125; gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) // 挂起当前goroutine throw(&quot;unreachable&quot;) &#125; if debugChan &#123; print(&quot;chansend: chan=&quot;, c, &quot;\\n&quot;) &#125; if raceenabled &#123; racereadpc(c.raceaddr(), callerpc, funcPC(chansend)) &#125; // Fast path: check for failed non-blocking operation without acquiring the lock. // // After observing that the channel is not closed, we observe that the channel is // not ready for sending. Each of these observations is a single word-sized read // (first c.closed and second full()). // Because a closed channel cannot transition from &#x27;ready for sending&#x27; to // &#x27;not ready for sending&#x27;, even if the channel is closed between the two observations, // they imply a moment between the two when the channel was both not yet closed // and not ready for sending. We behave as if we observed the channel at that moment, // and report that the send cannot proceed. // // It is okay if the reads are reordered here: if we observe that the channel is not // ready for sending and then observe that it is not closed, that implies that the // channel wasn&#x27;t closed during the first observation. However, nothing here // guarantees forward progress. We rely on the side effects of lock release in // chanrecv() and closechan() to update this thread&#x27;s view of c.closed and full(). // 快速检测非阻塞且channel未关闭情况下的失败场景（详情看下述full函数）： // 1. 对于无缓冲channel，接收队列里没有goroutine则发送失败(非阻塞) // 2. 对于有缓冲channel，循环数组中已装满元素则发送失败(非阻塞) if !block &amp;&amp; c.closed == 0 &amp;&amp; full(c) &#123; return false &#125; var t0 int64 if blockprofilerate &gt; 0 &#123; t0 = cputicks() &#125; lock(&amp;c.lock) // 锁住channel，并发安全 if c.closed != 0 &#123; // 如果channel关闭了，则解锁并抛出异常 unlock(&amp;c.lock) panic(plainError(&quot;send on closed channel&quot;)) &#125; // 如果接收队列里有goroutine，则直接将要发送的数据拷贝到接收goroutine if sg := c.recvq.dequeue(); sg != nil &#123; // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). send(c, sg, ep, func() &#123; unlock(&amp;c.lock) &#125;, 3) return true &#125; // 对于有缓冲的channel，如果还有缓冲空间 if c.qcount &lt; c.dataqsiz &#123; // Space is available in the channel buffer. Enqueue the element to send. qp := chanbuf(c, c.sendx) // qp指向buf的sendx位置 if raceenabled &#123; racenotify(c, c.sendx, nil) &#125; typedmemmove(c.elemtype, qp, ep) // 将数据从ep处拷贝到qp c.sendx++ // 发送游标值加一 if c.sendx == c.dataqsiz &#123; // 如果发送游标值等于容量值，游标值归0 c.sendx = 0 &#125; c.qcount++ // 缓冲区的元素数量加一 unlock(&amp;c.lock) // 解锁 return true &#125; if !block &#123; // 如果是非阻塞的，直接返回错误 unlock(&amp;c.lock) return false &#125; // channel满了，发送方会被阻塞。接下来会构造一个sudog // Block on the channel. Some receiver will complete our operation for us. gp := getg() // 获取当前goroutine的指针 mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 &#123; mysg.releasetime = -1 &#125; // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil mysg.g = gp mysg.isSelect = false mysg.c = c gp.waiting = mysg gp.param = nil c.sendq.enqueue(mysg) // 当前goroutine进入发送等待队列 // Signal to anyone trying to shrink our stack that we&#x27;re about // to park on a channel. The window between when this G&#x27;s status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. atomic.Store8(&amp;gp.parkingOnChan, 1) // 挂起当前goroutine gopark(chanparkcommit, unsafe.Pointer(&amp;c.lock), waitReasonChanSend, traceEvGoBlockSend, 2) // Ensure the value being sent is kept alive until the // receiver copies it out. The sudog has a pointer to the // stack object, but sudogs aren&#x27;t considered as roots of the // stack tracer. KeepAlive(ep) // someone woke us up. if mysg != gp.waiting &#123; throw(&quot;G waiting list is corrupted&quot;) &#125; gp.waiting = nil gp.activeStackChans = false closed := !mysg.success gp.param = nil if mysg.releasetime &gt; 0 &#123; blockevent(mysg.releasetime-t0, 2) &#125; mysg.c = nil releaseSudog(mysg) if closed &#123; if c.closed == 0 &#123; throw(&quot;chansend: spurious wakeup&quot;) &#125; panic(plainError(&quot;send on closed channel&quot;)) &#125; return true&#125; 1234567891011121314func full(c *hchan) bool &#123; // c.dataqsiz is immutable (never written after the channel is created) // so it is safe to read at any time during channel operation. if c.dataqsiz == 0 &#123; // Assumes that a pointer read is relaxed-atomic. return c.recvq.first == nil &#125; // Assumes that a uint read is relaxed-atomic. return c.qcount == c.dataqsiz&#125;// if !block &amp;&amp; c.closed == 0 &amp;&amp; full(c) &#123;// return false// &#125; 这里有一个点需要注意，结合在chansend中调用full的地方上的英文注释进行分析，在得知channel未被关闭的情况下(c.closed==0)，去获取c.recvq.first和c.qcount的值时为什么不需要加锁(假设这个期间channe被关闭，则前后条件实际上是不一致的)？ 因为一个已经关闭的channel不能将channel状态从ready for sending变成not ready for sending，意味着在两个观测之间有一个时刻，通道既没有被关闭，也没有准备好发送，此时直接返回false也是没有问题的 然后其会依赖chanrecv()和closechan()中锁释放的副作用来更新这个线程的c.closed和full 如果从等待接收队列recvq里出队一个sudog(代表一个goroutine)，说明此时channel是空的，没有元素，所以才会有等待接收者。这时会调用send函数将元素直接从发送者的栈拷贝到接收者的栈，关键操作由sendDirect函数完成。 12345678910111213141516171819202122232425262728293031323334353637// send processes a send operation on an empty channel c.// The value ep sent by the sender is copied to the receiver sg.// The receiver is then woken up to go on its merry way.// Channel c must be empty and locked. send unlocks c with unlockf.// sg must already be dequeued from c.// ep must be non-nil and point to the heap or the caller&#x27;s stack.func send(c *hchan, sg *sudog, ep unsafe.Pointer, unlockf func(), skip int) &#123; if raceenabled &#123; if c.dataqsiz == 0 &#123; racesync(c, sg) &#125; else &#123; // Pretend we go through the buffer, even though // we copy directly. Note that we need to increment // the head/tail locations only when raceenabled. racenotify(c, c.recvx, nil) racenotify(c, c.recvx, sg) c.recvx++ if c.recvx == c.dataqsiz &#123; c.recvx = 0 &#125; c.sendx = c.recvx // c.sendx = (c.sendx+1) % c.dataqsiz &#125; &#125; // sg.elem指向接收到的值存放的位置，如val &lt;-ch，指的就是&amp;val if sg.elem != nil &#123; sendDirect(c.elemtype, sg, ep) // 直接拷贝内存（从发送者到接收者） sg.elem = nil &#125; gp := sg.g // sudo上绑定的goroutine unlockf() gp.param = unsafe.Pointer(sg) sg.success = true if sg.releasetime != 0 &#123; sg.releasetime = cputicks() &#125; goready(gp, skip+1) // 唤醒接收的goroutine&#125; 继续看sendDirect函数： 12345678910111213141516171819202122// Sends and receives on unbuffered or empty-buffered channels are the// only operations where one running goroutine writes to the stack of// another running goroutine. The GC assumes that stack writes only// happen when the goroutine is running and are only done by that// goroutine. Using a write barrier is sufficient to make up for// violating that assumption, but the write barrier has to work.// typedmemmove will call bulkBarrierPreWrite, but the target bytes// are not in the heap, so that will not help. We arrange to call// memmove and typeBitsBulkBarrier instead.func sendDirect(t *_type, sg *sudog, src unsafe.Pointer) &#123; // src is on our stack, dst is a slot on another stack. // Once we read sg.elem out of sg, it will no longer // be updated if the destination&#x27;s stack gets copied (shrunk). // So make sure that no preemption points can happen between read &amp; use. dst := sg.elem typeBitsBulkBarrier(t, uintptr(dst), uintptr(src), t.size) // No need for cgo write barrier checks because dst is always // Go memory. memmove(dst, src, t.size)&#125; 这里涉及到一个goroutine直接写另一个goroutine栈的操作，一般而言，不同goroutine的栈是各自独有的。而这也违反了GC的一些假设。为了不出问题，写的过程中增加了写屏障，保证正确的完成写操作。这样做的好处是减少了一次内存拷贝，不用先拷贝到channel的buf，直接由发送者到接收者，减少了中间一层，效率得以提高。然后解锁，唤醒接收者，等待调度器的光临，接收者得以重见天日，可以继续执行接收操作后续代码了。 接收接收操作有两种写法，一种带”ok”，表示channel是否被关闭；一种不带”ok”，这种写法当接收到相应类型的零值时无法知道是真实的发送者发送者发送过来的值，还是channel被关闭后，返回给接收者默认类型的零值。经过编译器的处理后，这两种写法对应源码以下的两个函数： 1234567891011// entry points for &lt;- c from compiled code//go:nosplitfunc chanrecv1(c *hchan, elem unsafe.Pointer) &#123; chanrecv(c, elem, true)&#125;//go:nosplitfunc chanrecv2(c *hchan, elem unsafe.Pointer) (received bool) &#123; _, received = chanrecv(c, elem, true) return&#125; 有上述源码可见，最终都会调用chanrecv这个函数： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146// chanrecv receives on channel c and writes the received data to ep.// ep may be nil, in which case received data is ignored.// If block == false and no elements are available, returns (false, false).// Otherwise, if c is closed, zeros *ep and returns (true, false).// Otherwise, fills in *ep with an element and returns (true, true).// A non-nil ep must point to the heap or the caller&#x27;s stack.func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) &#123; // raceenabled: don&#x27;t need to check ep, as it is always on the stack // or is new memory allocated by reflect. if debugChan &#123; print(&quot;chanrecv: chan=&quot;, c, &quot;\\n&quot;) &#125; if c == nil &#123; // 如果是nil的channel if !block &#123; return &#125; gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(&quot;unreachable&quot;) &#125; // Fast path: check for failed non-blocking operation without acquiring the lock. if !block &amp;&amp; empty(c) &#123; // After observing that the channel is not ready for receiving, we observe whether the // channel is closed. // // Reordering of these checks could lead to incorrect behavior when racing with a close. // For example, if the channel was open and not empty, was closed, and then drained, // reordered reads could incorrectly indicate &quot;open and empty&quot;. To prevent reordering, // we use atomic loads for both checks, and rely on emptying and closing to happen in // separate critical sections under the same lock. This assumption fails when closing // an unbuffered channel with a blocked send, but that is an error condition anyway. if atomic.Load(&amp;c.closed) == 0 &#123; // Because a channel cannot be reopened, the later observation of the channel // being not closed implies that it was also not closed at the moment of the // first observation. We behave as if we observed the channel at that moment // and report that the receive cannot proceed. return &#125; // The channel is irreversibly closed. Re-check whether the channel has any pending data // to receive, which could have arrived between the empty and closed checks above. // Sequential consistency is also required here, when racing with such a send. if empty(c) &#123; // The channel is irreversibly closed and empty. if raceenabled &#123; raceacquire(c.raceaddr()) &#125; if ep != nil &#123; typedmemclr(c.elemtype, ep) &#125; return true, false &#125; &#125; var t0 int64 if blockprofilerate &gt; 0 &#123; t0 = cputicks() &#125; lock(&amp;c.lock) if c.closed != 0 &amp;&amp; c.qcount == 0 &#123; if raceenabled &#123; raceacquire(c.raceaddr()) &#125; unlock(&amp;c.lock) if ep != nil &#123; typedmemclr(c.elemtype, ep) &#125; return true, false &#125; if sg := c.sendq.dequeue(); sg != nil &#123; // Found a waiting sender. If buffer is size 0, receive value // directly from sender. Otherwise, receive from head of queue // and add sender&#x27;s value to the tail of the queue (both map to // the same buffer slot because the queue is full). recv(c, sg, ep, func() &#123; unlock(&amp;c.lock) &#125;, 3) return true, true &#125; // 有缓冲channel，buf里面有元素，可以正常接收 if c.qcount &gt; 0 &#123; // Receive directly from queue qp := chanbuf(c, c.recvx) if raceenabled &#123; racenotify(c, c.recvx, nil) &#125; if ep != nil &#123; // 不忽略要接收的值，不是&quot;&lt;-ch&quot;，而是&quot;val &lt;-ch&quot;，ep指向val typedmemmove(c.elemtype, ep, qp) &#125; typedmemclr(c.elemtype, qp) // 清理掉循环数组里相应位置的值 c.recvx++ // 接收游标向前移动 if c.recvx == c.dataqsiz &#123; c.recvx = 0 // 接收游标归零 &#125; c.qcount-- unlock(&amp;c.lock) return true, true &#125; if !block &#123; unlock(&amp;c.lock) return false, false &#125; // no sender available: block on this channel. gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 &#123; mysg.releasetime = -1 &#125; // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil c.recvq.enqueue(mysg) // Signal to anyone trying to shrink our stack that we&#x27;re about // to park on a channel. The window between when this G&#x27;s status // changes and when we set gp.activeStackChans is not safe for // stack shrinking. atomic.Store8(&amp;gp.parkingOnChan, 1) gopark(chanparkcommit, unsafe.Pointer(&amp;c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2) // someone woke us up if mysg != gp.waiting &#123; throw(&quot;G waiting list is corrupted&quot;) &#125; gp.waiting = nil gp.activeStackChans = false if mysg.releasetime &gt; 0 &#123; blockevent(mysg.releasetime-t0, 2) &#125; success := mysg.success gp.param = nil mysg.c = nil releaseSudog(mysg) return true, success&#125; 关闭1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071func closechan(c *hchan) &#123; if c == nil &#123; panic(plainError(&quot;close of nil channel&quot;)) // 关闭一个nil的channel直接panic &#125; lock(&amp;c.lock) if c.closed != 0 &#123; unlock(&amp;c.lock) panic(plainError(&quot;close of closed channel&quot;)) // 关闭一个已经关闭的channel，panic &#125; if raceenabled &#123; callerpc := getcallerpc() racewritepc(c.raceaddr(), callerpc, funcPC(closechan)) racerelease(c.raceaddr()) &#125; c.closed = 1 var glist gList // release all readers for &#123; sg := c.recvq.dequeue() if sg == nil &#123; break &#125; if sg.elem != nil &#123; typedmemclr(c.elemtype, sg.elem) sg.elem = nil &#125; if sg.releasetime != 0 &#123; sg.releasetime = cputicks() &#125; gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled &#123; raceacquireg(gp, c.raceaddr()) &#125; glist.push(gp) &#125; // release all writers (they will panic) for &#123; sg := c.sendq.dequeue() if sg == nil &#123; break &#125; sg.elem = nil if sg.releasetime != 0 &#123; sg.releasetime = cputicks() &#125; gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled &#123; raceacquireg(gp, c.raceaddr()) &#125; glist.push(gp) &#125; unlock(&amp;c.lock) // Ready all Gs now that we&#x27;ve dropped the channel lock. for !glist.empty() &#123; gp := glist.pop() gp.schedlink = 0 goready(gp, 3) &#125;&#125; close逻辑比较简单，对于一个channel，recvq和sendq中分别保存了阻塞的发送者和接收者。关闭channel后，对于等待接收者而言，会收到一个相应类型的零值。对于等待发送者，会直接panic。所以，在不了解channel还有没有接收者的情况下，不能贸然关闭channel。 close函数先上一把大锁，接着把所有挂在这个channel上的sender和receiver全都连成一个sudog链表，再解锁。最后再将所有的sudog全都唤醒。 唤醒之后，该干什么干什么。sender会继续执行chansend函数里goparkunlock函数之后的代码，当检测到channel已经关闭了则会panic。receiver则会进行后续的扫尾工作，然后返回，这里selected会返回true，received会根据channel是否关闭返回不同的值。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"go语言变量逃逸分析","slug":"go/go语言变量逃逸分析","date":"2022-02-12T07:16:09.000Z","updated":"2022-05-23T09:44:09.744Z","comments":true,"path":"2022/02/12/go/go语言变量逃逸分析/","link":"","permalink":"https://zcej.github.io/2022/02/12/go/go%E8%AF%AD%E8%A8%80%E5%8F%98%E9%87%8F%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/","excerpt":"","text":"go实现了内存的自动管理，其主要包括两个动作：分配与释放。为了更好的理解逃逸分析，需要对堆和栈有一定的了解。 堆和栈应用程序的内存载体，可以简单分为堆和栈。 在go中，栈的内存是由编译器进行分配和释放，栈区往往存储着函数参数、局部变量和调用函数帧，它们随着函数的创建而分配，函数的退出而销毁。一个goroutine对应一个栈，栈是调用栈的简称。一个栈通常又包含了许多栈帧，它描述的函数之间的调用关系，每一帧对应一次尚未返回的函数调用，它本身也是以栈形式存放数据。 与栈不同的是，应用程序在运行时只会存在一个堆。狭隘的说，内存管理只是针对堆内存而言的。程序在运行期间可以主动从堆上申请内存，这些内存通过go的内存分配器分配，并由垃圾回收器回收。 另外，对于堆内存的回收，还需要通过标记清除阶段，如三色标记法。但是对于栈上的内存而言，其分配和释放非常廉价。简单的说，它只需要两个cpu指令，一个是分配入栈，一个是栈内释放，而这只需要借助栈相关的寄存器即可完成。 逃逸分析对于一个对象是被分配在堆上还是栈上，官网上也有这样的回答： 如果可以，go编译器会尽可能将变量分配到栈上。但是，当编译器无法证明函数返回后，该变量没有被引用，那么编译器就必须在堆上分配该变量，以此避免悬挂指针。另外如果局部变量非常大，也会将其分配在堆上。 而go编译器则是通过逃逸分析去选择堆或者是栈，逃逸分析的基本思想如下：检查变量的生命周期是否是完全可知的，如果通过检查，则可以在栈上分配。否则，就是逃逸，必须在堆上进行分配。 可以通过命令go build -gcflags &quot;-m -l&quot;来查看逃逸分析结果： -m：打印逃逸分析信息 -l：禁止内联优化 常见的逃逸情况如下所示： 情况一：变量类型不确定12345678910func main() &#123; a := 666 fmt.Println(a)&#125;// 输出如下// $ go build -gcflags &quot;-m -l&quot; main.go// # command-line-arguments// ./main.go:7:13: ... argument does not escape// ./main.go:7:13: a escapes to heap 变量a发生了逃逸是因为其被传入了fmt.Println中，这个方法参数自己发生了逃逸。 func Println(a ...interface&#123;&#125;) (n int, err error) 因为fmt.Println函数参数为interface类型，编译期无法确定参数的具体类型，故分配在堆上 情况二：暴露给外部指针123456789101112func foo() *int &#123; a := 666 return &amp;a&#125;func main() &#123; _ = foo()&#125;// # command-line-arguments// .\\main.go:4:2: moved to heap: a 变量存在外部引用则必定分配到堆上。 情况三：变量所占内存较大1234567891011121314func foo() &#123; s := make([]int, 10000, 10000) for i := 0; i &lt; len(s); i++ &#123; s[i] = i &#125;&#125;func main() &#123; foo()&#125;// # command-line-arguments// .\\main.go:4:11: make([]int, 10000, 10000) escapes to heap 这里需要注意，在go中执行用户代码的goroutine是一种用户态线程，其调用栈内存被称为用户栈，它其实也是从堆区分配的，但是我们仍然可以将其看作和系统栈一样的内存空间，它的分配和释放都是通过编译器完成的。与其对应的是系统栈，它的分配和释放是操作系统完成的。在GMP模型中，一个M对应一个系统栈(也称为M的g0栈)，M上的多个goroutine会共享该系统栈。 不同架构的系统栈最大限制不同，以x86_64为例，其系统栈最大为8mb 我们常说的goroutine初始大小为2kb，说的是用户栈，可在runtime/stack.go中找到 在go中大对象的范围为大于32kb，即上述代码中的n达到8192，就会逃逸 情况四：变量大小不确定123456789101112131415func foo() &#123; n := 1 s := make([]int, n) for i := 0; i &lt; len(s); i++ &#123; s[i] = i &#125;&#125;func main() &#123; foo()&#125;// # command-line-arguments// .\\main.go:5:11: make([]int, n) escapes to heap 这次，在make方法中，没有直接指定大小，而是填入了变量n，这时go逃逸分析也会将其分配到堆区去。可见，为了保证内存的绝对安全，go的编译器可能会将一些变量不合时宜地分配到堆上，但是因为这些对象最终也会被垃圾收集器处理，所以也能接受。 小结 发生逃逸的情况还有很多，理解其思想才是最为重要的。 理解逃逸分析可以帮助我们写出更好的程序，知道变量分配在堆栈上的差别，则尽可能写出分配在栈上的代码，堆上的变量变少了，可以减轻内存分配的开销，减小gc的压力，提高程序的运行速度。 你会发现有些go上线项目，它们在函数传参的时候，并没有传递结构体指针，而是直接传递的结构体。这个做法，虽然它需要值拷贝，但是这是在栈上完成的操作，开销远比变量逃逸后动态的在堆上分配内存少的多。当然这个做法不是绝对的，如果结构体较大，传递指针将更加合适。 从gc的角度来看，指针传递是个双刃剑，需要谨慎使用，否则线上调优解决gc延时会让人崩溃。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"channel到底需不需要手动关闭","slug":"go/channel到底需不需要手动关闭？","date":"2021-12-25T16:31:29.000Z","updated":"2022-05-23T09:41:33.091Z","comments":true,"path":"2021/12/26/go/channel到底需不需要手动关闭？/","link":"","permalink":"https://zcej.github.io/2021/12/26/go/channel%E5%88%B0%E5%BA%95%E9%9C%80%E4%B8%8D%E9%9C%80%E8%A6%81%E6%89%8B%E5%8A%A8%E5%85%B3%E9%97%AD%EF%BC%9F/","excerpt":"","text":"前景提要下面的代码是《go语言圣经》这本书的其中一个案例，其中主协程和子协程兼具生产消费两种身份了，最终当没有新的消息时代码会阻塞住，而书中没有给出该案例的终止方式，自己也是思考了很久，看来还是对go的channel理解不够深，在使用channel的时候一定要有自己的思考，不然可能会引发很多问题，小到程序莫名其妙的panic，大到出现goroutine以及channel的泄露等等！ 123456789101112131415161718192021222324252627282930313233343536373839func crawl(url string) []string &#123; urls, err := links.Extract(url) // 书中其他章节, 具体逻辑是提取网页中所有a标签的链接 if err != nil &#123; log.Print(err) &#125; return urls&#125;func main() &#123; worklist := make(chan []string) // lists of URLs, may have duplicates unseenLinks := make(chan string) // de-duplicated URLs urls := []string&#123;&quot;http://xxxx.com&quot;&#125; // Add command-line arguments to worklist. go func() &#123; worklist &lt;- urls &#125;() // Create 20 crawler goroutines to fetch each unseen link. for i := 0; i &lt; 20; i++ &#123; go func() &#123; for link := range unseenLinks &#123; foundLinks := crawl(link) go func() &#123; worklist &lt;- foundLinks &#125;() &#125; &#125;() &#125; // The main goroutine de-duplicates worklist items // and sends the unseen ones to the crawlers. seen := make(map[string]bool) for list := range worklist &#123; for _, link := range list &#123; if !seen[link] &#123; seen[link] = true unseenLinks &lt;- link &#125; &#125; &#125;&#125; 虽然上述并发案例书中未提及如何终止的问题，不过书里也提供了另外一种并发方式且可自动终止，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041// tokens is a counting semaphore used to// enforce a limit of 20 concurrent requests.var tokens = make(chan struct&#123;&#125;, 20)func crawl(w work, mutex sync.Locker) []work &#123; fmt.Println(url) tokens &lt;- struct&#123;&#125;&#123;&#125; // acquire a token urls, err := links.Extract(w.url) &lt;-tokens // release the token if err != nil &#123; log.Print(err) &#125; return urls&#125;func main() &#123; worklist := make(chan []string) var n int // number of pending sends to worklist url := []string&#123;&quot;http://xxxx.com&quot;&#125; // start n++ go func() &#123; worklist &lt;- []work&#123;url&#125; &#125;() // crawl the web concurrently visited := make(map[string]bool) for ; n &gt; 0; n-- &#123; works := &lt;-worklist for _, w := range works &#123; if !visited[w.url] &#123; visited[w.url] = true n++ go func(w work) &#123; worklist &lt;- crawl(w, &amp;lock) &#125;(w) &#125; &#125; &#125;&#125; 这种实现方式很巧妙，使用了计数器n进行了限制，主协程在n减为0的时候会终止，子协程也会随之退出。这里的channel在没有被goroutine引用的时候也会被gc所销毁，结合第一个没有终止的案例，我们必须手动去关闭掉生产消费，让程序达到所有消息消费完后自动终止的目的。那么以下知识点就是必须要掌握的！ https://juejin.cn/post/7033671944587182087 什么情况下关闭channel会引发panic？示例如下： 1234567891011121314151617181920212223242526272829303132333435363738394041// 1. 关闭未初始化的chanfunc TestCloseNilChan(t *testing.T) &#123; var errCh chan error close(errCh) // Output: // panic: close of nil channel&#125;// 2. 关闭已经关闭的chanfunc TestRepeatClosingChan(t *testing.T) &#123; errCh := make(chan error) close(errCh) close(errCh) // Output: // panic: close of closed channel&#125;// 3. 关闭chan后发送数据func TestSendOnClosingChan(t *testing.T) &#123; errCh := make(chan error) close(errCh) errCh &lt;- errors.New(&quot;chan error&quot;) // Output: // panic: send on closed channel&#125;// 4. 发送数据时关闭chanfunc TestCloseOnSendingToChan(t *testing.T) &#123; errCh := make(chan error) go func() &#123; errCh &lt;- errors.New(&quot;chan error&quot;) &#125;() time.Sleep(1 * time.Second) close(errCh) // Output: // panic: send on closed channel&#125; 总结， 下述四种情况下关闭channel会引发panic： 关闭未初始化的channel 关闭已经关闭的channel 在关闭channel后发送数据 在发送数据时关闭channel 另外，可总结出以下规律： 只能让channel的唯一发送者关闭此channel 如果有多个发送者，应该使用专门的信号通知stop channel是否有必要关闭channel？不关闭又如何？当channel的发送次数等于接收次数12345678910111213141516171819202122232425262728// 1. 当channel的发送次数等于接收次数func TestIsCloseChannelNecessary_on_equal(t *testing.T) &#123; fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) ch := make(chan int) // sender go func() &#123; for i := 0; i &lt; 3; i++ &#123; ch &lt;- i &#125; &#125;() // receiver go func() &#123; for i := 0; i &lt; 3; i++ &#123; fmt.Println(&lt;-ch) &#125; &#125;() time.Sleep(time.Second * 1) fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) // Output: // NumGoroutine: 2 // 0 // 1 // 2 // NumGoroutine: 2&#125; channel的发送次数等于接收次数时，发送者的goroutine和接收者的goroutine分别会在发送和接收结束时结束自己的goroutine，用于传输数据的channel也会由于代码没有使用被垃圾收集器回收。所以该种情况下不需手动关闭chanel。当channel的发送次数大于&#x2F;小于接收次数12345678910111213141516171819202122232425262728293031// 2. 当channel的发送次数大于/小于接收次数func TestIsCloseChannelNecessary_on_more_equal(t *testing.T) &#123; fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) ch := make(chan int) // sender go func() &#123; defer fmt.Println(&quot;exit 1&quot;) for i := 0; i &lt; 4; i++ &#123; ch &lt;- i &#125; &#125;() // receiver go func() &#123; defer fmt.Println(&quot;exit 2&quot;) for i := 0; i &lt; 3; i++ &#123; fmt.Println(&lt;-ch) &#125; &#125;() time.Sleep(time.Second * 1) fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) // Output: // NumGoroutine: 2 // 0 // 1 // 2 // exit 2 // NumGoroutine: 3&#125; channel的发送次数大于接收次数时，发送者goroutine会等待接收者接收而一直阻塞。所以发送者goroutine一直未退出，channel也会由于一直被发送者使用而无法被垃圾回收。未退出的goroutine和channel会造成内存泄露等问题。 总结： 在只有一个发送者和一个接收者的情况下，只要确保发送者或接收者不会阻塞，不关闭channel是可行的。 在无法判断channel的发送次数和接收次数时，应当在合适的时机关闭channel。 另外使用for range从channel取值的时候，需要手动close掉channel，否则消费者会一直阻塞进而panic抛出错误，会被判定为死锁。 如何判断channel是否关闭？ channel关闭后继续读取该chennel不会阻塞，而是返回对应类型的零值。 使用channel的多重返回值(如err, ok :&#x3D; &lt;- errCh)12345678910111213141516171819202122// 1. 使用channel的返回值判断其是否关闭func TestReadFromClosedChan(t *testing.T) &#123; var errCh = make(chan error) go func() &#123; defer close(errCh) errCh &lt;- errors.New(&quot;chan error&quot;) &#125;() go func() &#123; for i := 0; i &lt; 3; i++ &#123; err, ok := &lt;-errCh; fmt.Println(i, err, ok) &#125; &#125;() time.Sleep(time.Second) // Output: // 0 chan error true // 1 &lt;nil&gt; false // 2 &lt;nil&gt; false&#125; err, ok :&#x3D; &lt;- errCh的第二个值ok返回false表示该channel已关闭。 使用for range简化语法123456789101112131415161718192021// 2. 使用for range简化语法func TestReadFromClosedChan2(t *testing.T) &#123; var errCh = make(chan error) go func() &#123; defer close(errCh) errCh &lt;- errors.New(&quot;chan error&quot;) &#125;() go func() &#123; i := 0 for err := range errCh &#123; fmt.Println(i, err) i++ &#125; &#125;() time.Sleep(time.Second) // Output: // 0 chan error&#125; 如何优雅的关闭channel?详细案例参考文章：https://gfw.go101.org/article/channel-closing.html 在使用单通道的函数中错误的关闭channel的话，编译的时候就会报错 参考上述文章，针对常规情况下需要关闭channel的四种场景，做了以下总结： 一个发送者，一个接收者：发送者关闭channel；接收者使用select或for range判断channel是否关闭 一个发送者，多个接收者：同上 多个发送者，一个接收者：接收者接收完后，使用专门的信号channel关闭；发送者使用select监听该信号channel是否关闭 多个发送者，多个接收者：任意一方或第三方使用专门的信号channel关闭；发送者，接收者都使用select监听该信号channel是否关闭总结回到开头例举的爬虫案例，个人进行了改写，主要是添加了超过递归深度时的退出以及超时退出和使用信号channel通知所用生产消费的goroutine关闭。具体代码如下，还有很多完善的点，以后理解更深后再进行修改：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475type work struct &#123; url string depth int&#125;func crawl(w work, quit chan struct&#123;&#125;) []work &#123; fmt.Printf(&quot;depth: %d, url: %s\\n&quot;, w.depth, w.url) if w.depth &gt; 3 &#123; quit &lt;- struct&#123;&#125;&#123;&#125; return nil &#125; urls, err := links.Extract(w.url) if err != nil &#123; log.Print(err) &#125; var works []work for _, url := range urls &#123; works = append(works, work&#123;url, w.depth + 1&#125;) &#125; return works&#125;//!+func main() &#123; worklist := make(chan []work) // lists of URLs, may have duplicates unseenLinks := make(chan work) // de-duplicated URLs stopCh := make(chan struct&#123;&#125;) // signal chan to stop all goroutine quit := make(chan struct&#123;&#125;) urls := work&#123;&quot;http://zorelworld.com/&quot;, 1&#125; // Add command-line arguments to worklist. go func() &#123; worklist &lt;- []work&#123;urls&#125; &#125;() // Create 20 crawler goroutines to fetch each unseen link. for i := 0; i &lt; 20; i++ &#123; go func() &#123; for &#123; select &#123; case &lt;-stopCh: return case link, _ := &lt;-unseenLinks: foundLinks := crawl(link, quit) go func() &#123;worklist &lt;- foundLinks&#125;() &#125; &#125; &#125;() &#125; // The main goroutine de-duplicates worklist items // and sends the unseen ones to the crawlers. seen := make(map[string]bool) for &#123; select &#123; case list := &lt;-worklist: for _, link := range list &#123; if !seen[link.url] &#123; seen[link.url] = true unseenLinks &lt;- link &#125; &#125; case &lt;-quit: fmt.Println(&quot;Exit, 111&quot;) close(stopCh) return case &lt;-time.After(3 * time.Second): // 如果上面的ch一直没数据会阻塞, 那么select也会检测其他case条件, 检测到后3s超时退出 fmt.Println(&quot;Exit, timeout&quot;) close(stopCh) return &#125; &#125;&#125;","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"关于channel和goroutine的内存泄漏问题","slug":"go/关于channel和goroutine的内存泄露问题","date":"2021-11-19T15:18:41.000Z","updated":"2022-05-23T09:40:05.603Z","comments":true,"path":"2021/11/19/go/关于channel和goroutine的内存泄露问题/","link":"","permalink":"https://zcej.github.io/2021/11/19/go/%E5%85%B3%E4%BA%8Echannel%E5%92%8Cgoroutine%E7%9A%84%E5%86%85%E5%AD%98%E6%B3%84%E9%9C%B2%E9%97%AE%E9%A2%98/","excerpt":"","text":"本文主要了解为关闭channel情况下所引发的内存泄露问题。 一个发送者导致的内存泄露主要原因是接收者提前退出了，导致发送者一直阻塞，最后导致了goroutine泄露，如下所示： 123456789101112131415161718192021222324252627func TestLeakOfMemory(t *testing.T) &#123; fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) chanLeakOfMemory() time.Sleep(time.Second * 3) // 等待 goroutine 执行，防止过早输出结果 fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine())&#125;func chanLeakOfMemory() &#123; errCh := make(chan error) // (1) go func() &#123; // (5) time.Sleep(2 * time.Second) errCh &lt;- errors.New(&quot;chan error&quot;) // (2) &#125;() var err error select &#123; case &lt;-time.After(time.Second): // (3) 大家也经常在这里使用 &lt;-ctx.Done() fmt.Println(&quot;超时&quot;) case err = &lt;-errCh: // (4) if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Println(nil) &#125; &#125;&#125; 上述代码分析： 由于没有发送方想errCh发送数据，故代码在(4)处阻塞 当(3)处超时后，函数退出且(4)处代码并未接收成功 之后(2)开始执行，由于errCh没有接收者，故一直阻塞在(2)出 因为(2)出的代码所在协程一直没有退出，故发生了内存泄露 这种情况处理起来也较为简单，只需将channel设置为有缓冲的就行。例如将(1)处代码改为errCh := make(chan error, 1)即可。 多个发送者导致的内存泄露产生原因也和上述相同，当接收者提前退出了，那么至少有一个goroutine无法退出，进而造成内存泄露。 12345678910111213141516171819202122232425262728293031func TestLeakOfMemory2(t *testing.T) &#123; fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) chanLeakOfMemory2() time.Sleep(time.Second * 3) // 等待 goroutine 执行，防止过早输出结果 fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine())&#125;func chanLeakOfMemory2() &#123; ich := make(chan int, 100) // (3) // sender go func() &#123; defer close(ich) for i := 0; i &lt; 10000; i++ &#123; ich &lt;- i time.Sleep(time.Millisecond) // 控制一下，别发太快 &#125; &#125;() // receiver go func() &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() for i := range ich &#123; // (2) if ctx.Err() != nil &#123; // (1) fmt.Println(ctx.Err()) return &#125; fmt.Println(i) &#125; &#125;()&#125; 尽管上述代码使用了有缓冲的channel，依然可能会出现接收者提前退出，导致有缓冲channel的缓存队列被占满，阻塞在第101个位置。这种情况需要使用一个额外的stop channel来结束发送者所在的goroutine，如下： 12345678910111213141516171819202122232425262728293031323334353637func TestLeakOfMemory2(t *testing.T) &#123; fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine()) chanLeakOfMemory2() time.Sleep(time.Second * 3) // 等待 goroutine 执行，防止过早输出结果 fmt.Println(&quot;NumGoroutine:&quot;, runtime.NumGoroutine())&#125;func chanLeakOfMemory2() &#123; ich := make(chan int, 100) stopCh := make(chan struct&#123;&#125;) // sender go func() &#123; defer close(ich) for i := 0; i &lt; 10000; i++ &#123; select &#123; case &lt;-stopCh: case ich &lt;- i: return &#125; time.Sleep(time.Millisecond) // 控制一下，别发太快 &#125; &#125;() // receiver go func() &#123; ctx, cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() for i := range ich &#123; if ctx.Err() != nil &#123; fmt.Println(ctx.Err()) close(stopCh) return &#125; fmt.Println(i) &#125; &#125;()&#125; 总结不论发送者发送一次还是多次，如果接收者在接收完channel中的数据之前退出，那么就会造成内存泄露。如果接收者需要在channel关闭之前退出，为了防止内存泄露，在发送者与接收者一对一时，应设置channel缓冲队列为1；在发送者与接收者一对多或多对多时，应使用专门的stop channel通知发送者关闭相应channel。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"关于channel发生死锁的情况总结","slug":"go/关于channel发生死锁的情况总结","date":"2021-11-03T13:09:18.000Z","updated":"2022-05-23T09:32:35.924Z","comments":true,"path":"2021/11/03/go/关于channel发生死锁的情况总结/","link":"","permalink":"https://zcej.github.io/2021/11/03/go/%E5%85%B3%E4%BA%8Echannel%E5%8F%91%E7%94%9F%E6%AD%BB%E9%94%81%E7%9A%84%E6%83%85%E5%86%B5%E6%80%BB%E7%BB%93/","excerpt":"","text":"时刻提醒自己必须深入理解channel的特性，有自己的思考，而不是死记硬背。之后可以阅读熟悉下channel的底层实现原理。 向无缓冲的channel发送&#x2F;接收数据无缓冲的channel必须有接收才能发送，下述代码在执行的时候会引发deadlock错误 12345func main() &#123; ch := make(chan int) ch &lt;- 1 // 这一行代码会引发死锁 // &lt;-ch // 直接取值也会引发死锁&#125; 解决方法是启用一个goroutine去接收值，如下： 12345678910func recv(c chan int) &#123; ret := &lt;-c fmt.Println(ret)&#125;func main() &#123; ch := make(chan int) go recv(ch) ch &lt;- 1&#125; 思考：下述情况会引发死锁吗？ 1234567func main() &#123; ch := make(chan int) go func() &#123; ch &lt;- 1 &#125;() time.Sleep(time.Second * 3)&#125; 答案是不会引发死锁，虽然子协程一直阻塞在传值语句，但是和主协程之间并无产生联系，当主协程退出的时候子协程也就跟着退出了。延伸：如果主协程和子协程之间建立了联系会产生死锁吗？ 123456789func main() &#123; ch1 := make(chan, int) ch2 := make(chan, int) go func() &#123; ch2 &lt;- 21 ch1 &lt;- 11 &#125;() &lt;-ch1&#125; 输出有缓冲的channel中所有的值当读取完channel中的数据后，继续读取的操作会造成阻塞，且阻塞发生在主协程中，故会引发阻塞。 12345678func main() &#123; ch := make(chan int, 2) ch &lt;- 1 ch &lt;- 2 for ch := range ch &#123; fmt.Println(ch) &#125;&#125; 解决方法是发送完所有数据后则关闭channel，或者通过select方法中的default进行处理，如下： 123456789101112131415161718func main() &#123; ch := make(chan int, 2) ch &lt;- 1 ch &lt;- 2 // solution 1: // close(ch) // solution 2: // select &#123; // case v := &lt;-ch: // fmt.Println(v) // default: // fmt.Println(&quot;nothing in channel&quot;) // &#125; for ch := range ch &#123; fmt.Println(ch) &#125;&#125; 过度向有缓冲的channel写入数据写入数据超过channel的容量的时候，也会引发死锁。 123456func main() &#123; ch := make(chan int, 2) ch &lt;- 1 ch &lt;- 2 ch &lt;- 3&#125; 解决方法是通过select方法中的default进行处理： 1234567891011func main() &#123; ch := make(chan int, 2) ch &lt;- 1 ch &lt;- 2 select &#123; case ch &lt;- 3: fmt.Println(&quot;ok&quot;) default: fmt.Println(&quot;wrong&quot;) &#125;&#125; 总结上述提到的死锁，是指在程序的主协程中发生的情况，如果上述情况是发生在非主协程中，读取或者写入的情况是发生阻塞的，而不是死锁(此时需要考虑是否需要主动关闭子协程)。实际上，阻塞情况省去了我们加锁的步骤，反而是更加有利于代码编写，要合理的运用阻塞。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"如何主动关闭goroutine","slug":"go/如何主动关闭goroutine？","date":"2021-10-22T12:22:41.000Z","updated":"2022-05-23T09:31:55.646Z","comments":true,"path":"2021/10/22/go/如何主动关闭goroutine？/","link":"","permalink":"https://zcej.github.io/2021/10/22/go/%E5%A6%82%E4%BD%95%E4%B8%BB%E5%8A%A8%E5%85%B3%E9%97%ADgoroutine%EF%BC%9F/","excerpt":"","text":"在学习go语言channel中，读到最多的一句话便是通过通信共享内存，而不是通过共享内存来进行通信（Do not communicate by sharing memory；instead，share memory by communicating.）那么如何来理解这句话呢？个人理解通过共享内存来通信的话必须保证数据的安全及正确性，即需要通过加锁等手段进行控制，但是此种方式带来的性能开销以及可能造成的死锁问题处理起来较为繁琐。而go语言则通过channel来通信，通过通信来传递内存数据，个人认为更加优雅简洁与高效。很多情况下我们需要主动关闭goroutine，那么如何实现呢？ 使用channel进行控制for-range结构for-range从channel上获取值，直到channel关闭。该结构对于从单一通道上获取数据去执行某些任务是十分方便的，如下所示： 123456789101112131415161718192021func producer(out chan&lt;- int) &#123; for i := 0; i &lt; 10; i++ &#123; data := i * i fmt.Println(&quot;生产者生产数据：&quot;, data) out &lt;- data &#125; close(out)&#125;func consumer(in &lt;-chan int) &#123; for data := range in &#123; fmt.Println(&quot;消费者得到数据：&quot;, data) &#125;&#125;func main() &#123; ch := make(chan int) go producer(ch) consumer(ch)&#125; for-select结构当channel比较多时，for-range结构就不是很方便了。此时可以使用for-select，select能够让goroutine在多个通信操作上等待（可以理解为监听多个channel）。 指定一个退出的channel12345678910111213141516171819202122232425262728func producer(out chan&lt;- int, exit chan struct&#123;&#125;) &#123; for i := 0; i &lt; 10; i++ &#123; data := i * i fmt.Println(&quot;生产者生产数据：&quot;, data) out &lt;- data &#125; exit &lt;- struct&#123;&#125;&#123;&#125;&#125;func consumer(in &lt;-chan int, exit chan struct&#123;&#125;) &#123; for &#123; select &#123; case &lt;-exit: fmt.Println(&quot;收到退出信号&quot;) // 不建议使用goto语句 return // 必须return, 否则goroutine不会结束 case data := &lt;-in: fmt.Println(&quot;消费者得到数据：&quot;, data) &#125; &#125;&#125;func main() &#123; ch := make(chan int) exitCh := make(chan struct&#123;&#125;) go producer(ch, exitCh) consumer(ch, exitCh)&#125; 多个channel都关闭才能退出12345678910111213141516171819202122232425262728293031323334353637383940func producer(out1, out2 chan&lt;- int) &#123; for i := 0; i &lt; 10; i++ &#123; data := i * i fmt.Println(&quot;生产者生产数据：&quot;, data) out1 &lt;- data time.Sleep(1 * time.Second) out2 &lt;- data * 2 &#125; close(out1) close(out2)&#125;func consumer(in1, in2 &lt;-chan int) &#123; for &#123; select &#123; case data, ok := &lt;-in1: if !ok &#123; fmt.Println(&quot;收到ch1关闭信号&quot;) in1 = nil &#125; fmt.Println(&quot;消费者得到数据：&quot;, data) case data, ok := &lt;-in2: if !ok &#123; fmt.Println(&quot;收到ch2关闭信号&quot;) in2 = nil &#125; fmt.Println(&quot;消费者得到数据：&quot;, data) &#125; if in1 == nil &amp;&amp; in2 == nil &#123; return &#125; &#125;&#125;func main() &#123; ch1 := make(chan int) ch2 := make(chan int) go producer(ch1, ch2) consumer(ch1, ch2)&#125; 使用content包进行控制context是官方提供的用于控制多个goroutine协作的包。 1234567891011121314151617181920212223242526272829303132333435363738394041func producer(out chan&lt;- int, ctx context.Context, cancel context.CancelFunc) &#123; for i := 0; i &lt; 10; i++ &#123; data := i * i fmt.Println(&quot;生产者生产数据：&quot;, data) out &lt;- data &#125; subCtx, _ := context.WithCancel(ctx) go consumer2(subCtx) cancel()&#125;func consumer(in &lt;-chan int, ctx context.Context) &#123; for &#123; select &#123; case data := &lt;-in: fmt.Println(&quot;消费者得到数据：&quot;, data) case &lt;-ctx.Done(): fmt.Println(&quot;收到结束信号&quot;) return // 必须return, 防止goroutine泄露 &#125; &#125;&#125;func consumer2(ctx context.Context) &#123; for &#123; select &#123; case &lt;-ctx.Done(): fmt.Println(&quot;收到结束信号, consumer2&quot;) return // 必须return, 防止goroutine泄露 &#125; &#125;&#125;func main() &#123; ctx, cancel := context.WithCancel(context.Background()) ch := make(chan int) go producer(ch, ctx, cancel) consumer(ch, ctx) time.Sleep(1 * time.Second)&#125; 总结在实际开发过程中，不会简单的启动goroutine就结束了。往往是需要有效的管理多个goroutine之间的协作，此时掌握如何主动关闭goroutine就显得尤为重要了。不仅如此，还需要学会分析go语言运行性能，下一个目标就是学习go语言中的性能大杀器pprof。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"如何控制并发速率","slug":"go/如何控制并发速率？","date":"2021-10-11T14:31:19.000Z","updated":"2022-05-23T09:28:14.399Z","comments":true,"path":"2021/10/11/go/如何控制并发速率？/","link":"","permalink":"https://zcej.github.io/2021/10/11/go/%E5%A6%82%E4%BD%95%E6%8E%A7%E5%88%B6%E5%B9%B6%E5%8F%91%E9%80%9F%E7%8E%87%EF%BC%9F/","excerpt":"","text":"为什么需要控制123456789101112func main() &#123; var wg sync.WaitGroup for i := 0; i &lt; math.MaxInt32; i++ &#123; wg.Add(1) go func(i int) &#123; defer wg.Done() fmt.Println(i) time.Sleep(time.Second) &#125;(i) &#125; wg.Wait()&#125; 过高的并发会将系统资源消耗殆尽，导致程序运行最终panic，关键的报错信息如下：panic: too many concurrent operations on a single file or socket (max 1048575) 导致出现上述错误的原因是源自fmt.Printf函数输出到标准输出，标准输出也可以视为文件，总之就是系统的资源被耗尽了。 就算注释掉fmt.Printf函数，也会因为内存不足而最终崩溃。 如何解决解决的主要方式就是限制并发的协程数量。 使用带缓冲的channel进行控制123456789101112131415func main() &#123; var wg sync.WaitGroup ch := make(chan struct&#123;&#125;, 3) for i := 0; i &lt; 10; i++ &#123; ch &lt;- struct&#123;&#125;&#123;&#125; wg.Add(1) go func(i int) &#123; defer wg.Done() log.Println(i) time.Sleep(time.Second) &lt;-ch &#125;(i) &#125; wg.Wait()&#125; 创建一个缓冲区大小为3的channel，在没有被接收的情况下，最多发送3个消息则被阻塞 开启协程前，调用ch &lt;- struct&#123;&#125;&#123;&#125;，若缓冲区满则阻塞 协程任务结束，调用&lt;-ch释放缓冲区 利用第三方库目前有很多第三方库实现了协程池，可以很方便的用来控制协程的并发数量，如Jeffail/tunny，panjf2000/ants，以tunny举例如下： 12345678910111213func main() &#123; pool := tunny.NewFunc(3, func(i interface&#123;&#125;) interface&#123;&#125; &#123; log.Println(i) time.Sleep(time.Second) return nil &#125;) defer pool.Close() for i := 0; i &lt; 10; i++ &#123; go pool.Process(i) &#125; time.Sleep(time.Second * 4)&#125; tunny.NewFunc(3, f)第一个参数是协程池的大小(poolSize)，第二个参数是协程运行的函数(worker) pool.Process(i)将参数i传递给协程池定义好的worker处理 pool.Close()关闭协程池 调整系统资源上限ulimit有些情况下，即使我们有效的限制了协程的并发数量，但是仍旧出现某一类资源不足的问题，例如： too many open files out of memory 操作系统通常会限制同时打开文件数量，栈空间大小等，ulimit -a可以看到系统的当前设置： 1234567891011121314151617[root@master ~]# ulimit -acore file size (blocks, -c) unlimiteddata seg size (kbytes, -d) unlimitedscheduling priority (-e) 0file size (blocks, -f) unlimitedpending signals (-i) 14997max locked memory (kbytes, -l) 64max memory size (kbytes, -m) unlimitedopen files (-n) 100001pipe size (512 bytes, -p) 8POSIX message queues (bytes, -q) 819200real-time priority (-r) 0stack size (kbytes, -s) 8192cpu time (seconds, -t) unlimitedmax user processes (-u) 14997virtual memory (kbytes, -v) unlimitedfile locks (-x) unlimited 进而进行按需调整即可。 虚拟内存virtual memory虚拟内存是一项非常常见的技术，当内存不足时，将磁盘映射为内存使用，比如linux下的交换分区(swap space)。在linux上创建并使用交换分区是一件非常简单的事情： 12345sudo fallocate -l 20G /mnt/.swapfile # 创建 20G 空文件sudo mkswap /mnt/.swapfile # 转换为交换分区文件sudo chmod 600 /mnt/.swapfile # 修改权限为 600sudo swapon /mnt/.swapfile # 激活交换分区free -m # 查看当前内存使用情况(包括交换分区) 关闭交换分区也非常简单： 12sudo swapoff /mnt/.swapfilerm -rf /mnt/.swapfile 磁盘的 I&#x2F;O 读写性能和内存条相差是非常大的，例如 DDR3 的内存条读写速率很容易达到 20GB&#x2F;s，但是 SSD 固态硬盘的读写性能通常只能达到 0.5GB&#x2F;s，相差 40倍之多。因此，使用虚拟内存技术将硬盘映射为内存使用，显然会对性能产生一定的影响。如果应用程序只是在较短的时间内需要较大的内存，那么虚拟内存能够有效避免 out of memory 的问题。如果应用程序长期高频度读写大量内存，那么虚拟内存对性能的影响就比较明显了。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"go语言实现爬虫(三)","slug":"go/个人项目实战：go语言实现爬虫(三)","date":"2021-09-15T16:12:23.000Z","updated":"2022-05-23T09:25:26.433Z","comments":true,"path":"2021/09/16/go/个人项目实战：go语言实现爬虫(三)/","link":"","permalink":"https://zcej.github.io/2021/09/16/go/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%EF%BC%9Ago%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E7%88%AC%E8%99%AB(%E4%B8%89)/","excerpt":"","text":"添加grpc简单编写proto文件： 1234567891011121314151617181920212223242526272829syntax = &quot;proto3&quot;;option go_package = &quot;./;proto&quot;;service Crawler &#123; rpc Start (StartReq) returns (TaskInfoResp) &#123;&#125; rpc Stop (TaskInfoReq) returns (TaskInfoResp) &#123;&#125; rpc Status (TaskInfoReq) returns (TaskInfoResp) &#123;&#125; rpc Pause (TaskInfoReq) returns (TaskInfoResp) &#123;&#125; rpc Resume (TaskInfoReq) returns (TaskInfoResp) &#123;&#125; rpc Result (TaskInfoReq) returns (TaskInfoResp) &#123;&#125;&#125;message StartReq &#123; string taskID = 1; repeated string urls = 2; int32 threads = 3; int32 timeout = 4; int32 depth = 5;&#125;message TaskInfoReq &#123; string taskID = 1;&#125;message TaskInfoResp &#123; int32 code = 1; string msg = 2; repeated string data = 3;&#125; 运行测试","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"go语言实现爬虫(二)","slug":"go/个人项目实战：go语言实现爬虫(二)","date":"2021-09-13T13:05:57.000Z","updated":"2022-05-23T09:23:53.972Z","comments":true,"path":"2021/09/13/go/个人项目实战：go语言实现爬虫(二)/","link":"","permalink":"https://zcej.github.io/2021/09/13/go/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%EF%BC%9Ago%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E7%88%AC%E8%99%AB(%E4%BA%8C)/","excerpt":"","text":"使用gin封装项目目录结构如下： api：主要业务逻辑实现，结合gin的上下文进行封装 config：项目主要配置文件 global：全局变量管理 model：结构体定义的地方 proto：定义proto文件，存放其生成的go文件 router：路由控制 storage：运行日志存储及临时结果存放 util：常用的工具类封装 1234567891011121314151617181920212223242526272829303132333435363738├─api│ │ base.go│ ││ └─crawler│ │ crawl.go│ ││ └─links│ links.go│├─config│ settings.go│├─global│ global.go│├─model│ ├─request│ │ request.go│ ││ └─response│ response.go│├─proto│ crawler.proto│├─router│ router.go│├─storage│ ├─logs│ └─tasks│─utils│ └─writer│ write_data.go│ go.mod│ go.sum│ main.go│ readme.md 完善各控制流程任务定义及初始化如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445type work struct &#123; url string // 网页链接 currDepth int // 当前深度&#125;type WlcTask struct &#123; taskID string // 任务ID workList chan []work // 存放每一个链接下一层的所有链接 workListBak chan []work // workList的备份, 用于任务的暂停与恢复 unVisitedLinks chan work // 存放未访问过的链接 stopSignalCh chan struct&#123;&#125; // 用于通知所有生产消费的goroutine退出, 防止内存泄露 quitCh chan struct&#123;&#125; // 用于主动停止任务, 通过递归深度判断 statusCh chan string // 用于记录任务状态变化 visited map[string]bool // 标记已访问过的链接 startUrl []work // 开始链接 concurrency int // 并发数量 timeOut int // 超时时间设置 depth int // 递归深度 currDepth int // 当前递归深度 status string // 任务状态 created running stopped finished pausing resuming&#125;func NewWclTask(wlcReq *request.WlcTaskReq) *WlcTask &#123; var startUrl []work for _, url := range wlcReq.Urls &#123; startUrl = append(startUrl, work&#123;url: url, currDepth: 1&#125;) &#125; workListCh := make(chan []work) return &amp;WlcTask&#123; taskID: wlcReq.TaskID, workList: workListCh, workListBak: workListCh, unVisitedLinks: make(chan work), stopSignalCh: make(chan struct&#123;&#125;), quitCh: make(chan struct&#123;&#125;), statusCh: make(chan string), visited: make(map[string]bool), startUrl: startUrl, concurrency: wlcReq.Concurrency, timeOut: wlcReq.Timeout, depth: wlcReq.Depth, currDepth: 1, status: config.TaskStatus.Created, &#125;&#125; 另外，还针对WlcTask封装了一个改变任务状态的方法： 1234567891011121314151617181920212223242526func (w *WlcTask) ChangeTaskStatus() &#123; for &#123; select &#123; case &lt;-w.stopSignalCh: log.Printf(&quot;[Start] record task(%s) status goroutine exit...&quot;, w.taskID) return case taskStr, ok := &lt;-w.statusCh: if ok &#123; arr := strings.Split(taskStr, &quot;,&quot;) w.status = arr[0] currDepth, err := strconv.Atoi(arr[1]) if err != nil &#123; log.Println(err) &#125; log.Printf(&quot;[Start] change task(%s) status to %s, depth is, %d&quot;, w.taskID, w.status, currDepth) // recode the task info to a json file task := request.TaskInfo&#123; Status: arr[0], CurrDepth: currDepth, &#125; writer.TaskInfoWriter(w.taskID, &amp;task) &#125; &#125; &#125;&#125; 启动12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061func (w *WlcTask) StartHandler(globalTask map[string]*WlcTask) &#123; // record the task status change go w.ChangeTaskStatus() go func() &#123; w.workList &lt;- w.startUrl &#125;() w.statusCh &lt;- fmt.Sprintf(&quot;%s,%d&quot;, config.TaskStatus.Running, w.currDepth) for i := 0; i &lt; w.concurrency; i++ &#123; go func(num int) &#123; for &#123; select &#123; case &lt;-w.stopSignalCh: log.Printf(&quot;[Start] task(%s) goroutine %d exit...&quot;, w.taskID, num) return case link, _ := &lt;-w.unVisitedLinks: foundLinks := crawl(link, w.depth, w.quitCh) go func() &#123; w.workList &lt;- foundLinks &#125;() &#125; &#125; &#125;(i) &#125; for &#123; select &#123; case list := &lt;-w.workList: // change taskStatus from resuming to running if w.status != config.TaskStatus.Running &#123; w.status = config.TaskStatus.Running &#125; for _, link := range list &#123; if !w.visited[link.url] &#123; w.visited[link.url] = true w.unVisitedLinks &lt;- link // write crawl result to file and update currDepth writer.TaskResultWriter(fmt.Sprintf(&quot;%s.txt&quot;, w.taskID), fmt.Sprintln(link.url)) if link.currDepth != w.currDepth &#123; w.currDepth = link.currDepth &#125; &#125; &#125; case &lt;-w.quitCh: log.Printf(&quot;[Start] task(%s) over than crawl depth, get quit signal and exit&quot;, w.taskID) w.statusCh &lt;- fmt.Sprintf(&quot;%s,%d&quot;, config.TaskStatus.Stopped, w.currDepth) close(w.stopSignalCh) delete(globalTask, w.taskID) return case &lt;-time.After(time.Duration(w.timeOut) * time.Second): if w.status == config.TaskStatus.Pausing || w.status == config.TaskStatus.Resuming &#123; continue &#125; else &#123; log.Printf(&quot;[Start] task(%s) execute timeout, get timeout signal and exit&quot;, w.taskID) w.statusCh &lt;- fmt.Sprintf(&quot;%s,%d&quot;, config.TaskStatus.Finished, w.currDepth) close(w.stopSignalCh) delete(globalTask, w.taskID) return &#125; &#125; &#125;&#125; 停止停止较为简单，直接向退出信号channel发送消息即可： 123func (w *WlcTask) StopHandler() &#123; w.quitCh &lt;- struct&#123;&#125;&#123;&#125;&#125; 暂停暂停的思路是将数据传输的channel赋值为nil，则相关的goroutine会阻塞进而整个执行暂停。 12345678910111213func (w *WlcTask) PauseHandler() &#123; if w.status == config.TaskStatus.Pausing &#123; log.Printf(&quot;[Pause] task(%s) is already pause, can&#x27;t pause again&quot;, w.taskID) return &#125; if w.status == config.TaskStatus.Stopped || w.status == config.TaskStatus.Finished &#123; log.Printf(&quot;[Pause] task(%s) is closed, can&#x27;t pause&quot;, w.taskID) return &#125; w.statusCh &lt;- fmt.Sprintf(&quot;%s,%d&quot;, config.TaskStatus.Pausing, w.currDepth) w.workList = nil log.Printf(&quot;[Pause] task(%s) is pausing&quot;, w.taskID)&#125; 恢复将之前备份好的数据channel重新赋值给当前使用的channel，则相关goroutine会接着运行。 123456789func (w *WlcTask) ResumingHandler() &#123; if w.status != config.TaskStatus.Pausing &#123; log.Printf(&quot;[Resume] task(%s) is not pausing, can&#x27;t resume&quot;, w.taskID) return &#125; w.workList = w.workListBak w.statusCh &lt;- fmt.Sprintf(&quot;%s,%d&quot;, config.TaskStatus.Resuming, w.currDepth) log.Printf(&quot;[Resume] task(%s) is resuming&quot;, w.taskID)&#125; 状态及结果获取状态获取： 123func (w *WlcTask) StatusHandler() (status string, currDepth int) &#123; return w.status, w.currDepth&#125; 结果获取： 12345678func ResultHandler(taskID string) (links []string, err error) &#123; f, err := ioutil.ReadFile(taskID + &quot;.txt&quot;) if err != nil &#123; return nil, err &#125; links = strings.Split(string(f), &quot;\\n&quot;) return links[:len(links)-1], nil&#125; 思考 本文使用的是channel控制整个流程，当换成标准库context时如何编写？ 路由的地方有重复性的地方，考虑如何优化？ 当前项目未自定义错误，如何完善整个项目的异常处理？","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"go语言实现爬虫(一)","slug":"go/个人项目实战：go语言实现爬虫(一)","date":"2021-09-06T11:47:11.000Z","updated":"2022-05-23T09:22:25.168Z","comments":true,"path":"2021/09/06/go/个人项目实战：go语言实现爬虫(一)/","link":"","permalink":"https://zcej.github.io/2021/09/06/go/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%EF%BC%9Ago%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0%E7%88%AC%E8%99%AB(%E4%B8%80)/","excerpt":"","text":"本项目适合在快速学习完go语言后的一个简单练手，主要达成以下功能： 能够递归的抓取网页链接，通过递归深度进行控制停止 支持爬取的并发控制，超时处理，以及其执行过程的暂停与恢复 基于gin提供restful的api接口，包括启动，停止，暂停，恢复，查看状态，获取结果等 提供grpc远程调用功能，并调研grpc-gateway，简单做一个学习案例 注：本文仅总结了重要的部分，还需不断进行完善，具体项目点击链接查看。 页面解析依赖模块golang.org/x/net/html，Extract函数向给定URL发起HTTP GET请求，解析HTML并返回HTML文档中存在的链接，如果要在此部分添加或删除规则，那么可以修改此函数。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364func Extract(url string) ([]string, error) &#123; resp, err := http.Get(url) if err != nil &#123; return nil, err &#125; if resp.StatusCode != http.StatusOK &#123; return nil, fmt.Errorf(&quot;getting %s: %s&quot;, url, resp.Status) &#125; doc, err := html.Parse(resp.Body) defer resp.Body.Close() if err != nil &#123; return nil, fmt.Errorf(&quot;parsing %s as HTML: %v&quot;, url, err) &#125; var links []string visitNode := func(n *html.Node) &#123; if n.Type == html.ElementNode &amp;&amp; n.Data == &quot;a&quot; &#123; for _, a := range n.Attr &#123; if a.Key != &quot;href&quot; &#123; continue &#125; link, err := resp.Request.URL.Parse(a.Val) if err != nil &#123; continue // ignore bad URLs &#125; links = append(links, link.String()) &#125; &#125; &#125; forEachNode(doc, visitNode, nil) //forEachNode(doc, startElement, endElement) return links, nil&#125;func forEachNode(n *html.Node, pre, post func(n *html.Node)) &#123; if pre != nil &#123; pre(n) &#125; for c := n.FirstChild; c != nil; c = c.NextSibling &#123; forEachNode(c, pre, post) &#125; if post != nil &#123; post(n) &#125;&#125;var depth intfunc startElement(n *html.Node) &#123; if n.Type == html.ElementNode &#123; fmt.Printf(&quot;%*s&lt;%s&gt;\\n&quot;, depth*2, &quot;&quot;, n.Data) depth++ &#125;&#125;func endElement(n *html.Node) &#123; if n.Type == html.ElementNode &#123; depth-- fmt.Printf(&quot;%*s&lt;/%s&gt;\\n&quot;, depth*2, &quot;&quot;, n.Data) &#125;&#125; 然后再根据广度优先遍历的思想新建一个函数breadthFirst，breadthFirst对每个worklist元素调用f，并将返回的内容添加到worklist中，对每一个元素，最多调用一次f。 123456789101112131415161718192021222324252627282930313233343536373839func breadthFirst(f func(item string) []string, worklist []string) &#123; seen := make(map[string]bool) for len(worklist) &gt; 0 &#123; items := worklist worklist = nil for _, item := range items &#123; if !seen[item] &#123; seen[item] = true worklist = append(worklist, f(item)...) &#125; &#125; &#125;&#125;func crawl(urlStr string) []string &#123; fmt.Println(urlStr) list, err := links.Extract(urlStr) if err != nil &#123; log.Print(err) &#125; //// extract same domain //var filterList []string //u, _ := url.Parse(urlStr) //for _, link := range list &#123; // l, _ := url.Parse(link) // if u.Hostname() == l.Hostname() &#123; // filterList = append(filterList, link) // &#125; //&#125; return list&#125;func main() &#123; urls := []string&#123;&quot;http://www.xxxx.com&quot;&#125; breadthFirst(crawl, urls)&#125; 并发控制在go语言中实现并发较为简单，只需要在函数定义前加上关键字go即可。对于爬虫而言，过高的并行度也不是一个好的做法，如何合理的控制并发速率也成为了当前需要控制的重点，下面介绍两种并发控制方式。 方式一利用有缓冲的channel控制并发，并灵活的通过一个计数器n来控制程序自动结束。 12345678910111213141516171819202122232425262728293031323334353637383940// tokens is a counting semaphore used to// enforce a limit of 20 concurrent requests.var tokens = make(chan struct&#123;&#125;, 20)func crawl(url string) []string &#123; fmt.Println(url) tokens &lt;- struct&#123;&#125;&#123;&#125; // acquire a token list, err := links.Extract(url) &lt;-tokens // release the token if err != nil &#123; log.Print(err) &#125; return list&#125;func main() &#123; worklist := make(chan []string) var n int url := &quot;http://www.xxxx.com&quot; // start n++ go func() &#123; worklist &lt;- []string&#123;url&#125; &#125;() // crawl the web concurrently visited := make(map[string]bool) for ; n &gt; 0; n-- &#123; list := &lt;-worklist for _, link := range list &#123; if !visited[link] &#123; visited[link] = true n++ go func(link string) &#123; worklist &lt;- crawl(link) &#125;(link) &#125; &#125; &#125;&#125; 方式二使用一定数量常驻goroutine控制并发，并在channel中没有数据后一定时间内超时退出。 123456789101112131415161718192021222324252627282930313233func main() &#123; worklist := make(chan []string) // lists of URLs, may have duplicates unseenLinks := make(chan string) // de-duplicated URLs // Add command-line arguments to worklist. go func() &#123; worklist &lt;- os.Args[1:] &#125;() // Create 20 crawler goroutines to fetch each unseen link. for i := 0; i &lt; 20; i++ &#123; go func() &#123; for link := range unseenLinks &#123; foundLinks := crawl(link) go func() &#123; worklist &lt;- foundLinks &#125;() &#125; &#125;() &#125; // The main goroutine de-duplicates worklist items // and sends the unseen ones to the crawlers. seen := make(map[string]bool) for &#123; select &#123; case list := &lt;-worklist &#123; for _, link := range list &#123; if !seen[link] &#123; seen[link] = true unseenLinks &lt;- link &#125; &#125; case &lt;- time.After(3 * time.Second) fmt.Println(&quot;Exit, timeout&quot;) return &#125; &#125;&#125; 递归深度要控制抓取的递归深度可以从crawl函数入手，将url进行封装，添加一个depth属性，当获取这个url的下一层链接时则对depth进行加一。另外还需添加一个信号控制channel，当递归层数满足要求时，发送信号控制程序退出。 123456789101112131415161718192021222324type work struct &#123; url string depth int&#125;func crawl(w work, quit chan struct&#123;&#125;) []work &#123; fmt.Printf(&quot;depth: %d, url: %s\\n&quot;, w.depth, w.url) if w.depth &gt; 3 &#123; quit &lt;- struct&#123;&#125;&#123;&#125; return nil &#125; urls, err := links.Extract(w.url) if err != nil &#123; log.Print(err) &#125; var works []work for _, url := range urls &#123; works = append(works, work&#123;url, w.depth + 1&#125;) &#125; return works&#125;","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"go语言中string和[]byte之间的转换","slug":"go/go语言中string和[]byte之间的转换","date":"2021-08-29T14:52:38.000Z","updated":"2022-05-23T09:19:41.222Z","comments":true,"path":"2021/08/29/go/go语言中string和[]byte之间的转换/","link":"","permalink":"https://zcej.github.io/2021/08/29/go/go%E8%AF%AD%E8%A8%80%E4%B8%ADstring%E5%92%8C[]byte%E4%B9%8B%E9%97%B4%E7%9A%84%E8%BD%AC%E6%8D%A2/","excerpt":"","text":"在项目实际运用中发现数据量较大时，通过pprof进行性能分析发现string到byte的标准转换内存消耗十分大，后使用了unsafe包进行强转后性能有了很大的提升，在此记录下。 转换方式标准转换123456// string to []bytes1 := &quot;hello&quot;b := []byte(s1)// []byte to strings2 := string(b) 强转换1234567func string2bytes(s string) []byte &#123; return *(*[]byte)(unsafe.Pointer(&amp;s))&#125;func bytes2string(b []byte) string &#123; return *(*string)(unsafe.Pointer(&amp;b))&#125; 性能对比123456789101112131415161718192021222324252627func Benchmark_NormalString2Bytes(b *testing.B) &#123; x := &quot;Test Normal String 2 Bytes With Go!&quot; for i := 0; i &lt; b.N; i++ &#123; _ = []byte(x) &#125;&#125;func Benchmark_Bytes2String(b *testing.B) &#123; x := []byte(&quot;Test Unsafe Bytes 2 String With Go!&quot;) for i := 0; i &lt; b.N; i++ &#123; _ = bytes2string(x) &#125;&#125;func Benchmark_NormalString2Bytes(b *testing.B) &#123; x := &quot;Test Normal String 2 Bytes With Go!&quot; for i := 0; i &lt; b.N; i++ &#123; _ = []byte(x) &#125;&#125;func Benchmark_String2Bytes(b *testing.B) &#123; x := &quot;Test Normal String 2 Bytes With Go!&quot; for i := 0; i &lt; b.N; i++ &#123; _ = string2bytes(x) &#125;&#125; 测试结果如下： 123456789101112D:\\goproject\\study_go\\study_unsafe\\test_byte_string&gt;go test -bench=&quot;.&quot; -benchmemgoos: windowsgoarch: amd64pkg: study_go/study_unsafe/test_byte_stringcpu: Intel(R) Core(TM) i7-9750H CPU @ 2.60GHzBenchmark_NormalBytes2String-12 43473496 28.20 ns/op 48 B/op 1 allocs/opBenchmark_Bytes2String-12 1000000000 0.2593 ns/op 0 B/op 0 allocs/opBenchmark_NormalString2Bytes-12 31570804 35.06 ns/op 48 B/op 1 allocs/opBenchmark_String2Bytes-12 1000000000 0.2626 ns/op 0 B/op 0 allocs/opPASSok study_go/study_unsafe/test_byte_string 4.436s 由上述可见，强转换性能明显优于标准转换 原理分析首先需要了解string和slice的底层数据结构： 12345678910type StringHeader struct &#123; Data uintptr Len int&#125;type SliceHeader struct &#123; Data uintptr Len int Cap int&#125; 在go中，任何类型的指针*T都可以转化为unsafe.Pointer类型的指针，它可以存储任何变量的地址 unsafe.Pointer类型的指针也可以转换回普通指针，而且不必和之前的类型*T相同 unsafe.Pointer类型还可以转换为uintptr类型，该类型保存了指针所指向地址的数值，从而可以对地址进行数值计算。 思考总结为什么强转换性能比标准转换好？ 对于标准转换，无论是从[]byte转string还是从string转[]byte都会涉及到底层数组的拷贝。而强转换是直接替换指针的指向，从而使得string和[]byte指向同一个底层数组。故后者的性能会更好 在上述测试中，当数据较大时，标准转换会有一次分配内存的操作，从而导致其性能更差，而为什么强转换不受影响？ 标准转换时，当数据长度大于32个字节时，需要通过mallocgc申请新的内存，之后再进行数据拷贝工作。而强转换只是更改指针的指向。故当数据较大时，两者性能差距越明显。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"go语言中的数据结构","slug":"go/go语言中的数据结构","date":"2021-08-21T15:01:04.000Z","updated":"2022-05-23T09:16:46.641Z","comments":true,"path":"2021/08/21/go/go语言中的数据结构/","link":"","permalink":"https://zcej.github.io/2021/08/21/go/go%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","excerpt":"","text":"数组初始化12arr1 := [3]int&#123;1, 2, 3&#125; // 显示指定数组大小arr2 := [...]int&#123;1, 2 ,3&#125; // 使用[...]T声明数组 [...]T初始化数组的方式是go语言提供的一种语法糖，最终也会转化为具体元素数量 在不考虑逃逸分析的情况下，如果数组中元素个数小于等于4个，则所有的变量会直接在栈上初始化；反之如果数组元素大于4个，变量就会在静态存储去初始化然后拷贝到栈上。 访问和赋值 无论是在栈上还是静态存储区，数组在内存中都是一连串的内存空间。我们通过指向数组开头的指针、元素的数量以及元素类型占的空间大小表示数组。 数组和字符串的一些简单的越界错误都会在编译期间发现。如使用整数或常量访问数组，但是如果使用变量去访问数组或字符串时，编译器就无法提前发现错误，此时会在运行时阻止不合法的访问。小结对数组的访问和赋值同时需要依赖编译器和运行时支持，其大多数操作在编译期间都会转换成直接读写内存，在中间代码生成期间，编译器还会插入运行时方法runtime.panicIndex防止发生越界错误。切片数据结构切片在运行时由reflect.SliceHeader结构体表示，如下：12345type SliceHeader struct &#123; Data uintptr // 指向数组的指针 Len int // 当前切片的长度 Cap int // 当前切片的容量, 即Data数组的大小&#125; 初始化有以下三种初始化切片的方式：12345678// 1. 通过下标的方式获得数组或切片的一部分arr[0:3] or slice[0:3]// 2. 使用字面量初始化新的切片slice := []int&#123;1, 2, 3&#125;// 3. 使用make关键字slice := make([]int, 10) 使用下标：使用下标初始化切片不会拷贝原数组或原切片中的数据，它只会创建一个指向原数组的切片结构体，所以修改新切片的数据也会修改原切片。 使用字面量：根据切片中的元素数量对底层数组的大小进行推断并创建一个数组，将字面量元素存储到初始化的数组中，创建一个同样指向相同类型的数组指针，将初始化的数组赋值给指针所在的地址，通过[:]操作获取一个底层使用该地址的切片。 访问元素切片的操作基本都是在编译期间完成的，除了访问切片的长度、容量或者其中的元素之外，编译期间也会将包含range关键字的遍历转换成形式更简单的循环。 追加和扩容当切片容量不足时，会调用runtime.growslice进行切片扩容。扩容是为切片分配新的内存空间并拷贝原切片中元素的过程，那么新切片的容量如何确定呢？ 如果期望容量大于当前容量的两倍就会使用当前容量 如果当前切片的长度小于1024就会将容量翻倍 如果当前切片的长度大于1024就会每次增加25%的容量，直到新容量大于期望容量 另外上述调用仅会确定切片的大致容量，还需要根据切片中的元素大小进行内存对齐。 拷贝切片无论是编译期间拷贝还是运行时拷贝，两种拷贝方式都会通过runtime.memmove将整块内存的内容拷贝到目标的内存区域中，相比于依次拷贝元素，runtime.memmove能提供更好的性能。 小结切片的很多功能都是由运行时实现的，无论是初始化切片，还是对切片进行追加或扩容都需要运行时的支持，需要注意的是在遇到大切片扩容或者复制时可能会发生大规模的内存拷贝，一定要减少类似的操作避免影响程序的性能。 字典哈希冲突开放寻址法拉链法 数据结构go语言运行时使用了多个数据结构组合表示哈希表，最核心的结构体runtime.hmap如下所示： 12345678910111213141516171819type hmap struct &#123; count int // 表示当前哈希表中的元素数量 flags uint8 B uint8 // 表示当前哈希表持有的buckets数量(都是2的倍数) noverflow uint16 hash0 uint32 // 哈希种子，为哈希函数的结果引入随机性 buckets unsafe.Pointer oldbuckets unsafe.Pointer // 扩容时用于保存之前buckets字段 nevacuate uintptr extra *mapextra&#125;type mapextra struct &#123; overflow *[]*bmap oldoverflow *[]*bmap nextOverflow *bmap&#125; 如上所示哈希表runtime.hmap的桶是runtime.bmap，每一个runtime.bmap都能存储8个键值对。当哈希表中存储的数据过多，单个桶已经装满时就会使用extra.nextOverflow中桶存储溢出的数据。这两种不同的桶在内存中都是连续的，分别称之为正常桶和溢出桶 初始化字面量 12345hash := map[string]int&#123; &quot;1&quot;: 2, &quot;2&quot;: 4, &quot;5&quot;: 6,&#125; 使用字面量初始化的过程都会使用go语言中的关键字make来创建新的哈希并通过最原始的[]语法向哈希追加元素，另外最终都是调用runtime.makemap。 读写操作扩容在以下两种情况下会进行扩容： 装载因子已经超过6.5 哈希使用了太多溢出桶 小结 go语言使用了拉链法来解决哈希碰撞的问题实现了哈希表，它的读写等操作都是在编译期间转换成了运行时的函数或方法。哈希在每一个桶中存储键对应哈希的前8位，当对哈希进行操作时，这些tophash就成为可以帮助哈希快速遍历桶中元素的缓存。 哈希表的每个桶都只能存储8个键值对，一旦当前哈希的某个桶超出8个，新的键值对就会存储到哈希的溢出桶中。随着键值对数量的增加，溢出桶的数量和哈希的装载因子也会逐渐升高，超过一定范围就会触发扩容，扩容会将桶的数量翻倍，元素再分配的过程也是在调用写操作时增量进行的，不会造成性能的瞬时巨大抖动。字符串数据结构字符串在运行时会使用如下的reflect.StringHeader表示：1234type StringHeader struct &#123; Data uintptr // 指向字节数组的指针 Len int // 数组的大小&#125; 字符串是只读的类型，我们并不会直接向字符串追加元素改变其本身的内存空间，所有字符串上的写入操作都是通过拷贝实现的。 解析过程1234str1 := &quot;this is a string&quot;str2 := `this is anotherstring` 类型转换 当解析和序列化json等数据格式时，经常需要将数据在string和[]byte之间来回转换，而类型转换的开销并没有想象的那么小。 字符串和[]byte中的内容虽然一样，但是字符串的内容是只读的，我们不能通过下标或者其他形式改变其中的数据，而跑[]byte中的内容是可读写的。不过无论从哪种类型转换到另一种都需要拷贝数据，而内存拷贝的性能损耗会随着字符串和[]byte长度的增长而增长。小结字符串作为只读的数据类型，我们无法改变其本身的结构，但是在做拼接和类型转换等操作时一定要注意性能的损耗，遇到需要极致性能的场景一定要尽量减少类型转换的次数。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"go语言中make和new的区别","slug":"go/go语言中make和new的区别","date":"2021-08-03T13:11:27.000Z","updated":"2022-05-23T01:08:55.098Z","comments":true,"path":"2021/08/03/go/go语言中make和new的区别/","link":"","permalink":"https://zcej.github.io/2021/08/03/go/go%E8%AF%AD%E8%A8%80%E4%B8%ADmake%E5%92%8Cnew%E7%9A%84%E5%8C%BA%E5%88%AB/","excerpt":"","text":"make用于初始化内置的数据结构，如slice，map，channel new的作用是根据传入的类型分配一片内存空间并返回指向这片内存空间的指针123slice := make([]int, 0, 100)hash := make(map[int]bool, 10)ch := make(chan int, 5) slice是一个包含data，cap和len的结构体reflect.SliceHeader hash是一个指向runtime.hmap结构体的指针 ch是一个指向runtime.hchan结构体的指针 1234i := new(int)var v inti := &amp;v 上述代码片段两种初始化方法是等价的，它们都会创建一个指向int零值的指针 make在编译期间的类型检查阶段，go语言会将代表make关键字的OMAKE节点根据参数类型的不同转换成了OMAKESLICE、OMAKEMAP和OMAKECHAN三种不同类型的节点，这些节点会调用不同的运行时函数来初始化相应的数据结构。 new编译器会在中间代码生成阶段通过以下两个函数处理该关键字： cmd/compile/internal/gc.callnew会将关键字转换成ONEWOBJ类型的节点 cmd/complie/internal/gc.state.expr会根据申请空间的大小分两种情况处理 如果申请的空间为0，就会返回一个表示空指针的zerobase变量 在遇到其他情况时会将关键字转换成runtime.newobject函数小结简单总结一下go语言中make和new关键字的实现原理，make关键字的作用是创建切片、哈希表和Channel等内置的数据结构，而new的作用是为类型申请一片内存空间，并返回指向这片内存的指针。","categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"}],"tags":[]},{"title":"在Django中使用缓存","slug":"django/在Django中使用缓存","date":"2020-08-16T04:19:21.000Z","updated":"2022-05-23T08:48:36.373Z","comments":true,"path":"2020/08/16/django/在Django中使用缓存/","link":"","permalink":"https://zcej.github.io/2020/08/16/django/%E5%9C%A8Django%E4%B8%AD%E4%BD%BF%E7%94%A8%E7%BC%93%E5%AD%98/","excerpt":"","text":"快速开始缓存是什么(What?) 缓存就是数据交换的缓冲区(称作Cache)，是存储数据的临时地方。当用户查询数据，首先在缓存中寻找，如果找到了则直接执行。如果找不到，则去数据库查找。 缓存的本质就是用空间换时间，牺牲数据的实时性，以服务器内存中的数据暂时代替从数据库读取的数据，减少数据库IO，减轻服务器压力，减少网络延迟，加快页面打开速度。 存储介质访问速度比较 来自Google工程师Jeff Dean的分享，仅供参考： 存储介质 速度 L1 cache reference 读取CPU的一级缓存 0.5 ns Branch mispredict(转移、分支预测) 5 ns L2 cache reference 读取CPU的二级缓存 7 ns Mutex lock&#x2F;unlock 互斥锁\\解锁 100 ns Main memory reference 读取内存数据 100 ns Compress 1K bytes with Zippy 1k字节压缩 10,000 ns Send 2K bytes over 1 Gbps network 在1Gbps的网络上发送2k字节 20,000 ns Read 1 MB sequentially from memory 从内存顺序读取1MB 250,000 ns Round trip within same datacenter 从一个数据中心往返一次，ping一下 500,000 ns Disk seek 磁盘搜索 10,000,000 ns Read 1 MB sequentially from network从网络上顺序读取1兆的数据 10,000,000 ns Read 1 MB sequentially from disk 从磁盘里面读出1MB 30,000,000 ns Send packet CA-&gt;Netherlands-&gt;CA 一个包的一次远程访问 150,000,000 ns 访问流程： 1234567graph TBA(读操作_) --&gt; B&#123;查询缓存_&#125;B --&gt; |有缓存_| C[返回_]B --&gt; |无缓存_| D[查询数据库_]D --&gt; E[放入缓存_] 缓存的优点: 减少了磁盘和网络IO来提高吞吐量，减少计算量(CPU计算)释放CPU，提高系统的响应速度。 面向切面的处理发出，可以在各层进行插拔，是所有性能优化的最简单有效的解决方案。 缓存应用场景(Where?) 对于数据实时性要求不高对于一些经常访问但是很少改变的数据，读明显多于写，使用缓存就很有必要。比如一些网站配置项。 对于性能要求高比如一些秒杀活动场景。 基于DRF快速开始(How?)pip install drf-extensions key值计算: {“view_instance”: “”, “view_method”: “”, “request”:””, “args”:””, “kwargs”: “”} –&gt; json –&gt; md5\\rest_framework_extensions\\key_constructor\\constructors.py 123456789101112131415161718192021222324252627282930313233343536373839404142# settings.py REST_FRAMEWORK_EXTENSIONS = &#123; &#x27;DEFAULT_OBJECT_CACHE_KEY_FUNC&#x27;: &#x27;rest_framework_extensions.utils.default_object_cache_key_func&#x27;, &#x27;DEFAULT_LIST_CACHE_KEY_FUNC&#x27;: &#x27;rest_framework_extensions.utils.default_list_cache_key_func&#x27;, &#x27;DEFAULT_CACHE_RESPONSE_TIMEOUT&#x27;: 60 * 15, &#x27;DEFAULT_CACHE_ERRORS&#x27;: False &#125; # views.py # usage 1: don&#x27;t overwirte list, retrieve method from rest_framework_extensions.cache.mixins import CacheResponseMixin class StudentViewSet(CacheResponseMixin, viewsets.ModelViewSet): pass # usage: 2 from rest_framework_extensions.cache.decorators import cache_response from rest_framework_extensions.utils import default_object_cache_key_func class StudentViewSet(CacheResponseMixin, viewsets.ModelViewSet): @cache_response(key_func=default_object_cache_key_func, cache_errors=False) def retrieve(self, request, *args, **kwargs): pass ``` &gt; python自带的缓存机制```pythonimport timeitfrom functools import lru_cache# @lru_cache(None)def fib(n): if n &lt; 2: return n return fib(n - 2) + fib(n - 1) print(timeit.timeit(lambda: fib(35), number=1)) 一、缓存类型1. 数据库缓存 常用的缓存方案有memcached、redis等 。把经常要从数据库查询的数据，或经常更新的数据放入到缓存中。这样下次查询时，直接从缓存直接返回，减轻数据库压力，提升数据库性能。 2. 服务器端缓存2.1 代理服务器缓存 代理服务器是浏览器和源服务器之间的中间服务器，浏览器先向这个中间服务器发起Web请求，经过处理后(比如权限验证，缓存匹配等)，再将请求转发到源服务器。 代理服务器缓存的运作原理跟浏览器的运作原理差不多，只是规模更大。可以把它理解为一个共享缓存，不只为一个用户服务，一般为大量用户提供服务，因此在减少响应时间和带宽使用方面很有效，同一个副本会被重用多次。 2.2 CDN缓存 也叫网关缓存、反向代理缓存。CDN缓存一般是由网站管理员自己部署，为了让他们的网站更容易扩展并获得更好的性能。 浏览器先向CDN网关发起Web请求，网关服务器后面对应着一台或多台负载均衡源服务器，会根据它们的负载请求，动态将请求转发到合适的源服务器上。 虽然这种架构负载均衡源服务器之间的缓存没法共享，但却拥有更好的处扩展性。从浏览器角度来看，整个CDN就是一个源服务器。 2.3 DNS缓存 万维网上作为域名和IP地址相互映射的一个分布式数据库，能够使用户更方便的访问互联网，而不用去记住能够被机器直接读取的IP数串。DNS协议运行在UDP协议之上，使用端口号53。 有dns的地方,就有缓存。浏览器、操作系统、Local DNS、根域名服务器，它们都会对DNS结果做一定程度的缓存。 DNS查询过程如下: 首先搜索浏览器自身的DNS缓存,如果存在，则域名解析到此完成。 如果浏览器自身的缓存里面没有找到对应的条目，那么会尝试读取操作系统的hosts文件看是否存在对应的映射关系,如果存在，则域名解析到此完成。 如果本地hosts文件不存在映射关系，则查找本地DNS服务器(ISP服务器,或者自己手动设置的DNS服务器),如果存在,域名到此解析完成。 如果本地DNS服务器还没找到的话,它就会向根服务器发出请求,进行递归查询。 3. 浏览器缓存 浏览器缓存根据一套与服务器约定的规则进行工作，在同一个会话过程中会检查一次并确定缓存的副本足够新。如果在浏览过程中前进或后退时访问到同一个图片，这些图片可以从浏览器缓存中调出而即时显示。 4. web应用层缓存 应用层缓存指的是从代码层面上，通过代码逻辑和缓存策略，实现对数据、页面、图片等资源的缓存，可以根据实际情况选择将数据存在文件系统或者内存中，减少数据库查询或者读写瓶颈，提高响应效率。 二、缓存淘汰策略1. FIFOFIFO (First in First out)， 先进先出。核心原则就是: 如果一个数据最先进入缓存中，则应最早淘汰掉。 2. LFULFU (Least Frequently Used)，最不频繁使用，以使用次数作为参考。 核心思想：如果数据过去被访问多次，那么将来被访问的几率也更高。 3. LRULRU(Least Recently Used)，最近最少使用，以时间作为参考。 核心思想：如果数据最近被访问过，那么将来被访问的频率也更高 三、Django缓存系统伪代码解释动态网站生成页面时，缓存是怎么工作的 123456789101112131415161718192021222324given a URL, try finding that page in the cache if the page is in the cache: return the cached page else: generate the page save the generated page in the cache (for next time) return the generated page ``` ## 设置缓存 ### django-redis - 更多详细配置参阅[官方文档](https://github.com/jazzband/django-redis)- `pip install django-redis` ```pythonCACHES = &#123; &quot;default&quot;: &#123; &quot;BACKEND&quot;: &quot;django_redis.cache.RedisCache&quot;, &quot;LOCATION&quot;: &quot;redis://127.0.0.1:6379/1&quot;, # &quot;LOCATION&quot;: &quot;redis://username:password@localhost:6379/0&quot; &quot;OPTIONS&quot;: &#123; &quot;CLIENT_CLASS&quot;: &quot;django_redis.client.DefaultClient&quot;, &#125; &#125;&#125; memcached 完全基于内存的缓存服务器： 是Django支持的最快，最高效的缓存类型。—&gt; Facebook，Wikipedia都有使用其来减少数据库访问并显著提高网站性能缓存的数据存储在内存中，如果服务器崩溃，那么数据将会丢失。 pip install python-memached pip install pylibmc 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115# use python-memcached CACHES = &#123; &#x27;default&#x27;: &#123; &#x27;BACKEND&#x27;: &#x27;django.core.cache.backends.memcached.MemcachedCache&#x27;, &#x27;LOCATION&#x27;: &#x27;127.0.0.1:11211&#x27;, # &#x27;LOCATION&#x27;: &#x27;unix:/tmp/memcached.sock&#x27;, # 能在多个服务器上共享缓存，即无需再每台机器上复制缓存值 # &#x27;LOCATION&#x27;: [ # &#x27;172.19.26.240:11211&#x27;, # &#x27;172.19.26.242:11211&#x27;, # ] &#125; &#125; # use pylibmc CACHES = &#123; &#x27;default&#x27;: &#123; &#x27;BACKEND&#x27;: &#x27;django.core.cache.backends.memcached.PyLibMCCache&#x27;, &#x27;LOCATION&#x27;: &#x27;/tmp/memcached.sock&#x27;, &#125; &#125; ``` ### 数据库缓存 - 适用于有一个快速，索引正常的数据库服务器。 - `python manage.py createcachetable` ```python CACHES = &#123; &#x27;default&#x27;: &#123; &#x27;BACKEND&#x27;: &#x27;django.core.cache.backends.db.DatabaseCache&#x27;, &#x27;LOCATION&#x27;: &#x27;my_cache_table&#x27;, &#125; &#125; ``` ### 文件系统缓存 - 一个缓存值为一个单独的文件 - 注意指定目的写权限问题。 ```python CACHES = &#123; &#x27;default&#x27;: &#123; &#x27;BACKEND&#x27;: &#x27;django.core.cache.backends.filebased.FileBasedCache&#x27;, &#x27;LOCATION&#x27;: &#x27;/var/tmp/django_cache&#x27;, # &#x27;LOCATION&#x27;: &#x27;c:/foo/bar&#x27;, &#125; &#125; ``` ### 本地内存缓存 - 是默认的缓存方式 - 使用LRU淘汰策略 &gt; 每个进程都有其自己的私有缓存实例，意味着不存在跨进程的缓存。 &gt; 也意味着本地缓存不是特别节省内存，不是生产环境的好选择，但在开发环境表现很好。 ```python CACHES = &#123; &#x27;default&#x27;: &#123; &#x27;BACKEND&#x27;: &#x27;django.core.cache.backends.locmem.LocMemCache&#x27;, &#x27;LOCATION&#x27;: &#x27;unique-snowflake&#x27;, &#125; &#125; ``` ### 虚拟缓存(用于开发模式) - 只是实现了缓存接口，并不做其他操作 - 如果你有一个正式网站在不同地方使用了重型缓存，但你不想在开发环境使用缓存时非常有用。 ```python CACHES = &#123; &#x27;default&#x27;: &#123; &#x27;BACKEND&#x27;: &#x27;django.core.cache.backends.dummy.DummyCache&#x27;, &#125; &#125; ``` ### 缓存参数 - **`TIMEOUT`**: 超时时间，默认为300秒。设置为`None`表示永不过时。 - **`OPTIONS`**: 实现自有的淘汰策略的缓存后端（比如 `locmem`, `filesystem` 和 `database` 后端）将遵循以下选项 -- **`MAX_ENTRIES`**: 允许缓存的最大条目， 默认为300。 -- **`CULL_FREQUENCY`**: 当达到最大条目时淘汰的条目数量，默认为3。比率为1 / CULL_FREQUENCY，为0是清空整个缓存。 - **`KEY_PREFIX`**: Django 服务器使用的所有缓存键的字符串。 - **`VERSION`**: 通过 Django 服务器生成的缓存键的默认版本号。 - **`KEY_FUNCTION`**: 一个包含指向函数的路径的字符串，该函数定义将如何前缀、版本和键组成最终的缓存键。 ## 站点缓存 ```python MIDDLEWARE = [ &#x27;django.middleware.cache.UpdateCacheMiddleware&#x27;, &#x27;django.middleware.common.CommonMiddleware&#x27;, &#x27;django.middleware.cache.FetchFromCacheMiddleware&#x27;, ] ``` ## 视图缓存 &gt; **cache_page**设置的缓存超时优先于Cache-Control头中的&quot;max_age&quot;&gt; 和缓存站点一样，对试图缓存以URL为键。如果多个URL指向相同的试图，每个URL将被单独缓存。```python from django.views.decorators.cache import cache_page @cache_page(60 * 15, cache=&quot;default&quot;, key_frefix=&quot;site1&quot;) def my_view(request): pass ``` ## 底层缓存API &gt; 以任意级别粒度在缓存中存储对象，如：模型对象的字符串、字典、列表，或者其他(pickle)。### 访问缓存&gt; 可通过`django.core.cache.caches`对象访问在CACHES配置的缓存。&gt; 重复请求同一个线程里的同一个别名将返回同一个对象。```pythonfrom django.core.cache import cachescache1 = caches[&#x27;myalias&#x27;]cache2 = caches[&#x27;myalias&#x27;]cache1 is cache2 # True 作为快捷方式，默认缓存可以通过django.core.cache.cache引用。等价于caches[&#39;default&#39;] 基本用法 cache.set(key, value, timeout&#x3D;DEFAULT_TIMEOUT, version&#x3D;None) cache.get(key, default&#x3D;None, version&#x3D;None) cache.add(key, value, timeout&#x3D;DEFAULT_TIMEOUT, version&#x3D;None) cache.get_or_set(key, default, timeout&#x3D;DEFAULT_TIMEOUT, version&#x3D;None) cache.get_many(keys, version&#x3D;None) cache.set_many(dict, timeout) cache.delete(key, version&#x3D;None) cache.delete_many(keys, version&#x3D;None) cache.clear() cache.touch(key, timeout&#x3D;DEFAULT_TIMEOUT, version&#x3D;None) 12345678# delete cachefrom django.core.cache import cachefrom django.utils.cache import get_cache_keyclass StudentViewSet(CacheResponseMixin, BaseModelViewSet): def update(self, request, *args, **kwargs): cache.delete(get_cache_key(request)) 下游缓存略 使用Vary标头略 四、常用的缓存组件1. Memcache详见另一篇笔记。 启动命令：memcached -d -m 10m -p 11211 -u root缓存过期策略：当内存容量达到指定值之后，就会基于LRU算法自动删除不使用的缓存。 2. Redis详见另一篇笔记。缓存过期策略： # MAXMEMORY POLICY: how Redis will select what to remove when maxmemory # is reached. You can select one from the following behaviors: # volatile-lru -&gt; Evict using approximated LRU, only keys with an expire set. # allkeys-lru -&gt; Evict any key using approximated LRU. # volatile-lfu -&gt; Evict using approximated LFU, only keys with an expire set. # allkeys-lfu -&gt; Evict any key using approximated LFU. # volatile-random -&gt; Remove a random key having an expire set. # allkeys-random -&gt; Remove a random key, any key. # volatile-ttl -&gt; Remove the key with the nearest expire time (minor TTL) # noeviction -&gt; Don&#39;t evict anything, just return an error on write operations. # # LRU means Least Recently Used # LFU means Least Frequently Used # # Both LRU, LFU and volatile-ttl are implemented using approximated # randomized algorithms. # # Note: with any of the above policies, Redis will return an error on write # operations, when there are no suitable keys for eviction. # # At the date of writing these commands are: set setnx setex append # incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd # sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby # zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby # getset mset msetnx exec sort # # The default is: # # maxmemory-policy noeviction Redis过期机制参考 五、缓存带来的问题1. 数据一致性 产生原因： ①先删除缓存：在写数据库之前，如果有读请求发生，可能导致旧数据入缓存， 引发数据不一致。②先修改数据库： a.在有缓存的情况下，两个并发的读写操作。写操作在删除缓存的时候，缓存删除失败，读操作此时读到的数据是老数据，引发数据不一致。(此处考虑是删除缓存还是更新缓存)b.在没有缓存的情况下，两个并发的读写操作。读操作没有及时的把数据放入缓存，写操作进来修改了数据库，删除了缓存，然后读操作恢复，把老数据写进了缓存。 解决方案： 延迟双删–&gt;改进–&gt;内存队列删除缓存(如果删除缓存失败，可以多次尝试)考虑到系统复杂度，一般情况下先修改数据库，后删除缓存就行。 2. 缓存击穿 产生原因： 针对某一key，该缓存在某一时间点过期的时候，刚好有对应这个key的大量并发请求过来，此时请求会直接走到数据库，可能回导致数据库崩溃。 解决方案： **①使用互斥锁(mutex key)**：使用zookeeper或者Redis实现互斥锁，等待第一个请求创建完缓存之后才允许后续请求继续访问。**②”数据永不过期”**：在value的内部设置一个超时值(timeout1)，timeout1比实际的超时时间小。当从缓存读取到timeout1发现其已经过期时，马上延迟timeout1并重新设置到缓存。然后再从数据库加载数据并这是到缓存中。 3. 缓存穿透 产生原因： 由于缓存是不命中时被动写的，且出于容错考虑，如果从数据库查不到数据就不写入缓存，当数据库中本来就不存在的数据一直被请求，在流量大时，数据库可能就会崩溃。 解决方案: ①请求校验：对请求url进行校验，有可能是恶意攻击。②使用布隆过滤器：将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层数据库的查询压力。③对空结果进行缓存：如果查询一个数据返回为空(不管是数据不存在还是系统故障)，仍然将这个空结果进行缓存，但需要设置过期时间。 4. 缓存雪崩 产生原因： 由于设置缓存时采用了相同的过期时间(或者服务器宕机)，导致缓存在某一时刻同时失效，请求全部转发到数据库，数据库瞬间压力过重而导致崩溃。 解决方案： ①将过期时间分散：在过期时间后面加上一个随机数，让key均匀的失效。②使用队列或锁控制：用队列或者锁让程序执行在压力范围之内，当然这种方案可能会影响并发量。③配置redis高可用，服务降级，缓存数据持久化","categories":[{"name":"django","slug":"django","permalink":"https://zcej.github.io/categories/django/"}],"tags":[]},{"title":"pyenv的使用","slug":"python/pyenv的使用","date":"2020-07-29T10:02:49.000Z","updated":"2022-05-23T08:42:48.553Z","comments":true,"path":"2020/07/29/python/pyenv的使用/","link":"","permalink":"https://zcej.github.io/2020/07/29/python/pyenv%E7%9A%84%E4%BD%BF%E7%94%A8/","excerpt":"","text":"pyenv安装(ubuntu)1. 拉取源代码git clone https://github.com/pyenv/pyenv.git ~/.pyenv 2. 定义环境变量1234echo &#x27;export PYENV_ROOT=&quot;$HOME/.pyenv&quot;&#x27; &gt;&gt; ~/.bashrcecho &#x27;export PATH=&quot;PYENV_ROOT/bin:$PATH&quot;&#x27; &gt;&gt; ~/.bashrcecho -e &#x27;if command -v pyenv 1&gt;/dev/null 2&gt;&amp;1;then\\n eval &quot;$(pyenv init -)&quot;\\nfi&#x27; &gt;&gt; ~/.bashrcsource /root/.bashrc 3. 安装python编译依赖1234sudo apt-get install -y build-essential libbz2-dev libssl-dev libreadline-dev libsqlite3-dev tk-dev libffi-dev# for Numpy,Matplotlibb,Scipy,etc.sudo apt-get install -y libpng-dev libfreetype6-dev python安装1. 修改镜像源export PYTHON_BUILD_MIRROR_URL=&quot;https://mirrors.huaweicloud.com&quot; 2. 安装指定版本123# 镜像源没用的话，提前下载好tar.xz包pyenv install 3.9.0 插件pyenv-virtualenv安装1. 下载插件到指定文件夹git clone https://github.com/pyenv/pyenv-virtualenv.git /root/.pyenv/plugins/pyenv-virtualenv 2. 添加到环境变量echo &#39;eval &quot;$(pyenv virtualenv-init-)&quot;&#39; &gt;&gt; ~/.bash_profile 3. 创建虚拟环境pyenv virtualenv 3.9.0 venvFirmadyne 4. 重启shell使其生效exec &quot;$SHELL&quot; 5. 激活及退出虚拟环境12pyenv activate venvFirmadynepyenv deactivate 6. 删除虚拟环境rm -rf /root/.pyenv/version/3.9.0/envs/venvFirmadyne pip源更换123456vim /root/.pip/pip.conf[global]index-url = https://pypi.tuna.tsinghua.edu.cn/simple[install]trusted-host = pypi.tuna.tsinghua.edu.cn 图片插入示例","categories":[{"name":"python","slug":"python","permalink":"https://zcej.github.io/categories/python/"}],"tags":[]},{"title":"python协程的相关总结","slug":"python/python协程的相关总结","date":"2020-07-26T11:35:21.000Z","updated":"2022-05-23T03:46:29.337Z","comments":true,"path":"2020/07/26/python/python协程的相关总结/","link":"","permalink":"https://zcej.github.io/2020/07/26/python/python%E5%8D%8F%E7%A8%8B%E7%9A%84%E7%9B%B8%E5%85%B3%E6%80%BB%E7%BB%93/","excerpt":"","text":"生成器可迭代对象、迭代器、生成器 可迭代对象：实现了方法__iter__或__getitem__就是可迭代的。 迭代器：在可迭代对象的基础上实现了__next__方法，__iter__方法需返回一个迭代器，如果自身是迭代器则返回self。 生成器：可以理解为在迭代器的基础上再实现了yield，yield返回新的值后，会在当前位置阻塞，等待下一次的调用。 如何激活生成器 next() generator.send(None) 生成器的执行状态 GEN_CREATED GEN_RUNNING GEN_SUSPENDED GEN_CLOSED 生成器的异常处理当生成器不满足生成元素的条件时，就应该抛出异常StopIteration 从生成器过度到协程 协程是为非抢占式多任务产生子程序的计算机程序组件，协程允许不同入口点在不同位置暂停或开始执行程序。 如何向生成器中发送消息： 12345678910111213141516def jumping_range(N): index = 0 while index &lt; N: # 通过send()发送的消息将赋值给jump jump = yield index if jump is None: jump += 1 index += jumpif __name__ == &#x27;__main__&#x27;: itr = jumping_range(5) print(next(itr)) # 0 print(itr.send(2)) # 2 print(next(itr)) # 3 print(itr.send(-1)) # 2 重点在于jump = yield index yield index 是将index return给外部调用程序 jump = yield 是可以接收外部程序通过send()发送的信息，并赋值给jump yield from 语法为什么要使用协程如果没有协程，要去实现一个并发程序，可能会有以下问题 使用最常规的同步编程要实现异步并发效果并不理想，或者难度极高 由于GIL锁的存在，多线程的运行需要频繁的加锁解锁，切换线程，这极大的降低了并发性能 而协程的出现，刚好可以解决以上的问题，它的特点有 协程是在单线程里实现任务的切换的 利用同步的方式去实现异步 不再需要锁，提高了并发性能 yield from用法详解yield from 是在python3.3才出现的语法。这个特性是在python2中没有的。yield from 后面是需要加可迭代对象，它可以普通的可迭代对象，也可以是迭代器，甚至是生成器。 1234567891011121314151617# usage: yielddef gen_1(*args, **kwargs): for item in args: for i in item: yield idef gen_2(*args, **kwargs): for item in args: yield from itemstr_1 = &quot;test&quot;list_1 = [1, 2, 3]ret_1 = gen_1(str_1, list_1)ret_2 = gen_2(str_1, list_1)# [&#x27;t&#x27;, &#x27;e&#x27;, &#x27;s&#x27;, &#x27;t&#x27;, 1, 2, 3] 生成器嵌套 调用方：调用委托生成器的客户端代码 委托生成器：包含yield from的表达式生成器函数 子生成器：yield from 后面加的生成器函数","categories":[{"name":"python","slug":"python","permalink":"https://zcej.github.io/categories/python/"}],"tags":[]}],"categories":[{"name":"go","slug":"go","permalink":"https://zcej.github.io/categories/go/"},{"name":"django","slug":"django","permalink":"https://zcej.github.io/categories/django/"},{"name":"python","slug":"python","permalink":"https://zcej.github.io/categories/python/"}],"tags":[]}